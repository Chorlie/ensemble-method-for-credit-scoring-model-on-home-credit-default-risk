{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Library","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport math\nimport plotly.express as px\nimport matplotlib.pyplot as plt\nimport random\nimport missingno as msno\nimport statsmodels.api as sm\nfrom collections import Counter\nfrom sklearn import preprocessing\nfrom random import sample\nfrom sklearn.pipeline import Pipeline\nfrom sklearn import metrics, linear_model\nfrom sklearn.model_selection import train_test_split, cross_val_score, cross_val_predict\nfrom sklearn.metrics import precision_score, recall_score, f1_score, classification_report, confusion_matrix, roc_curve, auc, accuracy_score, roc_auc_score, mean_squared_error, mean_absolute_error, log_loss\nfrom sklearn.preprocessing import MinMaxScaler, LabelEncoder\nfrom statsmodels.stats.outliers_influence import variance_inflation_factor\n# Slicing data\nfrom sklearn.model_selection import StratifiedShuffleSplit\n\n# Cross-Validation techniques\nfrom sklearn.model_selection import KFold, StratifiedKFold\n\n# Principal Analysis\nfrom sklearn.decomposition import PCA\nfrom numpy.linalg import eigh\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.impute import SimpleImputer\n\n# Deal with imbalance data\nfrom sklearn.utils import resample \nfrom sklearn.datasets import make_classification\n\n# Resampling method\n# RUS\nfrom imblearn.under_sampling import RandomUnderSampler\n# ROS\nfrom imblearn.over_sampling import RandomOverSampler\n# SMOTE\nfrom imblearn.over_sampling import SMOTE\n\n# Common machine learning methods\n# Linear regression\nfrom sklearn.linear_model import LinearRegression\n# Logistic Regression\nfrom sklearn.linear_model import LogisticRegression \nfrom matplotlib import pyplot\n# KNN\nfrom sklearn.neighbors import KNeighborsClassifier\n# SVM\nfrom sklearn import svm\nfrom sklearn.svm import SVC\n# Decision tree\nfrom sklearn import tree\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.tree import DecisionTreeRegressor \nfrom sklearn.tree import export_graphviz\nfrom IPython.display import Image \n# Neural Networks \nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.metrics import AUC\nfrom tensorflow.keras.utils import get_custom_objects\n\n# Bagging\nfrom sklearn.ensemble import BaggingClassifier\n# Random Forest\nfrom sklearn.ensemble import RandomForestClassifier \nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.datasets import make_regression\n# Bagged NN\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.ensemble import BaggingClassifier\n\n# Boosting\n# Light GBM\nfrom lightgbm import LGBMClassifier\n# Extreme Gradient Boosting\nimport xgboost as xgb\nfrom xgboost import XGBClassifier\n# Gradient Boosting\nfrom sklearn.ensemble import GradientBoostingClassifier\n# Adaptive Boosting\nfrom sklearn.ensemble import AdaBoostClassifie\n","metadata":{"execution":{"iopub.status.busy":"2023-07-04T14:59:05.085366Z","iopub.execute_input":"2023-07-04T14:59:05.086219Z","iopub.status.idle":"2023-07-04T14:59:11.978714Z","shell.execute_reply.started":"2023-07-04T14:59:05.086172Z","shell.execute_reply":"2023-07-04T14:59:11.977355Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"# Pre-processing data function","metadata":{}},{"cell_type":"code","source":"# Descriptive Statistics\ndef data_description(df):\n    print(\"Infomation of the dataset:\")\n    print(df.info())\n    print()\n    \n    print(\"The number of null value in each column:\")\n    print(df.isnull().sum())\n    print()\n    \n    print(\"The percentage of null value in each column:\")\n    print((df.isnull().sum()/len(df)).sort_values(ascending = False))  ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# map with previous_application, credit_card_balance, installments_payments\ndef POS_CASH_balance_preprocessing(df):\n    data_description(df)\n    print()\n    index_names = df[(df['NAME_CONTRACT_STATUS'] == 'Canceled') | (df['NAME_CONTRACT_STATUS'] == 'XNA')].index\n    df = df.drop(index_names)\n    print(\"NAME_CONTRACT_STATUS after removing Canceled and XNA\")\n    print(df['NAME_CONTRACT_STATUS'].value_counts())\n    # Get dummies value for name of contract status\n    dummies_NAME_CONTRACT_STATUS = pd.get_dummies(df['NAME_CONTRACT_STATUS'])\n    dummies_NAME_CONTRACT_STATUS.columns = dummies_NAME_CONTRACT_STATUS.columns.str.replace(' ', '_').str.upper()\n    df = pd.concat([df, dummies_NAME_CONTRACT_STATUS], axis = 1)\n    # Computation metrics\n    df['DPD30PLUS'] = df['SK_DPD'].apply(lambda x: 1 if x >= 30 else 0)\n    df['DPD60PLUS'] = df['SK_DPD'].apply(lambda x: 1 if x >= 60 else 0)\n    df['DPD90PLUS'] = df['SK_DPD'].apply(lambda x: 1 if x >= 90 else 0)\n    df['DPD120PLUS'] = df['SK_DPD'].apply(lambda x: 1 if x >= 120 else 0)\n    \n    df['DPD30PLUS_DEF'] = df['SK_DPD_DEF'].apply(lambda x: 1 if x >= 30 else 0)\n    df['DPD60PLUS_DEF'] = df['SK_DPD_DEF'].apply(lambda x: 1 if x >= 60 else 0)\n    df['DPD90PLUS_DEF'] = df['SK_DPD_DEF'].apply(lambda x: 1 if x >= 90 else 0)\n    df['DPD120PLUS_DEF'] = df['SK_DPD_DEF'].apply(lambda x: 1 if x >= 120 else 0)\n    \n    epsilon = 0\n    df['PER_INSTALLMENT_PAID'] = (df['CNT_INSTALMENT'] - df['CNT_INSTALMENT_FUTURE'])/(df['CNT_INSTALMENT']+epsilon)\n    df['PER_INSTALLMENT_FUTURE'] = df['CNT_INSTALMENT_FUTURE']/(df['CNT_INSTALMENT']+epsilon)\n    \n    POS_CASH_balance_agg_dict = {\n        'SK_ID_PREV': ['count'],\n        'MONTHS_BALANCE': ['max', 'min', 'mean'],\n        'CNT_INSTALMENT': ['max', 'min', 'mean'],\n        'CNT_INSTALMENT_FUTURE': ['max', 'min', 'mean'],\n        'SK_DPD': ['max', 'min', 'mean'],\n        'SK_DPD_DEF': ['max', 'min', 'mean'],\n    }\n    \n    POS_CASH_balance_group = df.groupby('SK_ID_CURR') \n    POS_CASH_balance_agg = POS_CASH_balance_group.agg(POS_CASH_balance_agg_dict)\n    POS_CASH_balance_agg.columns = ['PCB_'+('_').join(column).upper() for column in POS_CASH_balance_agg.columns.ravel()]\n    POS_CASH_balance_agg = POS_CASH_balance_agg.reset_index()\n    print('POS_CASH_balance_agg:', POS_CASH_balance_agg.shape)\n    \n    return POS_CASH_balance_agg","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def installments_payments_preprocessing(df):\n    data_description(df)\n    print()\n    df = df.fillna(0)\n    df['SK_DPD'] = df['DAYS_ENTRY_PAYMENT'] - df['DAYS_INSTALMENT']\n    df['UNPAID_AMT'] = df['AMT_INSTALMENT'] - df['AMT_PAYMENT']\n    df['PER_OVD_AMT'] = (df['AMT_INSTALMENT'] - df['AMT_PAYMENT'])/df['AMT_INSTALMENT']\n    # Computation metrics\n    df['DPD30PLUS'] = df['SK_DPD'].apply(lambda x: 1 if x >= 30 else 0)\n    df['DPD90PLUS'] = df['SK_DPD'].apply(lambda x: 1 if x >= 90 else 0)\n    df['DPD120PLUS'] = df['SK_DPD'].apply(lambda x: 1 if x >= 120 else 0)\n    # Agg dict\n    agg_dict = {\n        'SK_ID_PREV': ['count'],\n        'NUM_INSTALMENT_VERSION':['nunique'],\n        'DAYS_ENTRY_PAYMENT':['mean', 'max', 'sum'],\n        'DAYS_INSTALMENT':['mean', 'max', 'sum'],\n        'AMT_INSTALMENT':['mean', 'max', 'sum'],\n        'AMT_PAYMENT':['mean', 'max','sum'],\n        'SK_DPD':['mean', 'max', 'sum'],\n        'UNPAID_AMT':['mean', 'max', 'sum'],\n        'PER_OVD_AMT':['mean', 'max','sum'],\n        'DPD30PLUS': ['mean', 'max'],\n        'DPD90PLUS': ['mean', 'max'],\n        'DPD120PLUS': ['mean', 'max'],\n    }\n    print(df.info())\n    installments_payments_group = df.groupby(['SK_ID_CURR']) \n    installments_payments_agg = installments_payments_group.agg(agg_dict)\n    installments_payments_agg.columns = ['INS_PAYMENT'+('_').join(column).upper() for column in installments_payments_agg.columns.ravel()]\n    installments_payments_agg = installments_payments_agg.reset_index()\n    print('installments_payments_agg shape:', installments_payments_agg.shape)\n    \n    return installments_payments_agg","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def previous_application_preprocessing(df):\n    data_description(df)\n    print()\n    # Replace XNA with nan\n    df = df.replace('XNA', np.NaN)\n    \n    # Mapping value for FLAG_LAST_APPL_PER_CONTRACT\n    d = {'Y': 0, 'N': 1}\n    df['FLAG_LAST_APPL_PER_CONTRACT'] = df['FLAG_LAST_APPL_PER_CONTRACT'].map(d)\n    \n    # Get dummies value for name of contract status\n    get_dummies_column = ['NAME_CONTRACT_TYPE', 'NAME_CONTRACT_STATUS', 'NAME_CLIENT_TYPE', 'NAME_PORTFOLIO', 'NAME_YIELD_GROUP']\n    for i in get_dummies_column:\n        df_dummies = pd.DataFrame()\n        df_dummies = pd.get_dummies(df[i])\n        df_dummies.columns = df_dummies.columns.str.replace(' ', '_').str.upper()\n        df_dummies = df_dummies.add_prefix(f'{i}_')\n        df = pd.concat([df, df_dummies], axis = 1)\n    \n    # Replace columns value \n    replace_value_columns = ['DAYS_FIRST_DRAWING', 'DAYS_FIRST_DUE', 'DAYS_LAST_DUE_1ST_VERSION', 'DAYS_LAST_DUE', 'DAYS_TERMINATION']\n    for i in replace_value_columns:\n        df[i].replace(365243, np.NaN, inplace = True)\n    \n    # Computation metrics\n    df['PER_SELF_EVALUATION_AMT'] = df['AMT_ANNUITY']/df['AMT_APPLICATION']\n    df['PER_FI_EVALUATION_AMT'] = df['AMT_ANNUITY']/df['AMT_CREDIT']\n    df['PER_DOWN_PAYMENT'] = df['AMT_DOWN_PAYMENT']/df['AMT_GOODS_PRICE']\n    df['PER_GOODS_PRICE_CREDIT'] = df['AMT_GOODS_PRICE']/df['AMT_CREDIT']\n    df['PER_APPLICATION_CREDIT'] = df['AMT_APPLICATION']/df['AMT_CREDIT']\n    df['DAY_DIFF_LAST_FIRST_DUE'] = df['DAYS_LAST_DUE'] - df['DAYS_FIRST_DUE']\n    df['FULL_PAY_AMOUNT'] = df['AMT_ANNUITY'] * df['CNT_PAYMENT']\n    \n    agg_dict = {\n        'SK_ID_PREV' : ['count'],\n        'AMT_ANNUITY' : ['max', 'min', 'mean'],\n        'AMT_APPLICATION' : ['max', 'min', 'mean'],\n        'AMT_CREDIT' : ['max', 'min', 'mean'],\n        'AMT_DOWN_PAYMENT' : ['max', 'min', 'mean'],\n        'AMT_GOODS_PRICE' : ['max', 'min', 'mean'],\n        'NFLAG_LAST_APPL_IN_DAY': ['mean'],\n        'RATE_DOWN_PAYMENT': ['max', 'min', 'mean'],\n        'SELLERPLACE_AREA' : ['max', 'min', 'mean'],\n        'CNT_PAYMENT' : ['max', 'min', 'mean'],\n        'DAYS_FIRST_DRAWING' : ['max', 'min', 'mean'],\n        'DAYS_FIRST_DUE' : ['max', 'min', 'mean'],\n        'DAYS_LAST_DUE_1ST_VERSION' : ['max', 'min', 'mean'],\n        'DAYS_LAST_DUE' : ['max', 'min', 'mean'],\n        'DAYS_TERMINATION' : ['max', 'min', 'mean'],\n        'NFLAG_INSURED_ON_APPROVAL' : ['max', 'mean'],\n        'NAME_CONTRACT_TYPE_CASH_LOANS' : ['mean'],\n        'NAME_CONTRACT_TYPE_CONSUMER_LOANS' : ['mean'],\n        'NAME_CONTRACT_TYPE_REVOLVING_LOANS' : ['mean'],\n        'NAME_CONTRACT_STATUS_APPROVED' : ['mean'],\n        'NAME_CONTRACT_STATUS_CANCELED' : ['mean'],\n        'NAME_CONTRACT_STATUS_REFUSED' : ['mean'],\n        'NAME_CONTRACT_STATUS_UNUSED_OFFER' : ['mean'],\n        'NAME_CLIENT_TYPE_NEW' : ['mean'],\n        'NAME_CLIENT_TYPE_REFRESHED' : ['mean'],\n        'NAME_CLIENT_TYPE_REPEATER' : ['mean'],\n        'NAME_PORTFOLIO_CARDS' : ['mean'],\n        'NAME_PORTFOLIO_CARS' : ['mean'],\n        'NAME_PORTFOLIO_CASH': ['mean'],\n        'NAME_PORTFOLIO_POS' : ['mean'],\n        'NAME_YIELD_GROUP_HIGH' : ['mean'],\n        'NAME_YIELD_GROUP_LOW_ACTION' : ['mean'],\n        'NAME_YIELD_GROUP_LOW_NORMAL' : ['mean'],        \n        'NAME_YIELD_GROUP_MIDDLE' : ['mean'],\n        'PER_SELF_EVALUATION_AMT' : ['mean'],\n        'PER_FI_EVALUATION_AMT' : ['mean'],\n        'PER_DOWN_PAYMENT' : ['mean'],\n        'PER_GOODS_PRICE_CREDIT' : ['mean'],\n        'PER_APPLICATION_CREDIT' : ['mean'],\n        'DAY_DIFF_LAST_FIRST_DUE' : ['max', 'min', 'mean'],\n        'FULL_PAY_AMOUNT' : ['max', 'min', 'mean']\n    }\n    \n    previous_application_group = df.groupby('SK_ID_CURR') \n    previous_application_agg = previous_application_group.agg(agg_dict)\n    previous_application_agg.columns = ['PREV_APP_'+('_').join(column).upper() for column in previous_application_agg.columns.ravel()]\n    previous_application_agg = previous_application_agg.reset_index()\n    print('previous_application_agg shape:', previous_application_agg.shape)\n    \n    return previous_application_agg","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def credit_card_balance_preprocessing(df):\n    data_description(df)\n    print()\n    # select numeric columns\n    numeric_columns = df.select_dtypes(include=['number']).columns\n    # fill 0 to all NaN \n    df[numeric_columns] = df[numeric_columns].fillna(0)\n    \n    # Get dummies value for NAME_OF_CONTRACT_STATUS\n    df_dummies = pd.DataFrame()\n    df_dummies = pd.get_dummies(df['NAME_CONTRACT_STATUS'])\n    df_dummies.columns = df_dummies.columns.str.replace(' ', '_').str.upper()\n    df_dummies = df_dummies.add_prefix('CONTRACT_STATUS_')\n    df = pd.concat([df, df_dummies], axis = 1)\n    df = df.drop(['NAME_CONTRACT_STATUS'], axis = 1)\n    \n    # DPD Flag\n    df['DPD30PLUS'] = df['SK_DPD'].apply(lambda x: 1 if x >= 30 else 0)\n    df['DPD60PLUS'] = df['SK_DPD'].apply(lambda x: 1 if x >= 60 else 0)\n    df['DPD90PLUS'] = df['SK_DPD'].apply(lambda x: 1 if x >= 90 else 0)\n    df['DPD120PLUS'] = df['SK_DPD'].apply(lambda x: 1 if x >= 120 else 0)\n    \n    df['DPD30PLUS_DEF'] = df['SK_DPD_DEF'].apply(lambda x: 1 if x >= 30 else 0)\n    df['DPD60PLUS_DEF'] = df['SK_DPD_DEF'].apply(lambda x: 1 if x >= 60 else 0)\n    df['DPD90PLUS_DEF'] = df['SK_DPD_DEF'].apply(lambda x: 1 if x >= 90 else 0)\n    df['DPD120PLUS_DEF'] = df['SK_DPD_DEF'].apply(lambda x: 1 if x >= 120 else 0)\n    \n    # Computation metrics\n    df['AMT_OUTSTANDING'] = df['AMT_CREDIT_LIMIT_ACTUAL'] - df['AMT_BALANCE']\n    df['PER_UTILIZATION'] = df['AMT_OUTSTANDING']/df['AMT_CREDIT_LIMIT_ACTUAL']\n    df['PER_AMT_DRAWINGS_ATM_CURRENT_OVER_AMT_OUTSTANDING'] = df['AMT_DRAWINGS_ATM_CURRENT'] / df['AMT_OUTSTANDING']\n    df['PER_AMT_DRAWINGS_ATM_CURRENT_OVER_CREDIT_LIMIT'] = df['AMT_DRAWINGS_ATM_CURRENT'] / df['AMT_CREDIT_LIMIT_ACTUAL']\n    df['PER_AMT_DRAWINGS_CURRENT_OVER_AMT_OUTSTANDING'] = df['AMT_DRAWINGS_CURRENT'] / df['AMT_OUTSTANDING']\n    df['PER_AMT_DRAWINGS_CURRENT_OVER_CREDIT_LIMIT'] = df['AMT_DRAWINGS_CURRENT'] / df['AMT_CREDIT_LIMIT_ACTUAL']\n    df['PER_AMT_DRAWINGS_POS_CURRENT'] = df['AMT_DRAWINGS_POS_CURRENT'] / df['AMT_DRAWINGS_CURRENT']\n    df['PER_AMT_DRAWINGS_ATM_CURRENT'] = df['AMT_DRAWINGS_ATM_CURRENT'] / df['AMT_DRAWINGS_CURRENT']    \n    df['PER_AMT_DRAWINGS_OTHER_CURRENT'] = df['AMT_DRAWINGS_OTHER_CURRENT'] / df['AMT_DRAWINGS_CURRENT']\n    df['PER_INS_MIN'] = df['AMT_INST_MIN_REGULARITY'] / df['AMT_OUTSTANDING']\n    df['PER_AMT_PAYMENT_CURRENT'] = df['AMT_PAYMENT_CURRENT'] / df['AMT_OUTSTANDING']\n    df['PER_AMT_PAYMENT_TOTAL_CURRENT'] = df['AMT_PAYMENT_TOTAL_CURRENT'] / df['AMT_OUTSTANDING']\n    df['PER_RECEIVABLE_TOTAL'] = df['AMT_TOTAL_RECEIVABLE'] / df['AMT_OUTSTANDING']\n    df['PER_RECEIVABLE_PRINCIPAL'] = df['AMT_RECEIVABLE_PRINCIPAL'] / df['AMT_OUTSTANDING']\n    df['PER_CNT_DRAWINGS_ATM_CURRENT'] = df['CNT_DRAWINGS_ATM_CURRENT'] / df['CNT_DRAWINGS_CURRENT']\n    df['PER_CNT_DRAWINGS_OTHER_CURRENT'] = df['CNT_DRAWINGS_OTHER_CURRENT'] / df['CNT_DRAWINGS_CURRENT']\n    df['PER_CNT_DRAWINGS_POS_CURRENT'] = df['CNT_DRAWINGS_POS_CURRENT'] / df['CNT_DRAWINGS_CURRENT']\n    \n    agg_dict = {\n        'SK_ID_PREV': ['count'],\n        'MONTHS_BALANCE': ['max', 'min', 'mean'],\n        'AMT_CREDIT_LIMIT_ACTUAL': ['max', 'min', 'mean'],\n        'CNT_DRAWINGS_ATM_CURRENT': ['max', 'min', 'mean'],\n        'CNT_DRAWINGS_CURRENT': ['max', 'min', 'mean'],\n        'CNT_DRAWINGS_OTHER_CURRENT': ['max', 'min', 'mean'],\n        'CNT_DRAWINGS_POS_CURRENT': ['max', 'min', 'mean'],\n        'CNT_INSTALMENT_MATURE_CUM': ['max', 'min', 'mean'],\n        'SK_DPD': ['max', 'min', 'mean'],\n        'SK_DPD_DEF': ['max', 'min', 'mean'],\n        'CONTRACT_STATUS_ACTIVE': ['max', 'mean'],\n        'CONTRACT_STATUS_APPROVED': ['max', 'mean'],\n        'CONTRACT_STATUS_COMPLETED': ['max', 'mean'],\n        'CONTRACT_STATUS_DEMAND': ['max', 'mean'],\n        'CONTRACT_STATUS_REFUSED': ['max', 'mean'],\n        'CONTRACT_STATUS_SENT_PROPOSAL': ['max', 'mean'],\n        'CONTRACT_STATUS_SIGNED': ['max', 'mean'],\n        'DPD30PLUS': ['max', 'mean'],\n        'DPD90PLUS': ['max', 'mean'],\n        'DPD120PLUS': ['max', 'mean'],\n        'DPD30PLUS_DEF': ['max', 'mean'],\n        'DPD90PLUS_DEF': ['max', 'mean'],\n        'DPD120PLUS_DEF': ['max', 'mean'],\n        'PER_UTILIZATION': ['max', 'min', 'mean'],\n        'PER_AMT_DRAWINGS_ATM_CURRENT_OVER_AMT_OUTSTANDING': ['max', 'min', 'mean'],\n        'PER_AMT_DRAWINGS_ATM_CURRENT_OVER_CREDIT_LIMIT': ['max', 'min', 'mean'],\n        'PER_AMT_DRAWINGS_CURRENT_OVER_AMT_OUTSTANDING': ['max', 'min', 'mean'],\n        'PER_AMT_DRAWINGS_CURRENT_OVER_CREDIT_LIMIT': ['max', 'min', 'mean'],\n        'PER_AMT_DRAWINGS_POS_CURRENT': ['max', 'min', 'mean'],\n        'PER_AMT_DRAWINGS_ATM_CURRENT': ['max', 'min', 'mean'],\n        'PER_AMT_DRAWINGS_OTHER_CURRENT': ['max', 'min', 'mean'],\n        'PER_INS_MIN': ['max', 'min', 'mean'],\n        'PER_AMT_PAYMENT_CURRENT': ['max', 'min', 'mean'],\n        'PER_AMT_PAYMENT_TOTAL_CURRENT': ['max', 'min', 'mean'],\n        'PER_RECEIVABLE_TOTAL': ['max', 'min', 'mean'],\n        'PER_RECEIVABLE_PRINCIPAL': ['max', 'min', 'mean'],\n        'PER_CNT_DRAWINGS_ATM_CURRENT': ['max', 'min', 'mean'],\n        'PER_CNT_DRAWINGS_OTHER_CURRENT': ['max', 'min', 'mean'],\n        'PER_CNT_DRAWINGS_POS_CURRENT': ['max', 'min', 'mean']\n    }\n    credit_card_balance_group = df.groupby('SK_ID_CURR') \n    credit_card_balance_agg = credit_card_balance_group.agg(agg_dict)\n    credit_card_balance_agg.columns = ['CCB_'+('_').join(column).upper() for column in credit_card_balance_agg.columns.ravel()]\n    credit_card_balance_agg = credit_card_balance_agg.reset_index()\n    print('credit_card_balance_agg shape:', credit_card_balance_agg.shape)\n    \n    return credit_card_balance_agg","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def bureau_preprocessing(bureau, bureau_balance):\n    print(\"Data type info of bureau:\")\n    print(bureau.info())\n    arr1 = np.where(bureau['DAYS_CREDIT_ENDDATE'].isnull() & bureau['DAYS_ENDDATE_FACT'].notnull(), 0, bureau['DAYS_CREDIT_ENDDATE'])\n    bureau['DAYS_CREDIT_ENDDATE'] = arr1\n    arr2 = np.where(bureau['DAYS_CREDIT_ENDDATE'].notnull() & bureau['DAYS_ENDDATE_FACT'].isnull(), 0, bureau['DAYS_ENDDATE_FACT'])\n    bureau['DAYS_ENDDATE_FACT'] = arr2\n    # bureau_balance = pd.read_csv(bureau_balance_path)\n    print(\"Data type info of bureau_balance:\")\n    print(bureau_balance.info())\n    # Inner join \n    bureau_total = pd.merge(bureau, bureau_balance, how=\"inner\", on=[\"SK_ID_BUREAU\"])\n\n    # CREDIT_CURRENCY\n    mapping = {'currency 1':1,\n               'currency 2':2,\n               'currency 3':3,\n               'currency 4':4\n              }\n    bureau_total['CREDIT_CURRENCY'] = bureau_total['CREDIT_CURRENCY'].map(mapping) \n\n    # Num metrics\n    # Number of days from the time of applying the loan at CB (the loan period may not be closed) until the payment due date\n    bureau_total['DAYS_DIFF_CREDIT_ENDDATE'] = bureau_total['DAYS_CREDIT'] - bureau_total['DAYS_CREDIT_ENDDATE']\n    # Số ngày kể từ lúc apply khoảng vay ở CB (khoảng vay đã close) đến khi đến hạn thanh toán\n    bureau_total['DAYS_DIFF_CREDIT_ENDDATE_FACT'] = bureau_total['DAYS_CREDIT'] - bureau_total['DAYS_ENDDATE_FACT']\n    bureau_total['DAYS_DIFF_ENDDATE_FACT_CREDIT_ENDDATE'] = bureau_total['DAYS_ENDDATE_FACT'] - bureau_total['DAYS_CREDIT_ENDDATE']\n\n    bureau_total['STATUS_CLOSED'] = bureau_total['STATUS'].apply(lambda x: 1 if x == 'C' else 0)\n    bureau_total['STATUS_UNKNOWN'] = bureau_total['STATUS'].apply(lambda x: 1 if x == 'X' else 0)\n    bureau_total['DPD0'] = bureau_total['STATUS'].apply(lambda x: 1 if x == '0' else 0)\n    bureau_total['DPD1_TO_30'] = bureau_total['STATUS'].apply(lambda x: 1 if x == '1' else 0)\n    bureau_total['DPD31_TO_60'] = bureau_total['STATUS'].apply(lambda x: 1 if x == '2' else 0)\n    bureau_total['DPD61_TO_90'] = bureau_total['STATUS'].apply(lambda x: 1 if x == '3' else 0)\n    bureau_total['DPD91_TO_120'] = bureau_total['STATUS'].apply(lambda x: 1 if x == '4' else 0)\n    bureau_total['DPD120PLUS_SOLD_WRITEOFF'] = bureau_total['STATUS'].apply(lambda x: 1 if x == '5' else 0)\n\n    bureau_total['HAS_DPD'] = bureau_total['CREDIT_DAY_OVERDUE'].apply(lambda x: 1 if x > 0 else 0)\n    bureau_total['HAS_DPD30PLUS'] = bureau_total['CREDIT_DAY_OVERDUE'].apply(lambda x: 1 if x >= 30 else 0)\n    bureau_total['HAS_DPD60PLUS'] = bureau_total['CREDIT_DAY_OVERDUE'].apply(lambda x: 1 if x >= 60 else 0)\n    bureau_total['HAS_DPD90PLUS'] = bureau_total['CREDIT_DAY_OVERDUE'].apply(lambda x: 1 if x >= 90 else 0)\n    bureau_total['HAS_DPD_OVER120'] = bureau_total['CREDIT_DAY_OVERDUE'].apply(lambda x: 1 if x > 120 else 0)\n\n    # Add in metrics\n    # Percentage metrics\n    epsilon = 0\n    # The total owned amt over the total credit limit\n    bureau_total['PER_DEBT_AMT_CREDIT'] = bureau_total['AMT_CREDIT_SUM_DEBT']/(bureau_total['AMT_CREDIT_SUM']+epsilon)\n    # The total owned amt over the total credit limit of credit card\n    bureau_total['PER_DEBT_AMT_CREDIT_CARD'] = bureau_total['AMT_CREDIT_SUM_DEBT']/(bureau_total['AMT_CREDIT_SUM_LIMIT']+epsilon)\n    # The total overdue amount over the total debt\n    bureau_total['PER_CREDIT_OVD_AMT_DEBT'] = bureau_total['AMT_CREDIT_SUM_OVERDUE']/(bureau_total['AMT_CREDIT_SUM_DEBT']+epsilon)\n    # The total overdue amount over the total credit limit of credit card\n    bureau_total['PER_CREDIT_OVD_AMT_CREDIT_CARD_LIMIT'] = bureau_total['AMT_CREDIT_SUM_OVERDUE']/(bureau_total['AMT_CREDIT_SUM_LIMIT']+epsilon)\n    # The total overdue amount over the total credit limit\n    bureau_total['PER_CREDIT_OVD_AMT_CREDIT_LIMIT'] = bureau_total['AMT_CREDIT_SUM_OVERDUE']/(bureau_total['AMT_CREDIT_SUM']+epsilon)\n    # The monthly payment amt over the total credit limit\n    bureau_total['PER_ANNUITY_TOTAL_CREDIT'] = bureau_total['AMT_ANNUITY']/(bureau_total['AMT_CREDIT_SUM']+epsilon)\n    # The monthly payment amt over the total credit limit of credit card\n    bureau_total['PER_ANNUITY_CREDIT_CARD'] = bureau_total['AMT_ANNUITY']/(bureau_total['AMT_CREDIT_SUM_LIMIT']+epsilon)\n    # The maximum overdue amt over total debt \n    bureau_total['PER_MAX_CREDIT_OVD_AMT_DEBT'] = bureau_total['AMT_CREDIT_MAX_OVERDUE']/(bureau_total['AMT_CREDIT_SUM_DEBT']+epsilon)\n    # The maximum overdue amt over the credit limit of credit card\n    bureau_total['PER_MAX_CREDIT_OVD_AMT_CREDIT_CARD_LIMIT'] = bureau_total['AMT_CREDIT_MAX_OVERDUE']/(bureau_total['AMT_CREDIT_SUM_LIMIT']+epsilon)\n    # The maximum overdue amt over the total credit limit\n    bureau_total['PER_MAX_CREDIT_OVD_AMT_CREDIT_LIMIT'] = bureau_total['AMT_CREDIT_MAX_OVERDUE']/(bureau_total['AMT_CREDIT_SUM']+epsilon)\n\n    bureau_agg_dict = {\n        'SK_ID_BUREAU':['count'],\n        'DAYS_CREDIT':['min', 'max', 'mean'],\n        'CREDIT_DAY_OVERDUE':['min', 'max', 'mean'],\n        'DAYS_CREDIT_ENDDATE':['min', 'max', 'mean'],\n        'DAYS_ENDDATE_FACT':['min', 'max', 'mean'],\n        'AMT_CREDIT_MAX_OVERDUE': ['max', 'mean'],\n        'AMT_CREDIT_SUM': ['max', 'mean', 'sum'],\n        'AMT_CREDIT_SUM_DEBT': ['max', 'mean', 'sum'],\n        'AMT_CREDIT_SUM_OVERDUE': ['max', 'mean', 'sum'],\n        'AMT_ANNUITY': ['max', 'mean', 'sum'],\n\n        'DAYS_DIFF_CREDIT_ENDDATE':['min', 'max', 'mean'],\n        'DAYS_DIFF_CREDIT_ENDDATE_FACT':['min', 'max', 'mean'],\n        'DAYS_DIFF_ENDDATE_FACT_CREDIT_ENDDATE':['min', 'max', 'mean'],\n\n        'PER_DEBT_AMT_CREDIT':['min', 'max', 'mean'],\n        'PER_DEBT_AMT_CREDIT_CARD':['min', 'max', 'mean'],\n        'PER_CREDIT_OVD_AMT_DEBT':['min', 'max', 'mean'],\n        'PER_CREDIT_OVD_AMT_CREDIT_CARD_LIMIT':['min', 'max', 'mean'],\n        'PER_CREDIT_OVD_AMT_CREDIT_LIMIT':['min', 'max', 'mean'],\n        'PER_ANNUITY_TOTAL_CREDIT':['min', 'max', 'mean'],\n        'PER_ANNUITY_CREDIT_CARD':['min', 'max', 'mean'],\n        'PER_MAX_CREDIT_OVD_AMT_DEBT':['min', 'max', 'mean'],\n        'PER_MAX_CREDIT_OVD_AMT_CREDIT_CARD_LIMIT':['min', 'max', 'mean'],\n        'PER_MAX_CREDIT_OVD_AMT_CREDIT_LIMIT':['min', 'max', 'mean'],\n\n        'STATUS_CLOSED': ['max', 'mean'],\n        'STATUS_UNKNOWN': ['max', 'mean'],\n        'DPD0': ['max', 'mean'],\n        'DPD1_TO_30': ['max', 'mean'],\n        'DPD31_TO_60': ['max', 'mean'],\n        'DPD61_TO_90': ['max', 'mean'],\n        'DPD91_TO_120': ['max', 'mean'],\n        'DPD120PLUS_SOLD_WRITEOFF': ['max', 'mean'],\n\n        'HAS_DPD': ['max', 'mean'],\n        'HAS_DPD30PLUS': ['max', 'mean'],\n        'HAS_DPD60PLUS': ['max', 'mean'],\n        'HAS_DPD90PLUS': ['max', 'mean'],\n        'HAS_DPD_OVER120': ['max', 'mean'],\n\n        'MONTHS_BALANCE': ['min', 'max', 'mean']\n      }\n    bureau_grp = bureau_total.groupby('SK_ID_CURR')\n    bureau_day_amt_agg = bureau_grp.agg(bureau_agg_dict)\n    bureau_day_amt_agg.columns = ['BUREAU_'+('_').join(column).upper() for column in bureau_day_amt_agg.columns.ravel()]\n    bureau_day_amt_agg = bureau_day_amt_agg.reset_index()\n    print('bureau_day_amt_agg shape:', bureau_day_amt_agg.shape)\n    return bureau_day_amt_agg","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def application_preprocessing(apps):\n    apps = apps[apps['CODE_GENDER'] != 'XNA']\n\n    # NaN values for DAYS_EMPLOYED: 365.243 -> nan\n    apps['DAYS_EMPLOYED'].replace(365243, np.nan, inplace= True)\n    # Some simple new features (percentages)\n    apps['DAYS_EMPLOYED_PERC'] = apps['DAYS_EMPLOYED'] / apps['DAYS_BIRTH']\n    apps['INCOME_CREDIT_PERC'] = apps['AMT_INCOME_TOTAL'] / apps['AMT_CREDIT']\n    apps['INCOME_PER_PERSON'] = apps['AMT_INCOME_TOTAL'] / apps['CNT_FAM_MEMBERS']\n    apps['ANNUITY_INCOME_PERC'] = apps['AMT_ANNUITY'] / (1 + apps['AMT_INCOME_TOTAL'])\n\n    apps['APPS_CREDIT_GOODS'] = apps['AMT_CREDIT'] / apps['AMT_GOODS_PRICE']\n    apps['APPS_CREDIT_MINUS_GOODS'] = apps['AMT_CREDIT'] - apps['AMT_GOODS_PRICE']\n    apps['reg_div_publish'] = apps['DAYS_REGISTRATION'] / apps['DAYS_ID_PUBLISH']\n    apps['birth_div_reg'] = apps['DAYS_BIRTH'] / apps['DAYS_REGISTRATION']\n\n    apps['NEW_PHONE_TO_BIRTH_RATIO'] = apps['DAYS_LAST_PHONE_CHANGE'] / apps['DAYS_BIRTH']\n    apps['NEW_PHONE_TO_BIRTH_RATIO_EMPLOYER'] = apps['DAYS_LAST_PHONE_CHANGE'] / apps['DAYS_EMPLOYED']\n    \n    apps['APPS_EXT_SOURCE_MEAN'] = apps[['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3']].mean(axis=1)\n    apps['APPS_EXT_SOURCE_STD'] = apps[['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3']].std(axis=1)\n    apps['APPS_EXT_SOURCE_STD'] = apps['APPS_EXT_SOURCE_STD'].fillna(apps['APPS_EXT_SOURCE_STD'].mean())\n    \n    # AMT_ANNUITY - amount should be paid per month.\n    # AMT_CREDIT  - total amount of loan.\n    # AMT_GOODS_PRICE : consumer loadn.eg) car purchase installment.\n    apps['APPS_ANNUITY_CREDIT_RATIO'] = apps['AMT_ANNUITY']/apps['AMT_CREDIT']\n    apps['APPS_GOODS_CREDIT_RATIO'] = apps['AMT_GOODS_PRICE']/apps['AMT_CREDIT']\n    \n    # AMT_INCOME_TOTAL : income \n    # CNT_FAM_MEMBERS  : the number of family members\n    apps['APPS_ANNUITY_INCOME_RATIO'] = apps['AMT_ANNUITY']/apps['AMT_INCOME_TOTAL']\n    apps['APPS_CREDIT_INCOME_RATIO'] = apps['AMT_CREDIT']/apps['AMT_INCOME_TOTAL']\n    apps['APPS_GOODS_INCOME_RATIO'] = apps['AMT_GOODS_PRICE']/apps['AMT_INCOME_TOTAL']\n    apps['APPS_CNT_FAM_INCOME_RATIO'] = apps['AMT_INCOME_TOTAL']/apps['CNT_FAM_MEMBERS']\n    \n    # DAYS_BIRTH : Client's age in days at the time of application\n    # DAYS_EMPLOYED : How many days before the application the person started current employment\n    apps['APPS_EMPLOYED_BIRTH_RATIO'] = apps['DAYS_EMPLOYED']/apps['DAYS_BIRTH']\n    apps['APPS_INCOME_EMPLOYED_RATIO'] = apps['AMT_INCOME_TOTAL']/apps['DAYS_EMPLOYED']\n    apps['APPS_INCOME_BIRTH_RATIO'] = apps['AMT_INCOME_TOTAL']/apps['DAYS_BIRTH']\n    apps['APPS_CAR_BIRTH_RATIO'] = apps['OWN_CAR_AGE'] / apps['DAYS_BIRTH']\n    apps['APPS_CAR_EMPLOYED_RATIO'] = apps['OWN_CAR_AGE'] / apps['DAYS_EMPLOYED']\n    \n    return apps","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def all_infomation_gathering(application_train, POS_CASH_balance, bureau, bureau_balance, credit_card_balance, installments_payments, previous_application):\n    # POS_CASH_balance\n    POS_CASH_balance_new = pd.merge(application_train[['SK_ID_CURR']], POS_CASH_balance, how='inner', on='SK_ID_CURR')\n    POS_CASH_balance_new = POS_CASH_balance_preprocessing(POS_CASH_balance_new)\n    # bureau\n    bureau_new = pd.merge(application_train[['SK_ID_CURR']], bureau, how='inner', on='SK_ID_CURR')\n    bureau_total = bureau_preprocessing(bureau_new, bureau_balance)\n    # credit card balance\n    credit_card_balance_new = pd.merge(application_train[['SK_ID_CURR']], credit_card_balance, how='inner', on='SK_ID_CURR')\n    credit_card_balance_new = credit_card_balance_preprocessing(credit_card_balance)\n    # installments_payments\n    installments_payments_new = pd.merge(application_train[['SK_ID_CURR']], installments_payments, how='inner', on='SK_ID_CURR')\n    installments_payments_new = installments_payments_preprocessing(installments_payments_new)\n    # previous_application\n    previous_application_new = pd.merge(application_train[['SK_ID_CURR']], previous_application, how='inner', on='SK_ID_CURR')\n    previous_application_new = previous_application_preprocessing(previous_application_new)\n    # application train|test\n    application_train_new = application_preprocessing(application_train)\n    \n    # Join data\n    apps_all = pd.merge(application_train_new, previous_application_new, how = 'left', on = 'SK_ID_CURR')\n    apps_all = pd.merge(apps_all, installments_payments_new, how = 'left', on = 'SK_ID_CURR')\n    apps_all = pd.merge(apps_all, credit_card_balance_new,  how = 'left', on = 'SK_ID_CURR')\n    apps_all = pd.merge(apps_all, POS_CASH_balance_new,  how = 'left', on = 'SK_ID_CURR')\n    apps_all = pd.merge(apps_all, bureau_total,  how = 'left', on = 'SK_ID_CURR')\n    \n    # Remove string columns\n    apps_all = apps_all[apps_all.columns[apps_all.dtypes != 'object']]\n    \n    return apps_all","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Import data","metadata":{}},{"cell_type":"code","source":"application_train = pd.read_csv('/kaggle/input/home-credit-default-risk/application_train.csv')\napplication_test = pd.read_csv('/kaggle/input/home-credit-default-risk/application_test.csv')\nbureau = pd.read_csv('/kaggle/input/home-credit-default-risk/bureau.csv')\nbureau_balance = pd.read_csv('/kaggle/input/home-credit-default-risk/bureau_balance.csv')\nPOS_CASH_balance = pd.read_csv('/kaggle/input/home-credit-default-risk/POS_CASH_balance.csv')\ncredit_card_balance = pd.read_csv('/kaggle/input/home-credit-default-risk/credit_card_balance.csv')\nprevious_application = pd.read_csv('/kaggle/input/home-credit-default-risk/previous_application.csv')\ninstallments_payments = pd.read_csv('/kaggle/input/home-credit-default-risk/installments_payments.csv')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Print data structure","metadata":{}},{"cell_type":"code","source":"print(\"application_train\")\ndata_description(application_train)\nprint()\nprint(\"application_test\")\ndata_description(application_test)\nprint()\nprint(\"bureau\")\ndata_description(bureau)\nprint()\nprint(\"bureau_balance\")\ndata_description(bureau_balance)\nprint()\nprint(\"POS_CASH_balance\")\ndata_description(POS_CASH_balance)\nprint()\nprint(\"credit_card_balance\")\ndata_description(credit_card_balance)\nprint()\nprint(\"previous_application\")\ndata_description(previous_application)\nprint()\nprint(\"installments_payments\")\ndata_description(installments_payments)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Combine data","metadata":{}},{"cell_type":"code","source":"apps_all_train = all_infomation_gathering(application_train, POS_CASH_balance, bureau, bureau_balance, credit_card_balance, installments_payments, previous_application)\napps_all_test = all_infomation_gathering(application_test, POS_CASH_balance, bureau, bureau_balance, credit_card_balance, installments_payments, previous_application)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Slicing data","metadata":{}},{"cell_type":"markdown","source":"Extract 40% of the orginal data for training models","metadata":{}},{"cell_type":"code","source":"X = apps_all_train.drop('TARGET', axis=1)\ny = apps_all_train['TARGET']\n\n# Create an instance of StratifiedShuffleSplit\nsss = StratifiedShuffleSplit(n_splits=1, test_size=0.4, random_state=42)\n\n# Generate the splits and extract the stratified sample\nfor train_index, test_index in sss.split(X, y):\n    X_strat_sample, y_strat_sample = X.iloc[test_index], y.iloc[test_index]\n\n# Save this to output working space\napps_train = X_strat_sample.copy()\napps_train[\"TARGET\"] = y_strat_sample","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Principal Component Analysis","metadata":{}},{"cell_type":"code","source":"def PCA_data_processing(df, random_state, drop_columns_arr, target_col, PCA_var_explain, n_components, apps_all_test):\n    # deal with missing data\n  df = df.replace([np.inf, -np.inf], np.nan)\n\n  ftr_app = df.drop(drop_columns_arr, axis=1)  # feature dateset\n  target_app = df[target_col]                  # target datasets\n\n  # Get the correlation matrix\n  corr_matrix = ftr_app.corr()\n  # Find the pairs of columns that are perfectly correlated\n  correlated_columns = corr_matrix.where(corr_matrix >= 0.7).dropna(axis=1)\n  # Remove the correlated columns\n  ftr_app = ftr_app.drop(correlated_columns.columns, axis=1)\n\n  if not correlated_columns.empty:\n    # Remove the correlated columns\n    ftr_app = ftr_app.drop(correlated_columns.columns, axis=1)\n\n  # Fill NaN with median value\n  ftr_app = ftr_app.fillna(-999)\n\n  # Extract the matrix from the DataFrame\n  matrix = ftr_app.values\n\n  # Find the rank of the matrix\n  rank = np.linalg.matrix_rank(matrix)\n\n  # Perform PCA on the data\n  pca = PCA()\n  pca.fit(ftr_app)\n  print()\n  print(\"Explained variance ratio:\")\n  plt.plot(np.cumsum(pca.explained_variance_ratio_))\n  plt.xlabel('number of components for red')\n  plt.ylabel('cumlative explained variance')\n\n  number_of_PCs = 0\n  for i in np.cumsum(pca.explained_variance_ratio_):\n    if i < PCA_var_explain: \n      number_of_PCs += 1\n    if i >= PCA_var_explain:\n      print(i)\n      break\n\n  # Standardize the features\n  scaler = StandardScaler()\n  normalized_train_dataset = scaler.fit_transform(ftr_app)\n  if n_components is not None:\n    pca = PCA(n_components=n_components)\n  else:\n    pca = PCA(n_components=number_of_PCs)\n  X_pca = pca.fit_transform(normalized_train_dataset)\n\n  # Get the transformed dataset\n  X_pca = pd.DataFrame(X_pca)\n  print(\"Size X_pca: \")\n  print(X_pca.shape)\n    \n  X_test = apps_all_test.loc[:, apps_all_test.columns != 'SK_ID_CURR']\n  \n  X_test = X_test.drop(correlated_columns.columns, axis=1)\n\n  if not correlated_columns.empty:\n    # Remove the correlated columns\n    X_test = X_test.drop(correlated_columns.columns, axis=1)\n\n  # deal with missing data\n  X_test = X_test.replace([np.inf, -np.inf], np.nan)\n  X_test = X_test.fillna(-999)\n  \n  normalized_dataset_test = scaler.transform(X_test)\n  X_pca_test = pca.transform(normalized_dataset_test)\n\n  # Get the transformed dataset\n  X_pca_test = pd.DataFrame(X_pca_test)\n    \n  return ftr_app, target_app, X_pca, X_pca_test","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Save output\nftr_app, target_app, X_pca, X_pca_test = PCA_data_processing(df = apps_train, random_state = 10, drop_columns_arr=['TARGET', 'SK_ID_CURR'], target_col='TARGET', PCA_var_explain=0.99999, n_components=170, apps_all_test=apps_all_test)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Popular ML Algorithms","metadata":{}},{"cell_type":"markdown","source":"## Logistic Regression with PCA","metadata":{}},{"cell_type":"markdown","source":"### K-Fold Cross-Validation","metadata":{}},{"cell_type":"code","source":"# No resampling method\ndef KFold_LogisticReg_model(ftr_app, target_app, X_pca, X_pca_test, df, nfolds, random_state, drop_columns_arr, target_col, PCA_var_explain, n_components, apps_all_test):\n  # Data Frame\n  df_off_preds = pd.DataFrame()\n  df_off_preds['SK_ID_CURR'] = df['SK_ID_CURR']\n  \n  # KFold\n  folds = KFold(n_splits = nfolds, shuffle=True, random_state = random_state)\n\n  clf = LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n                           intercept_scaling=1, max_iter=5000, multi_class='ovr', n_jobs=1,\n                           penalty='l1', random_state=None, solver='saga', tol=0.0001,\n                           verbose=0, warm_start=False)\n  \n  oof_preds_proba = np.zeros(X_pca.shape[0])\n  auc_scores = []\n\n  for fold_idx, (train_idx , valid_idx) in enumerate(folds.split(ftr_app)):\n        print(\"# iteration\", fold_idx, 'starts')\n        train_x = X_pca.iloc[train_idx, :]\n        train_y = target_app.iloc[train_idx]\n        valid_x = X_pca.iloc[valid_idx, :]\n        valid_y = target_app.iloc[valid_idx]\n        \n        # Fit Model\n        clf.fit(train_x, train_y)\n\n        # Save predicted proba labels for validation set\n        oof_preds_proba[valid_idx] = clf.predict_proba(valid_x)[:, 1]\n\n        # compute AUC on validation set\n        auc_score = roc_auc_score(valid_y, oof_preds_proba[valid_idx])\n        auc_scores.append(auc_score)\n        print(f\"AUC: {auc_score}\")\n\n  print(f\"Mean AUC: {np.mean(auc_scores):.5f}\")  \n\n  df_off_preds['TARGET'] = oof_preds_proba\n\n  # calculate p-values\n  X2 = sm.add_constant(X_pca)\n  target_app_arr = np.array(target_app)\n  est = sm.Logit(target_app_arr, X2)\n  est2 = est.fit()\n  print(est2.summary())\n\n  # app test \n  res = pd.DataFrame()\n  res[\"SK_ID_CURR\"] = apps_all_test[\"SK_ID_CURR\"]\n\n  y_pred_test = clf.predict_proba(X_pca_test)[:, 1]\n  res[\"TARGET\"] = y_pred_test\n  \n  return df_off_preds, clf, res","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Save output for evaluation and submission\ndf_off_preds, clf, res = KFold_LogisticReg_model(ftr_app=ftr_app, target_app=target_app, X_pca=X_pca, X_pca_test=X_pca_test, df=apps_train, nfolds=5, random_state = 10, drop_columns_arr=['TARGET', 'SK_ID_CURR'], target_col='TARGET', PCA_var_explain=0.99999, n_components=170, apps_all_test=apps_all_test)\ndf_off_preds.to_csv(\"/kaggle/working/KFold_LogisticRegression_train.csv\", index=False)\nres.to_csv(\"/kaggle/working/KFold_LogisticRegression_test.csv\", index=False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Random Over Sampling\ndef KFold_ROS_LogisticReg_model(ftr_app, target_app, X_pca, X_pca_test, df, nfolds, random_state, drop_columns_arr, target_col, PCA_var_explain, n_components, apps_all_test):\n  # Data Frame\n  df_off_preds = pd.DataFrame()\n  df_off_preds['SK_ID_CURR'] = df['SK_ID_CURR']\n  \n  # KFold\n  folds = KFold(n_splits = nfolds, shuffle=True, random_state = random_state)\n\n  clf = LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n                           intercept_scaling=1, max_iter=5000, multi_class='ovr', n_jobs=1,\n                           penalty='l1', random_state=None, solver='saga', tol=0.0001,\n                           verbose=0, warm_start=False)\n  \n  oof_preds_proba = np.zeros(X_pca.shape[0])\n  auc_scores = []\n  # ROS\n  ros = RandomOverSampler()\n\n  for fold_idx, (train_idx , valid_idx) in enumerate(folds.split(ftr_app)):\n        print(\"# iteration\", fold_idx, 'starts')\n        train_x = X_pca.iloc[train_idx, :]\n        train_y = target_app.iloc[train_idx]\n        valid_x = X_pca.iloc[valid_idx, :]\n        valid_y = target_app.iloc[valid_idx]\n\n        train_x_resampled, train_y_resampled = ros.fit_resample(train_x, train_y)\n        \n        # Fit ROS\n        clf.fit(train_x_resampled, train_y_resampled)\n\n        # Save predicted proba labels for validation set\n        oof_preds_proba[valid_idx] = clf.predict_proba(valid_x)[:, 1]\n\n        # compute AUC on validation set\n        auc_score = roc_auc_score(valid_y, oof_preds_proba[valid_idx])\n        auc_scores.append(auc_score)\n        print(f\"AUC: {auc_score}\")\n\n  print(f\"Mean AUC: {np.mean(auc_scores):.5f}\")  \n\n  df_off_preds['TARGET'] = oof_preds_proba\n\n  # calculate p-values\n  X2 = sm.add_constant(X_pca)\n  target_app_arr = np.array(target_app)\n  est = sm.Logit(target_app_arr, X2)\n  est2 = est.fit()\n  print(est2.summary())\n\n  # app test \n  res = pd.DataFrame()\n  res[\"SK_ID_CURR\"] = apps_all_test[\"SK_ID_CURR\"]\n\n  y_pred_test = clf.predict_proba(X_pca_test)[:, 1]\n  res[\"TARGET\"] = y_pred_test\n  \n  return df_off_preds, clf, res","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Save output for evaluation and submission\ndf_off_preds, clf, res = KFold_ROS_LogisticReg_model(ftr_app=ftr_app, target_app=target_app, X_pca=X_pca, X_pca_test=X_pca_test, df=apps_train, nfolds=5, random_state = 10, drop_columns_arr=['TARGET', 'SK_ID_CURR'], target_col='TARGET', PCA_var_explain=0.99999, n_components=170, apps_all_test=apps_all_test)\ndf_off_preds.to_csv(\"/kaggle/working/KFold_ROS_LogisticRegression_train.csv\", index=False)\nres.to_csv(\"/kaggle/working/KFold_ROS_LogisticRegression_test.csv\", index=False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Random Under Sampling\ndef KFold_RUS_LogisticReg_model(ftr_app, target_app, X_pca, X_pca_test, df, nfolds, random_state, drop_columns_arr, target_col, PCA_var_explain, n_components, apps_all_test):\n  # Data Frame\n  df_off_preds = pd.DataFrame()\n  df_off_preds['SK_ID_CURR'] = df['SK_ID_CURR']\n  \n  # KFold\n  folds = KFold(n_splits = nfolds, shuffle=True, random_state = random_state)\n\n  clf = LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n                           intercept_scaling=1, max_iter=5000, multi_class='ovr', n_jobs=1,\n                           penalty='l1', random_state=None, solver='saga', tol=0.0001,\n                           verbose=0, warm_start=False)\n  \n  oof_preds_proba = np.zeros(X_pca.shape[0])\n  auc_scores = []\n  # RUS\n  rus = RandomUnderSampler(random_state = 42)\n\n  for fold_idx, (train_idx , valid_idx) in enumerate(folds.split(ftr_app)):\n        print(\"# iteration\", fold_idx, 'starts')\n        train_x = X_pca.iloc[train_idx, :]\n        train_y = target_app.iloc[train_idx]\n        valid_x = X_pca.iloc[valid_idx, :]\n        valid_y = target_app.iloc[valid_idx]\n\n        train_x_resampled, train_y_resampled = rus.fit_resample(train_x, train_y)\n        \n        # Fit RUS\n        clf.fit(train_x_resampled, train_y_resampled)\n\n        # Save predicted proba labels for validation set\n        oof_preds_proba[valid_idx] = clf.predict_proba(valid_x)[:, 1]\n\n        # compute AUC on validation set\n        auc_score = roc_auc_score(valid_y, oof_preds_proba[valid_idx])\n        auc_scores.append(auc_score)\n        print(f\"AUC: {auc_score}\")\n\n  print(f\"Mean AUC: {np.mean(auc_scores):.5f}\")  \n\n  df_off_preds['TARGET'] = oof_preds_proba\n\n  # calculate p-values\n  X2 = sm.add_constant(X_pca)\n  target_app_arr = np.array(target_app)\n  est = sm.Logit(target_app_arr, X2)\n  est2 = est.fit()\n  print(est2.summary())\n\n  # app test \n  res = pd.DataFrame()\n  res[\"SK_ID_CURR\"] = apps_all_test[\"SK_ID_CURR\"]\n\n  y_pred_test = clf.predict_proba(X_pca_test)[:, 1]\n  res[\"TARGET\"] = y_pred_test\n  \n  return df_off_preds, clf, res","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Save output for evaluation and submission\ndf_off_preds, clf, res = KFold_RUS_LogisticReg_model(ftr_app=ftr_app, target_app=target_app, X_pca=X_pca, X_pca_test=X_pca_test, df=apps_train, nfolds=5, random_state = 10, drop_columns_arr=['TARGET', 'SK_ID_CURR'], target_col='TARGET', PCA_var_explain=0.99999, n_components=170, apps_all_test=apps_all_test)\ndf_off_preds.to_csv(\"/kaggle/working/KFold_RUS_LogisticRegression_train.csv\", index=False)\nres.to_csv(\"/kaggle/working/KFold_RUS_LogisticRegression_test.csv\", index=False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# SMOTE\ndef KFold_SMOTE_LogisticReg_model(ftr_app, target_app, X_pca, X_pca_test, df, nfolds, random_state, drop_columns_arr, target_col, PCA_var_explain, n_components, apps_all_test):\n  # Data Frame\n  df_off_preds = pd.DataFrame()\n  df_off_preds['SK_ID_CURR'] = df['SK_ID_CURR']\n  \n  # KFold\n  folds = KFold(n_splits = nfolds, shuffle=True, random_state = random_state)\n\n  clf = LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n                           intercept_scaling=1, max_iter=5000, multi_class='ovr', n_jobs=1,\n                           penalty='l1', random_state=None, solver='saga', tol=0.0001,\n                           verbose=0, warm_start=False)\n  \n  oof_preds_proba = np.zeros(X_pca.shape[0])\n  auc_scores = []\n  # SMOTE\n  smote = SMOTE()\n\n  for fold_idx, (train_idx , valid_idx) in enumerate(folds.split(ftr_app)):\n        print(\"# iteration\", fold_idx, 'starts')\n        train_x = X_pca.iloc[train_idx, :]\n        train_y = target_app.iloc[train_idx]\n        valid_x = X_pca.iloc[valid_idx, :]\n        valid_y = target_app.iloc[valid_idx]\n\n        train_x_resampled, train_y_resampled = smote.fit_resample(train_x, train_y)\n        \n        # Fit SMOTE\n        clf.fit(train_x_resampled, train_y_resampled)\n\n        # Save predicted proba labels for validation set\n        oof_preds_proba[valid_idx] = clf.predict_proba(valid_x)[:, 1]\n\n        # compute AUC on validation set\n        auc_score = roc_auc_score(valid_y, oof_preds_proba[valid_idx])\n        auc_scores.append(auc_score)\n        print(f\"AUC: {auc_score}\")\n\n  print(f\"Mean AUC: {np.mean(auc_scores):.5f}\")  \n\n  df_off_preds['TARGET'] = oof_preds_proba\n\n  # calculate p-values\n  X2 = sm.add_constant(X_pca)\n  target_app_arr = np.array(target_app)\n  est = sm.Logit(target_app_arr, X2)\n  est2 = est.fit()\n  print(est2.summary())\n\n  # app test \n  res = pd.DataFrame()\n  res[\"SK_ID_CURR\"] = apps_all_test[\"SK_ID_CURR\"]\n\n  y_pred_test = clf.predict_proba(X_pca_test)[:, 1]\n  res[\"TARGET\"] = y_pred_test\n  \n  return df_off_preds, clf, res","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Save output for evaluation and submission\ndf_off_preds, clf, res = KFold_SMOTE_LogisticReg_model(ftr_app=ftr_app, target_app=target_app, X_pca=X_pca, X_pca_test=X_pca_test, df=apps_train, nfolds=5, random_state = 10, drop_columns_arr=['TARGET', 'SK_ID_CURR'], target_col='TARGET', PCA_var_explain=0.99999, n_components=170, apps_all_test=apps_all_test)\ndf_off_preds.to_csv(\"/kaggle/working/KFold_SMOTE_LogisticRegression_train.csv\", index=False)\nres.to_csv(\"/kaggle/working/KFold_SMOTE_LogisticRegression_test.csv\", index=False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Stratified K-Fold Cross-Validation","metadata":{}},{"cell_type":"code","source":"# No resampling method\ndef StratifiedKFold_LogisticReg_model(ftr_app, target_app, X_pca, X_pca_test, df, nfolds, random_state, drop_columns_arr, target_col, PCA_var_explain, n_components, apps_all_test):\n  # Data Frame\n  df_off_preds = pd.DataFrame()\n  df_off_preds['SK_ID_CURR'] = df['SK_ID_CURR']\n  \n  # StratifiedKFold\n  folds = StratifiedKFold(n_splits = nfolds, shuffle=True, random_state = random_state)\n\n  clf = LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n                           intercept_scaling=1, max_iter=5000, multi_class='ovr', n_jobs=1,\n                           penalty='l1', random_state=None, solver='saga', tol=0.0001,\n                           verbose=0, warm_start=False)\n  \n  oof_preds_proba = np.zeros(X_pca.shape[0])\n  auc_scores = []\n\n  for fold_idx, (train_idx , valid_idx) in enumerate(folds.split(ftr_app, target_app)):\n        print(\"# iteration\", fold_idx, 'starts')\n        train_x = X_pca.iloc[train_idx, :]\n        train_y = target_app.iloc[train_idx]\n        valid_x = X_pca.iloc[valid_idx, :]\n        valid_y = target_app.iloc[valid_idx]\n        \n        # Fit Model\n        clf.fit(train_x, train_y)\n\n        # Save predicted proba labels for validation set\n        oof_preds_proba[valid_idx] = clf.predict_proba(valid_x)[:, 1]\n\n        # compute AUC on validation set\n        auc_score = roc_auc_score(valid_y, oof_preds_proba[valid_idx])\n        auc_scores.append(auc_score)\n        print(f\"AUC: {auc_score}\")\n\n  print(f\"Mean AUC: {np.mean(auc_scores):.5f}\")  \n\n  df_off_preds['TARGET'] = oof_preds_proba\n\n  # calculate p-values\n  X2 = sm.add_constant(X_pca)\n  target_app_arr = np.array(target_app)\n  est = sm.Logit(target_app_arr, X2)\n  est2 = est.fit()\n  print(est2.summary())\n\n  # app test \n  res = pd.DataFrame()\n  res[\"SK_ID_CURR\"] = apps_all_test[\"SK_ID_CURR\"]\n\n  y_pred_test = clf.predict_proba(X_pca_test)[:, 1]\n  res[\"TARGET\"] = y_pred_test\n  \n  return df_off_preds, clf, res","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Save output for evaluation and submission\ndf_off_preds, clf, res = StratifiedKFold_LogisticReg_model(ftr_app=ftr_app, target_app=target_app, X_pca=X_pca, X_pca_test=X_pca_test, df=apps_train, nfolds=5, random_state = 10, drop_columns_arr=['TARGET', 'SK_ID_CURR'], target_col='TARGET', PCA_var_explain=0.99999, n_components=170, apps_all_test=apps_all_test)\ndf_off_preds.to_csv(\"/kaggle/working/StratifiedKFold_LogisticRegression_train.csv\", index=False)\nres.to_csv(\"/kaggle/working/StratifiedKFold_LogisticRegression_test.csv\", index=False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Random Over Sampling\ndef StratifiedKFold_ROS_LogisticReg_model(ftr_app, target_app, X_pca, X_pca_test, df, nfolds, random_state, drop_columns_arr, target_col, PCA_var_explain, n_components, apps_all_test):\n  # Data Frame\n  df_off_preds = pd.DataFrame()\n  df_off_preds['SK_ID_CURR'] = df['SK_ID_CURR']\n  \n  # Stratified KFold\n  folds = StratifiedKFold(n_splits = nfolds, shuffle=True, random_state = random_state)\n\n  clf = LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n                           intercept_scaling=1, max_iter=5000, multi_class='ovr', n_jobs=1,\n                           penalty='l1', random_state=None, solver='saga', tol=0.0001,\n                           verbose=0, warm_start=False)\n  \n  oof_preds_proba = np.zeros(X_pca.shape[0])\n  auc_scores = []\n  # ROS\n  ros = RandomOverSampler()\n\n  for fold_idx, (train_idx , valid_idx) in enumerate(folds.split(ftr_app, target_app)):\n        print(\"# iteration\", fold_idx, 'starts')\n        train_x = X_pca.iloc[train_idx, :]\n        train_y = target_app.iloc[train_idx]\n        valid_x = X_pca.iloc[valid_idx, :]\n        valid_y = target_app.iloc[valid_idx]\n\n        train_x_resampled, train_y_resampled = ros.fit_resample(train_x, train_y)\n        \n        # Fit ROS\n        clf.fit(train_x_resampled, train_y_resampled)\n\n        # Save predicted proba labels for validation set\n        oof_preds_proba[valid_idx] = clf.predict_proba(valid_x)[:, 1]\n\n        # compute AUC on validation set\n        auc_score = roc_auc_score(valid_y, oof_preds_proba[valid_idx])\n        auc_scores.append(auc_score)\n        print(f\"AUC: {auc_score}\")\n\n  print(f\"Mean AUC: {np.mean(auc_scores):.5f}\")  \n\n  df_off_preds['TARGET'] = oof_preds_proba\n\n  # calculate p-values\n  X2 = sm.add_constant(X_pca)\n  target_app_arr = np.array(target_app)\n  est = sm.Logit(target_app_arr, X2)\n  est2 = est.fit()\n  print(est2.summary())\n\n  # app test \n  res = pd.DataFrame()\n  res[\"SK_ID_CURR\"] = apps_all_test[\"SK_ID_CURR\"]\n\n  y_pred_test = clf.predict_proba(X_pca_test)[:, 1]\n  res[\"TARGET\"] = y_pred_test\n  \n  return df_off_preds, clf, res","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Save output for evaluation and submission\ndf_off_preds, clf, res = StratifiedKFold_ROS_LogisticReg_model(ftr_app=ftr_app, target_app=target_app, X_pca=X_pca, X_pca_test=X_pca_test, df=apps_train, nfolds=5, random_state = 10, drop_columns_arr=['TARGET', 'SK_ID_CURR'], target_col='TARGET', PCA_var_explain=0.99999, n_components=170, apps_all_test=apps_all_test)\ndf_off_preds.to_csv(\"/kaggle/working/StratifiedKFold_ROS_LogisticRegression_train.csv\", index=False)\nres.to_csv(\"/kaggle/working/StratifiedKFold_ROS_LogisticRegression_test.csv\", index=False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Random Under Sampling\ndef StratifiedKFold_RUS_LogisticReg_model(ftr_app, target_app, X_pca, X_pca_test, df, nfolds, random_state, drop_columns_arr, target_col, PCA_var_explain, n_components, apps_all_test):\n  # Data Frame\n  df_off_preds = pd.DataFrame()\n  df_off_preds['SK_ID_CURR'] = df['SK_ID_CURR']\n  \n  # StratifiedKFold\n  folds = StratifiedKFold(n_splits = nfolds, shuffle=True, random_state = random_state)\n\n  clf = LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n                           intercept_scaling=1, max_iter=5000, multi_class='ovr', n_jobs=1,\n                           penalty='l1', random_state=None, solver='saga', tol=0.0001,\n                           verbose=0, warm_start=False)\n  \n  oof_preds_proba = np.zeros(X_pca.shape[0])\n  auc_scores = []\n  # RUS\n  rus = RandomUnderSampler(random_state=42)\n\n  for fold_idx, (train_idx , valid_idx) in enumerate(folds.split(ftr_app, target_app)):\n        print(\"# iteration\", fold_idx, 'starts')\n        train_x = X_pca.iloc[train_idx, :]\n        train_y = target_app.iloc[train_idx]\n        valid_x = X_pca.iloc[valid_idx, :]\n        valid_y = target_app.iloc[valid_idx]\n\n        train_x_resampled, train_y_resampled = rus.fit_resample(train_x, train_y)\n        \n        # Fit RUS\n        clf.fit(train_x_resampled, train_y_resampled)\n\n        # Save predicted proba labels for validation set\n        oof_preds_proba[valid_idx] = clf.predict_proba(valid_x)[:, 1]\n\n        # compute AUC on validation set\n        auc_score = roc_auc_score(valid_y, oof_preds_proba[valid_idx])\n        auc_scores.append(auc_score)\n        print(f\"AUC: {auc_score}\")\n\n  print(f\"Mean AUC: {np.mean(auc_scores):.5f}\")  \n\n  df_off_preds['TARGET'] = oof_preds_proba\n\n  # calculate p-values\n  X2 = sm.add_constant(X_pca)\n  target_app_arr = np.array(target_app)\n  est = sm.Logit(target_app_arr, X2)\n  est2 = est.fit()\n  print(est2.summary())\n\n  # app test \n  res = pd.DataFrame()\n  res[\"SK_ID_CURR\"] = apps_all_test[\"SK_ID_CURR\"]\n\n  y_pred_test = clf.predict_proba(X_pca_test)[:, 1]\n  res[\"TARGET\"] = y_pred_test\n  \n  return df_off_preds, clf, res","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Save output for evaluation and submission\ndf_off_preds, clf, res = StratifiedKFold_RUS_LogisticReg_model(ftr_app=ftr_app, target_app=target_app, X_pca=X_pca, X_pca_test=X_pca_test, df=apps_train, nfolds=5, random_state = 10, drop_columns_arr=['TARGET', 'SK_ID_CURR'], target_col='TARGET', PCA_var_explain=0.99999, n_components=170, apps_all_test=apps_all_test)\ndf_off_preds.to_csv(\"/kaggle/working/StratifiedKFold_RUS_LogisticRegression_train.csv\", index=False)\nres.to_csv(\"/kaggle/working/StratifiedKFold_RUS_LogisticRegression_test.csv\", index=False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# SMOTE\ndef StratifiedKFold_SMOTE_LogisticReg_model(ftr_app, target_app, X_pca, X_pca_test, df, nfolds, random_state, drop_columns_arr, target_col, PCA_var_explain, n_components, apps_all_test):\n  # Data Frame\n  df_off_preds = pd.DataFrame()\n  df_off_preds['SK_ID_CURR'] = df['SK_ID_CURR']\n  \n  # StratifiedKFold\n  folds = StratifiedKFold(n_splits = nfolds, shuffle=True, random_state = random_state)\n\n  clf = LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n                           intercept_scaling=1, max_iter=5000, multi_class='ovr', n_jobs=1,\n                           penalty='l1', random_state=None, solver='saga', tol=0.0001,\n                           verbose=0, warm_start=False)\n  \n  oof_preds_proba = np.zeros(X_pca.shape[0])\n  auc_scores = []\n  # SMOTE\n  smote = SMOTE()\n\n  for fold_idx, (train_idx , valid_idx) in enumerate(folds.split(ftr_app, target_app)):\n        print(\"# iteration\", fold_idx, 'starts')\n        train_x = X_pca.iloc[train_idx, :]\n        train_y = target_app.iloc[train_idx]\n        valid_x = X_pca.iloc[valid_idx, :]\n        valid_y = target_app.iloc[valid_idx]\n\n        train_x_resampled, train_y_resampled = smote.fit_resample(train_x, train_y)\n        \n        # Fit SMOTE\n        clf.fit(train_x_resampled, train_y_resampled)\n\n        # Save predicted proba labels for validation set\n        oof_preds_proba[valid_idx] = clf.predict_proba(valid_x)[:, 1]\n\n        # compute AUC on validation set\n        auc_score = roc_auc_score(valid_y, oof_preds_proba[valid_idx])\n        auc_scores.append(auc_score)\n        print(f\"AUC: {auc_score}\")\n\n  print(f\"Mean AUC: {np.mean(auc_scores):.5f}\")  \n\n  df_off_preds['TARGET'] = oof_preds_proba\n\n  # calculate p-values\n  X2 = sm.add_constant(X_pca)\n  target_app_arr = np.array(target_app)\n  est = sm.Logit(target_app_arr, X2)\n  est2 = est.fit()\n  print(est2.summary())\n\n  # app test \n  res = pd.DataFrame()\n  res[\"SK_ID_CURR\"] = apps_all_test[\"SK_ID_CURR\"]\n\n  y_pred_test = clf.predict_proba(X_pca_test)[:, 1]\n  res[\"TARGET\"] = y_pred_test\n  \n  return df_off_preds, clf, res","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Save output for evaluation and submission\ndf_off_preds, clf, res = StratifiedKFold_SMOTE_LogisticReg_model(ftr_app=ftr_app, target_app=target_app, X_pca=X_pca, X_pca_test=X_pca_test, df=apps_train, nfolds=5, random_state = 10, drop_columns_arr=['TARGET', 'SK_ID_CURR'], target_col='TARGET', PCA_var_explain=0.99999, n_components=170, apps_all_test=apps_all_test)\ndf_off_preds.to_csv(\"/kaggle/working/StratifiedKFold_SMOTE_LogisticRegression_train.csv\", index=False)\nres.to_csv(\"/kaggle/working/StratifiedKFold_SMOTE_LogisticRegression_test.csv\", index=False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## $k$-Nearest Neighbors","metadata":{}},{"cell_type":"markdown","source":"### K-Fold Cross-Validation","metadata":{}},{"cell_type":"code","source":"# No resampling method\ndef KFold_kNN_model(df, nfolds, random_state, drop_columns_arr, target_col, apps_all_test):\n    df_off_preds = pd.DataFrame()\n    df_off_preds['SK_ID_CURR'] = df['SK_ID_CURR']\n\n    # deal with missing data\n    df = df.replace([np.inf, -np.inf], np.nan)\n    # Fill NaN with median value\n    df = df.fillna(-999)\n\n    ftr_app = df.drop(drop_columns_arr, axis=1)  # feature dateset\n    target_app = df[target_col]                  # target datasets\n    # apply KFolds\n    folds = KFold(n_splits = nfolds, shuffle=True, random_state = random_state)\n    \n    oof_preds_proba = np.zeros(ftr_app.shape[0])\n    auc_scores = []\n\n    clf = KNeighborsClassifier(n_neighbors=5, metric='euclidean')\n    \n    for fold_idx, (train_idx , valid_idx) in enumerate(folds.split(ftr_app, target_app)):\n        print(\"# iteration\", fold_idx, 'starts')\n        train_x = ftr_app.iloc[train_idx, :]\n        train_y = target_app.iloc[train_idx]\n        valid_x = ftr_app.iloc[valid_idx, :]\n        valid_y = target_app.iloc[valid_idx]\n\n        clf.fit(train_x, train_y)\n        # Save predicted proba labels for validation set\n        oof_preds_proba[valid_idx] = clf.predict_proba(valid_x)[:, 1]\n\n        # compute AUC on validation set\n        auc_score = roc_auc_score(valid_y, oof_preds_proba[valid_idx])\n        auc_scores.append(auc_score)\n        print(f\"AUC: {auc_score}\")\n\n    print(f\"Mean AUC: {np.mean(auc_scores):.5f}\")\n\n    df_off_preds['TARGET'] = oof_preds_proba\n\n    # apps_all_test \n    df_test = apps_all_test.copy()\n    test_res = pd.DataFrame()\n    # save SK_ID_CURR\n    test_res[\"SK_ID_CURR\"]=df_test[\"SK_ID_CURR\"]\n    # deal with missing value\n    df_test = df_test.replace([np.inf, -np.inf], np.nan)\n    # fill NaN with median value\n    df_test = df_test.fillna(-999)\n  \n    X_apps_test = df_test.drop(\"SK_ID_CURR\", axis=1)\n\n    y_apps_test = clf.predict_proba(X_apps_test)\n    test_res[f\"TARGET\"] = y_apps_test[:, 1]\n\n    return df_off_preds, clf, test_res","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_off_preds, clf, test_res = KFold_kNN_model(df=apps_train, nfolds=5, random_state=10, drop_columns_arr=['TARGET', 'SK_ID_CURR'], target_col='TARGET', apps_all_test=apps_all_test)\ndf_off_preds.to_csv(\"/kaggle/working/KFold_kNN_train.csv\", index=False)\ntest_res.to_csv(\"/kaggle/working/KFold_kNN_test.csv\", index=False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Random Over Sampling\ndef KFold_ROS_kNN_model(df, nfolds, random_state, drop_columns_arr, target_col, apps_all_test):\n    df_off_preds = pd.DataFrame()\n    df_off_preds['SK_ID_CURR'] = df['SK_ID_CURR']\n\n    # deal with missing data\n    df = df.replace([np.inf, -np.inf], np.nan)\n    # Fill NaN with median value\n    df = df.fillna(-999)\n\n    ftr_app = df.drop(drop_columns_arr, axis=1)  # feature dateset\n    target_app = df[target_col]                  # target datasets\n    # apply KFolds\n    folds = KFold(n_splits = nfolds, shuffle=True, random_state = random_state)\n    \n    oof_preds_proba = np.zeros(ftr_app.shape[0])\n    auc_scores = []\n\n    clf = KNeighborsClassifier(n_neighbors=5, metric='euclidean')\n    # ROS\n    ros = RandomOverSampler()\n    \n    for fold_idx, (train_idx , valid_idx) in enumerate(folds.split(ftr_app, target_app)):\n        print(\"# iteration\", fold_idx, 'starts')\n        train_x = ftr_app.iloc[train_idx, :]\n        train_y = target_app.iloc[train_idx]\n        valid_x = ftr_app.iloc[valid_idx, :]\n        valid_y = target_app.iloc[valid_idx]\n        \n        train_x_resampled, train_y_resampled = ros.fit_resample(train_x, train_y)\n\n        clf.fit(train_x_resampled, train_y_resampled)\n        # Save predicted proba labels for validation set\n        oof_preds_proba[valid_idx] = clf.predict_proba(valid_x)[:, 1]\n\n        # compute AUC on validation set\n        auc_score = roc_auc_score(valid_y, oof_preds_proba[valid_idx])\n        auc_scores.append(auc_score)\n        print(f\"AUC: {auc_score}\")\n\n    print(f\"Mean AUC: {np.mean(auc_scores):.5f}\")\n\n    df_off_preds['TARGET'] = oof_preds_proba\n\n    # apps_all_test \n    df_test = apps_all_test.copy()\n    test_res = pd.DataFrame()\n    # save SK_ID_CURR\n    test_res[\"SK_ID_CURR\"]=df_test[\"SK_ID_CURR\"]\n    # deal with missing value\n    df_test = df_test.replace([np.inf, -np.inf], np.nan)\n    # fill NaN with median value\n    df_test = df_test.fillna(-999)\n  \n    X_apps_test = df_test.drop(\"SK_ID_CURR\", axis=1)\n\n    y_apps_test = clf.predict_proba(X_apps_test)\n    test_res[f\"TARGET\"] = y_apps_test[:, 1]\n\n    return df_off_preds, clf, test_res","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_off_preds, clf, test_res = KFold_ROS_kNN_model(df=apps_train, nfolds=5, random_state=10, drop_columns_arr=['TARGET', 'SK_ID_CURR'], target_col='TARGET', apps_all_test=apps_all_test)\ndf_off_preds.to_csv(\"/kaggle/working/KFold_ROS_kNN_train.csv\", index=False)\ntest_res.to_csv(\"/kaggle/working/KFold_ROS_kNN_test.csv\", index=False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Random Under Sampling\ndef KFold_RUS_kNN_model(df, nfolds, random_state, drop_columns_arr, target_col, apps_all_test):\n    df_off_preds = pd.DataFrame()\n    df_off_preds['SK_ID_CURR'] = df['SK_ID_CURR']\n\n    # deal with missing data\n    df = df.replace([np.inf, -np.inf], np.nan)\n    # Fill NaN with median value\n    df = df.fillna(-999)\n\n    ftr_app = df.drop(drop_columns_arr, axis=1)  # feature dateset\n    target_app = df[target_col]                  # target datasets\n    # apply KFolds\n    folds = KFold(n_splits = nfolds, shuffle=True, random_state = random_state)\n    \n    oof_preds_proba = np.zeros(ftr_app.shape[0])\n    auc_scores = []\n\n    clf = KNeighborsClassifier(n_neighbors=5, metric='euclidean')\n    # RUS\n    rus = RandomUnderSampler(random_state=42)\n    \n    for fold_idx, (train_idx , valid_idx) in enumerate(folds.split(ftr_app, target_app)):\n        print(\"# iteration\", fold_idx, 'starts')\n        train_x = ftr_app.iloc[train_idx, :]\n        train_y = target_app.iloc[train_idx]\n        valid_x = ftr_app.iloc[valid_idx, :]\n        valid_y = target_app.iloc[valid_idx]\n        \n        train_x_resampled, train_y_resampled = rus.fit_resample(train_x, train_y)\n\n        clf.fit(train_x_resampled, train_y_resampled)\n        # Save predicted proba labels for validation set\n        oof_preds_proba[valid_idx] = clf.predict_proba(valid_x)[:, 1]\n\n        # compute AUC on validation set\n        auc_score = roc_auc_score(valid_y, oof_preds_proba[valid_idx])\n        auc_scores.append(auc_score)\n        print(f\"AUC: {auc_score}\")\n\n    print(f\"Mean AUC: {np.mean(auc_scores):.5f}\")\n\n    df_off_preds['TARGET'] = oof_preds_proba\n\n    # apps_all_test \n    df_test = apps_all_test.copy()\n    test_res = pd.DataFrame()\n    # save SK_ID_CURR\n    test_res[\"SK_ID_CURR\"]=df_test[\"SK_ID_CURR\"]\n    # deal with missing value\n    df_test = df_test.replace([np.inf, -np.inf], np.nan)\n    # fill NaN with median value\n    df_test = df_test.fillna(-999)\n  \n    X_apps_test = df_test.drop(\"SK_ID_CURR\", axis=1)\n\n    y_apps_test = clf.predict_proba(X_apps_test)\n    test_res[f\"TARGET\"] = y_apps_test[:, 1]\n\n    return df_off_preds, clf, test_res","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_off_preds, clf, test_res = KFold_RUS_kNN_model(df=apps_train, nfolds=5, random_state=10, drop_columns_arr=['TARGET', 'SK_ID_CURR'], target_col='TARGET', apps_all_test=apps_all_test)\ndf_off_preds.to_csv(\"/kaggle/working/KFold_RUS_kNN_train.csv\", index=False)\ntest_res.to_csv(\"/kaggle/working/KFold_RUS_kNN_test.csv\", index=False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# SMOTE\ndef KFold_SMOTE_kNN_model(df, nfolds, random_state, drop_columns_arr, target_col, apps_all_test):\n    df_off_preds = pd.DataFrame()\n    df_off_preds['SK_ID_CURR'] = df['SK_ID_CURR']\n\n    # deal with missing data\n    df = df.replace([np.inf, -np.inf], np.nan)\n    # Fill NaN with median value\n    df = df.fillna(-999)\n\n    ftr_app = df.drop(drop_columns_arr, axis=1)  # feature dateset\n    target_app = df[target_col]                  # target datasets\n    # apply KFolds\n    folds = KFold(n_splits = nfolds, shuffle=True, random_state = random_state)\n    \n    oof_preds_proba = np.zeros(ftr_app.shape[0])\n    auc_scores = []\n\n    clf = KNeighborsClassifier(n_neighbors=5, metric='euclidean')\n    # SMOTE\n    smote = SMOTE()\n    \n    for fold_idx, (train_idx , valid_idx) in enumerate(folds.split(ftr_app, target_app)):\n        print(\"# iteration\", fold_idx, 'starts')\n        train_x = ftr_app.iloc[train_idx, :]\n        train_y = target_app.iloc[train_idx]\n        valid_x = ftr_app.iloc[valid_idx, :]\n        valid_y = target_app.iloc[valid_idx]\n        \n        train_x_resampled, train_y_resampled = smote.fit_resample(train_x, train_y)\n\n        clf.fit(train_x_resampled, train_y_resampled)\n        # Save predicted proba labels for validation set\n        oof_preds_proba[valid_idx] = clf.predict_proba(valid_x)[:, 1]\n\n        # compute AUC on validation set\n        auc_score = roc_auc_score(valid_y, oof_preds_proba[valid_idx])\n        auc_scores.append(auc_score)\n        print(f\"AUC: {auc_score}\")\n\n    print(f\"Mean AUC: {np.mean(auc_scores):.5f}\")\n\n    df_off_preds['TARGET'] = oof_preds_proba\n\n    # apps_all_test \n    df_test = apps_all_test.copy()\n    test_res = pd.DataFrame()\n    # save SK_ID_CURR\n    test_res[\"SK_ID_CURR\"]=df_test[\"SK_ID_CURR\"]\n    # deal with missing value\n    df_test = df_test.replace([np.inf, -np.inf], np.nan)\n    # fill NaN with median value\n    df_test = df_test.fillna(-999)\n  \n    X_apps_test = df_test.drop(\"SK_ID_CURR\", axis=1)\n\n    y_apps_test = clf.predict_proba(X_apps_test)\n    test_res[f\"TARGET\"] = y_apps_test[:, 1]\n\n    return df_off_preds, clf, test_res","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_off_preds, clf, test_res = KFold_SMOTE_kNN_model(df=apps_train, nfolds=5, random_state=10, drop_columns_arr=['TARGET', 'SK_ID_CURR'], target_col='TARGET', apps_all_test=apps_all_test)\ndf_off_preds.to_csv(\"/kaggle/working/KFold_SMOTE_kNN_train.csv\", index=False)\ntest_res.to_csv(\"/kaggle/working/KFold_SMOTE_kNN_test.csv\", index=False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Stratified K-Fold Cross-Validation","metadata":{}},{"cell_type":"code","source":"# No resampling method\ndef StratifiedKFold_kNN_model(df, nfolds, random_state, drop_columns_arr, target_col, apps_all_test):\n    df_off_preds = pd.DataFrame()\n    df_off_preds['SK_ID_CURR'] = df['SK_ID_CURR']\n\n    # deal with missing data\n    df = df.replace([np.inf, -np.inf], np.nan)\n    # Fill NaN with median value\n    df = df.fillna(-999)\n\n    ftr_app = df.drop(drop_columns_arr, axis=1)  # feature dateset\n    target_app = df[target_col]                  # target datasets\n    # apply Stratified KFold\n    folds = StratifiedKFold(n_splits = nfolds, shuffle=True, random_state = random_state)\n    \n    oof_preds_proba = np.zeros(ftr_app.shape[0])\n    auc_scores = []\n\n    clf = KNeighborsClassifier(n_neighbors=5, metric='euclidean')\n    \n    for fold_idx, (train_idx , valid_idx) in enumerate(folds.split(ftr_app, target_app)):\n        print(\"# iteration\", fold_idx, 'starts')\n        train_x = ftr_app.iloc[train_idx, :]\n        train_y = target_app.iloc[train_idx]\n        valid_x = ftr_app.iloc[valid_idx, :]\n        valid_y = target_app.iloc[valid_idx]\n\n        clf.fit(train_x, train_y)\n        # Save predicted proba labels for validation set\n        oof_preds_proba[valid_idx] = clf.predict_proba(valid_x)[:, 1]\n\n        # compute AUC on validation set\n        auc_score = roc_auc_score(valid_y, oof_preds_proba[valid_idx])\n        auc_scores.append(auc_score)\n        print(f\"AUC: {auc_score}\")\n\n    print(f\"Mean AUC: {np.mean(auc_scores):.5f}\")\n\n    df_off_preds['KFold_RF_AUC_PROBA'] = oof_preds_proba\n\n    # apps_all_test \n    df_test = apps_all_test.copy()\n    test_res = pd.DataFrame()\n    # save SK_ID_CURR\n    test_res[\"SK_ID_CURR\"]=df_test[\"SK_ID_CURR\"]\n    # deal with missing value\n    df_test = df_test.replace([np.inf, -np.inf], np.nan)\n    # fill NaN with median value\n    df_test = df_test.fillna(-999)\n  \n    X_apps_test = df_test.drop(\"SK_ID_CURR\", axis=1)\n\n    y_apps_test = clf.predict_proba(X_apps_test)\n    test_res[f\"TARGET\"] = y_apps_test[:, 1]\n\n    return df_off_preds, clf, test_res","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_off_preds, clf, test_res = StratifiedKFold_kNN_model(df=apps_train, nfolds=5, random_state=10, drop_columns_arr=['TARGET', 'SK_ID_CURR'], target_col='TARGET', apps_all_test=apps_all_test)\ndf_off_preds.to_csv(\"/kaggle/working/StratifiedKFold_kNN_train.csv\", index=False)\ntest_res.to_csv(\"/kaggle/working/StratifiedKFold_kNN_test.csv\", index=False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Random Over Sampling\ndef StratifiedKFold_ROS_kNN_model(df, nfolds, random_state, drop_columns_arr, target_col, apps_all_test):\n    df_off_preds = pd.DataFrame()\n    df_off_preds['SK_ID_CURR'] = df['SK_ID_CURR']\n\n    # deal with missing data\n    df = df.replace([np.inf, -np.inf], np.nan)\n    # Fill NaN with median value\n    df = df.fillna(-999)\n\n    ftr_app = df.drop(drop_columns_arr, axis=1)  # feature dateset\n    target_app = df[target_col]                  # target datasets\n    # apply Stratified KFold\n    folds = StratifiedKFold(n_splits = nfolds, shuffle=True, random_state = random_state)\n    \n    oof_preds_proba = np.zeros(ftr_app.shape[0])\n    auc_scores = []\n\n    clf = KNeighborsClassifier(n_neighbors=5, metric='euclidean')\n    # ROS\n    ros = RandomOverSampler()\n    \n    for fold_idx, (train_idx , valid_idx) in enumerate(folds.split(ftr_app, target_app)):\n        print(\"# iteration\", fold_idx, 'starts')\n        train_x = ftr_app.iloc[train_idx, :]\n        train_y = target_app.iloc[train_idx]\n        valid_x = ftr_app.iloc[valid_idx, :]\n        valid_y = target_app.iloc[valid_idx]\n        \n        train_x_resampled, train_y_resampled = ros.fit_resample(train_x, train_y)\n\n        clf.fit(train_x_resampled, train_y_resampled)\n        # Save predicted proba labels for validation set\n        oof_preds_proba[valid_idx] = clf.predict_proba(valid_x)[:, 1]\n\n        # compute AUC on validation set\n        auc_score = roc_auc_score(valid_y, oof_preds_proba[valid_idx])\n        auc_scores.append(auc_score)\n        print(f\"AUC: {auc_score}\")\n\n    print(f\"Mean AUC: {np.mean(auc_scores):.5f}\")\n\n    df_off_preds['KFold_RF_AUC_PROBA'] = oof_preds_proba\n\n    # apps_all_test \n    df_test = apps_all_test.copy()\n    test_res = pd.DataFrame()\n    # save SK_ID_CURR\n    test_res[\"SK_ID_CURR\"]=df_test[\"SK_ID_CURR\"]\n    # deal with missing value\n    df_test = df_test.replace([np.inf, -np.inf], np.nan)\n    # fill NaN with median value\n    df_test = df_test.fillna(-999)\n  \n    X_apps_test = df_test.drop(\"SK_ID_CURR\", axis=1)\n\n    y_apps_test = clf.predict_proba(X_apps_test)\n    test_res[f\"TARGET\"] = y_apps_test[:, 1]\n\n    return df_off_preds, clf, test_res","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_off_preds, clf, test_res = StratifiedKFold_ROS_kNN_model(df=apps_train, nfolds=5, random_state=10, drop_columns_arr=['TARGET', 'SK_ID_CURR'], target_col='TARGET', apps_all_test=apps_all_test)\ndf_off_preds.to_csv(\"/kaggle/working/StratifiedKFold_ROS_kNN_train.csv\", index=False)\ntest_res.to_csv(\"/kaggle/working/StratifiedKFold_ROS_kNN_test.csv\", index=False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Random Under Sampling\ndef StratifiedKFold_RUS_kNN_model(df, nfolds, random_state, drop_columns_arr, target_col, apps_all_test):\n    df_off_preds = pd.DataFrame()\n    df_off_preds['SK_ID_CURR'] = df['SK_ID_CURR']\n\n    # deal with missing data\n    df = df.replace([np.inf, -np.inf], np.nan)\n    # Fill NaN with median value\n    df = df.fillna(-999)\n\n    ftr_app = df.drop(drop_columns_arr, axis=1)  # feature dateset\n    target_app = df[target_col]                  # target datasets\n    # apply Stratified KFold\n    folds = StratifiedKFold(n_splits = nfolds, shuffle=True, random_state = random_state)\n    \n    oof_preds_proba = np.zeros(ftr_app.shape[0])\n    auc_scores = []\n\n    clf = KNeighborsClassifier(n_neighbors=5, metric='euclidean')\n    # RUS\n    rus = RandomUnderSampler(random_state=42)\n    \n    for fold_idx, (train_idx , valid_idx) in enumerate(folds.split(ftr_app, target_app)):\n        print(\"# iteration\", fold_idx, 'starts')\n        train_x = ftr_app.iloc[train_idx, :]\n        train_y = target_app.iloc[train_idx]\n        valid_x = ftr_app.iloc[valid_idx, :]\n        valid_y = target_app.iloc[valid_idx]\n        \n        train_x_resampled, train_y_resampled = rus.fit_resample(train_x, train_y)\n\n        clf.fit(train_x_resampled, train_y_resampled)\n        # Save predicted proba labels for validation set\n        oof_preds_proba[valid_idx] = clf.predict_proba(valid_x)[:, 1]\n\n        # compute AUC on validation set\n        auc_score = roc_auc_score(valid_y, oof_preds_proba[valid_idx])\n        auc_scores.append(auc_score)\n        print(f\"AUC: {auc_score}\")\n\n    print(f\"Mean AUC: {np.mean(auc_scores):.5f}\")\n\n    df_off_preds['KFold_RF_AUC_PROBA'] = oof_preds_proba\n\n    # apps_all_test \n    df_test = apps_all_test.copy()\n    test_res = pd.DataFrame()\n    # save SK_ID_CURR\n    test_res[\"SK_ID_CURR\"]=df_test[\"SK_ID_CURR\"]\n    # deal with missing value\n    df_test = df_test.replace([np.inf, -np.inf], np.nan)\n    # fill NaN with median value\n    df_test = df_test.fillna(-999)\n  \n    X_apps_test = df_test.drop(\"SK_ID_CURR\", axis=1)\n\n    y_apps_test = clf.predict_proba(X_apps_test)\n    test_res[f\"TARGET\"] = y_apps_test[:, 1]\n\n    return df_off_preds, clf, test_res","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_off_preds, clf, test_res = StratifiedKFold_RUS_kNN_model(df=apps_train, nfolds=5, random_state=10, drop_columns_arr=['TARGET', 'SK_ID_CURR'], target_col='TARGET', apps_all_test=apps_all_test)\ndf_off_preds.to_csv(\"/kaggle/working/StratifiedKFold_RUS_kNN_train.csv\", index=False)\ntest_res.to_csv(\"/kaggle/working/StratifiedKFold_RUS_kNN_test.csv\", index=False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# SMOTE\ndef StratifiedKFold_SMOTE_kNN_model(df, nfolds, random_state, drop_columns_arr, target_col, apps_all_test):\n    df_off_preds = pd.DataFrame()\n    df_off_preds['SK_ID_CURR'] = df['SK_ID_CURR']\n\n    # deal with missing data\n    df = df.replace([np.inf, -np.inf], np.nan)\n    # Fill NaN with median value\n    df = df.fillna(-999)\n\n    ftr_app = df.drop(drop_columns_arr, axis=1)  # feature dateset\n    target_app = df[target_col]                  # target datasets\n    # apply Stratified KFold\n    folds = StratifiedKFold(n_splits = nfolds, shuffle=True, random_state = random_state)\n    \n    oof_preds_proba = np.zeros(ftr_app.shape[0])\n    auc_scores = []\n\n    clf = KNeighborsClassifier(n_neighbors=5, metric='euclidean')\n    # SMOTE\n    smote = SMOTE()\n    \n    for fold_idx, (train_idx , valid_idx) in enumerate(folds.split(ftr_app, target_app)):\n        print(\"# iteration\", fold_idx, 'starts')\n        train_x = ftr_app.iloc[train_idx, :]\n        train_y = target_app.iloc[train_idx]\n        valid_x = ftr_app.iloc[valid_idx, :]\n        valid_y = target_app.iloc[valid_idx]\n        \n        train_x_resampled, train_y_resampled = smote.fit_resample(train_x, train_y)\n\n        clf.fit(train_x_resampled, train_y_resampled)\n        # Save predicted proba labels for validation set\n        oof_preds_proba[valid_idx] = clf.predict_proba(valid_x)[:, 1]\n\n        # compute AUC on validation set\n        auc_score = roc_auc_score(valid_y, oof_preds_proba[valid_idx])\n        auc_scores.append(auc_score)\n        print(f\"AUC: {auc_score}\")\n\n    print(f\"Mean AUC: {np.mean(auc_scores):.5f}\")\n\n    df_off_preds['KFold_RF_AUC_PROBA'] = oof_preds_proba\n\n    # apps_all_test \n    df_test = apps_all_test.copy()\n    test_res = pd.DataFrame()\n    # save SK_ID_CURR\n    test_res[\"SK_ID_CURR\"]=df_test[\"SK_ID_CURR\"]\n    # deal with missing value\n    df_test = df_test.replace([np.inf, -np.inf], np.nan)\n    # fill NaN with median value\n    df_test = df_test.fillna(-999)\n  \n    X_apps_test = df_test.drop(\"SK_ID_CURR\", axis=1)\n\n    y_apps_test = clf.predict_proba(X_apps_test)\n    test_res[f\"TARGET\"] = y_apps_test[:, 1]\n\n    return df_off_preds, clf, test_res","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_off_preds, clf, test_res = StratifiedKFold_SMOTE_kNN_model(df=apps_train, nfolds=5, random_state=10, drop_columns_arr=['TARGET', 'SK_ID_CURR'], target_col='TARGET', apps_all_test=apps_all_test)\ndf_off_preds.to_csv(\"/kaggle/working/StratifiedKFold_SMOTE_kNN_train.csv\", index=False)\ntest_res.to_csv(\"/kaggle/working/StratifiedKFold_SMOTE_kNN_test.csv\", index=False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Support Vector Machines","metadata":{}},{"cell_type":"markdown","source":"### K-Fold Cross-Validation","metadata":{}},{"cell_type":"code","source":"# No resampling method\ndef KFold_SVM_model(df, nfolds, random_state, drop_columns_arr, target_col, apps_all_test):\n    df_off_preds = pd.DataFrame()\n    df_off_preds['SK_ID_CURR'] = df['SK_ID_CURR']\n\n    # deal with missing data\n    df = df.replace([np.inf, -np.inf], np.nan)\n    # Fill NaN with median value\n    df = df.fillna(-999)\n\n    ftr_app = df.drop(drop_columns_arr, axis=1)  # feature dateset\n    target_app = df[target_col]                  # target datasets\n    # apply KFolds\n    folds = KFold(n_splits = nfolds, shuffle=True, random_state = random_state)\n    \n    oof_preds_proba = np.zeros(ftr_app.shape[0])\n    auc_scores = []\n\n    clf = SVC(kernel='rbf', probability=True)\n    \n    for fold_idx, (train_idx , valid_idx) in enumerate(folds.split(ftr_app)):\n        print(\"# iteration\", fold_idx, 'starts')\n        train_x = ftr_app.iloc[train_idx, :]\n        train_y = target_app.iloc[train_idx]\n        valid_x = ftr_app.iloc[valid_idx, :]\n        valid_y = target_app.iloc[valid_idx]\n\n        clf.fit(train_x, train_y)\n        # Save predicted proba labels for validation set\n        oof_preds_proba[valid_idx] = clf.predict(valid_x)\n\n        # compute AUC on validation set\n        auc_score = roc_auc_score(valid_y, oof_preds_proba[valid_idx])\n        auc_scores.append(auc_score)\n        print(f\"AUC: {auc_score}\")\n\n    print(f\"Mean AUC: {np.mean(auc_scores):.5f}\")\n\n    df_off_preds['TARGET'] = oof_preds_proba\n\n    # apps_all_test \n    df_test = apps_all_test.copy()\n    test_res = pd.DataFrame()\n    # save SK_ID_CURR\n    test_res[\"SK_ID_CURR\"]=df_test[\"SK_ID_CURR\"]\n    # deal with missing value\n    df_test = df_test.replace([np.inf, -np.inf], np.nan)\n    # fill NaN with median value\n    df_test = df_test.fillna(-999)\n  \n    X_apps_test = df_test.drop(\"SK_ID_CURR\", axis=1)\n\n    y_apps_test = clf.predict(X_apps_test)\n    test_res[f\"TARGET\"] = y_apps_test\n\n    return df_off_preds, clf, test_res","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_off_preds, clf, test_res = KFold_SVM_model(df=apps_train, nfolds=5, random_state=10, drop_columns_arr=['TARGET', 'SK_ID_CURR'], target_col='TARGET', apps_all_test=apps_all_test)\ndf_off_preds.to_csv(\"/kaggle/working/KFold_SVM_train.csv\", index=False)\ntest_res.to_csv(\"/kaggle/working/KFold_SVM_test.csv\", index=False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Random Under Sampling\ndef KFold_RUS_SVM_model(df, nfolds, random_state, drop_columns_arr, target_col, apps_all_test):\n    df_off_preds = pd.DataFrame()\n    df_off_preds['SK_ID_CURR'] = df['SK_ID_CURR']\n\n    # deal with missing data\n    df = df.replace([np.inf, -np.inf], np.nan)\n    # Fill NaN with median value\n    df = df.fillna(-999)\n\n    ftr_app = df.drop(drop_columns_arr, axis=1)  # feature dateset\n    target_app = df[target_col]                  # target datasets\n    # apply KFolds\n    folds = KFold(n_splits = nfolds, shuffle=True, random_state = random_state)\n    \n    oof_preds_proba = np.zeros(ftr_app.shape[0])\n    auc_scores = []\n\n    clf = SVC(kernel='rbf', probability=True)\n    rus = RandomUnderSampler(random_state=42)\n    \n    for fold_idx, (train_idx , valid_idx) in enumerate(folds.split(ftr_app, target_app)):\n        print(\"# iteration\", fold_idx, 'starts')\n        train_x = ftr_app.iloc[train_idx, :]\n        train_y = target_app.iloc[train_idx]\n        valid_x = ftr_app.iloc[valid_idx, :]\n        valid_y = target_app.iloc[valid_idx]\n        \n        train_x_resampled, train_y_resampled = rus.fit_resample(train_x, train_y)\n\n        clf.fit(train_x_resampled, train_y_resampled)\n        # Save predicted proba labels for validation set\n        oof_preds_proba[valid_idx] = clf.predict_proba(valid_x)[:,1]\n\n        # compute AUC on validation set\n        auc_score = roc_auc_score(valid_y, oof_preds_proba[valid_idx])\n        auc_scores.append(auc_score)\n        print(f\"AUC: {auc_score}\")\n\n    print(f\"Mean AUC: {np.mean(auc_scores):.5f}\")\n\n    df_off_preds['TARGET'] = oof_preds_proba\n\n    # apps_all_test \n    df_test = apps_all_test.copy()\n    test_res = pd.DataFrame()\n    # save SK_ID_CURR\n    test_res[\"SK_ID_CURR\"]=df_test[\"SK_ID_CURR\"]\n    # deal with missing value\n    df_test = df_test.replace([np.inf, -np.inf], np.nan)\n    # fill NaN with median value\n    df_test = df_test.fillna(-999)\n  \n    X_apps_test = df_test.drop(\"SK_ID_CURR\", axis=1)\n\n    y_apps_test = clf.predict_proba(X_apps_test)[:,1]\n    test_res[f\"TARGET\"] = y_apps_test\n\n    return df_off_preds, clf, test_res","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_off_preds, clf, test_res = KFold_RUS_SVM_model(df=apps_train, nfolds=5, random_state=10, drop_columns_arr=['TARGET', 'SK_ID_CURR'], target_col='TARGET', apps_all_test=apps_all_test)\ndf_off_preds.to_csv(\"/kaggle/working/KFold_RUS_SVM_train.csv\", index=False)\ntest_res.to_csv(\"/kaggle/working/KFold_RUS_SVM_test.csv\", index=False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Stratified K-Fold Cross-Validation","metadata":{}},{"cell_type":"code","source":"# No resampling method\ndef StratifiedKFold_SVM_model(df, nfolds, random_state, drop_columns_arr, target_col, apps_all_test):\n    df_off_preds = pd.DataFrame()\n    df_off_preds['SK_ID_CURR'] = df['SK_ID_CURR']\n\n    # deal with missing data\n    df = df.replace([np.inf, -np.inf], np.nan)\n    # Fill NaN with median value\n    df = df.fillna(-999)\n\n    ftr_app = df.drop(drop_columns_arr, axis=1)  # feature dateset\n    target_app = df[target_col]                  # target datasets\n    # apply Stratified KFold\n    folds = StratifiedKFold(n_splits = nfolds, shuffle=True, random_state = random_state)\n    \n    oof_preds_proba = np.zeros(ftr_app.shape[0])\n    auc_scores = []\n\n    clf = SVC(kernel='rbf', probability=True)\n    \n    for fold_idx, (train_idx , valid_idx) in enumerate(folds.split(ftr_app, target_app)):\n        print(\"# iteration\", fold_idx, 'starts')\n        train_x = ftr_app.iloc[train_idx, :]\n        train_y = target_app.iloc[train_idx]\n        valid_x = ftr_app.iloc[valid_idx, :]\n        valid_y = target_app.iloc[valid_idx]\n\n        clf.fit(train_x, train_y)\n        # Save predicted proba labels for validation set\n        oof_preds_proba[valid_idx] = clf.predict(valid_x)\n\n        # compute AUC on validation set\n        auc_score = roc_auc_score(valid_y, oof_preds_proba[valid_idx])\n        auc_scores.append(auc_score)\n        print(f\"AUC: {auc_score}\")\n\n    print(f\"Mean AUC: {np.mean(auc_scores):.5f}\")\n\n    df_off_preds['TARGET'] = oof_preds_proba\n\n    # apps_all_test \n    df_test = apps_all_test.copy()\n    test_res = pd.DataFrame()\n    # save SK_ID_CURR\n    test_res[\"SK_ID_CURR\"]=df_test[\"SK_ID_CURR\"]\n    # deal with missing value\n    df_test = df_test.replace([np.inf, -np.inf], np.nan)\n    # fill NaN with median value\n    df_test = df_test.fillna(-999)\n  \n    X_apps_test = df_test.drop(\"SK_ID_CURR\", axis=1)\n\n    y_apps_test = clf.predict(X_apps_test)\n    test_res[f\"TARGET\"] = y_apps_test\n\n    return df_off_preds, clf, test_res","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_off_preds, clf, test_res = StratifiedKFold_SVM_model(df=apps_train, nfolds=5, random_state=10, drop_columns_arr=['TARGET', 'SK_ID_CURR'], target_col='TARGET', apps_all_test=apps_all_test)\ndf_off_preds.to_csv(\"/kaggle/working/StratifiedKFold_SVM_train.csv\", index=False)\ntest_res.to_csv(\"/kaggle/working/StratifiedKFold_SVM_test.csv\", index=False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Random Under Sampling\ndef StratifiedKFold_RUS_SVM_model(df, nfolds, random_state, drop_columns_arr, target_col, apps_all_test):\n    df_off_preds = pd.DataFrame()\n    df_off_preds['SK_ID_CURR'] = df['SK_ID_CURR']\n\n    # deal with missing data\n    df = df.replace([np.inf, -np.inf], np.nan)\n    # Fill NaN with median value\n    df = df.fillna(-999)\n\n    ftr_app = df.drop(drop_columns_arr, axis=1)  # feature dateset\n    target_app = df[target_col]                  # target datasets\n    # apply Stratified KFold\n    folds = StratifiedKFold(n_splits = nfolds, shuffle=True, random_state = random_state)\n    \n    oof_preds_proba = np.zeros(ftr_app.shape[0])\n    auc_scores = []\n\n    clf = SVC(kernel='rbf', probability=True)\n    rus = RandomUnderSampler(random_state=42)\n    \n    for fold_idx, (train_idx , valid_idx) in enumerate(folds.split(ftr_app, target_app)):\n        print(\"# iteration\", fold_idx, 'starts')\n        train_x = ftr_app.iloc[train_idx, :]\n        train_y = target_app.iloc[train_idx]\n        valid_x = ftr_app.iloc[valid_idx, :]\n        valid_y = target_app.iloc[valid_idx]\n        \n        train_x_resampled, train_y_resampled = rus.fit_resample(train_x, train_y)\n\n        clf.fit(train_x_resampled, train_y_resampled)\n        # Save predicted proba labels for validation set\n        oof_preds_proba[valid_idx] = clf.predict_proba(valid_x)[:,1]\n\n        # compute AUC on validation set\n        auc_score = roc_auc_score(valid_y, oof_preds_proba[valid_idx])\n        auc_scores.append(auc_score)\n        print(f\"AUC: {auc_score}\")\n\n    print(f\"Mean AUC: {np.mean(auc_scores):.5f}\")\n\n    df_off_preds['TARGET'] = oof_preds_proba\n\n    # apps_all_test \n    df_test = apps_all_test.copy()\n    test_res = pd.DataFrame()\n    # save SK_ID_CURR\n    test_res[\"SK_ID_CURR\"]=df_test[\"SK_ID_CURR\"]\n    # deal with missing value\n    df_test = df_test.replace([np.inf, -np.inf], np.nan)\n    # fill NaN with median value\n    df_test = df_test.fillna(-999)\n  \n    X_apps_test = df_test.drop(\"SK_ID_CURR\", axis=1)\n\n    y_apps_test = clf.predict_proba(X_apps_test)[:,1]\n    test_res[f\"TARGET\"] = y_apps_test\n\n    return df_off_preds, clf, test_res","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_off_preds, clf, test_res = StratifiedKFold_RUS_SVM_model(df=apps_train, nfolds=5, random_state=10, drop_columns_arr=['TARGET', 'SK_ID_CURR'], target_col='TARGET', apps_all_test=apps_all_test)\ndf_off_preds.to_csv(\"/kaggle/working/StratifiedKFold_RUS_SVM_train.csv\", index=False)\ntest_res.to_csv(\"/kaggle/working/StratifiedKFold_RUS_SVM_test.csv\", index=False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Decision Tree","metadata":{}},{"cell_type":"markdown","source":"### K-Fold Cross-Validation","metadata":{}},{"cell_type":"code","source":"# No resampling method\ndef KFold_DecisionTree_model(df, nfolds, random_state, drop_columns_arr, target_col, apps_all_test):\n    df_off_preds = pd.DataFrame()\n    df_off_preds['SK_ID_CURR'] = df['SK_ID_CURR']\n\n    # deal with missing data\n    df = df.replace([np.inf, -np.inf], np.nan)\n    # Fill NaN with median value\n    df = df.fillna(-999)\n\n    ftr_app = df.drop(drop_columns_arr, axis=1)  # feature dateset\n    target_app = df[target_col]                  # target datasets\n    \n    # Initialize the Decision Tree model\n    dt = DecisionTreeClassifier(max_depth=20, random_state=42)\n\n    # Initialize the CalibratedClassifierCV object with the Decision Tree model and 5-fold cross-validation\n    kf = KFold(n_splits=5)\n    calibrated_dt = CalibratedClassifierCV(dt, cv=kf, method='isotonic')\n\n    # Initialize the AUC score\n    auc_scores = []\n\n    # Fit the calibrated model on the data and calculate AUC on the testing data\n    calibrated_dt.fit(ftr_app, target_app)\n\n    # Predict probabilities on the testing data\n    y_pred_prob = calibrated_dt.predict_proba(ftr_app)[:, 1]\n\n    # Calculate the AUC score\n    auc = roc_auc_score(target_app, y_pred_prob)\n    auc_scores.append(auc)\n\n    # Print the mean and standard deviation of the AUC scores across all folds\n    print(f'Mean AUC: {np.mean(auc_scores):.4f}')\n\n    # apps_all_test \n    df_test = apps_all_test.copy()\n    test_res = pd.DataFrame()\n    # save SK_ID_CURR\n    test_res[\"SK_ID_CURR\"]=df_test[\"SK_ID_CURR\"]\n    # deal with missing value\n    df_test = df_test.replace([np.inf, -np.inf], np.nan)\n    # fill NaN with median value\n    df_test = df_test.fillna(-999)\n  \n    X_apps_test = df_test.drop(\"SK_ID_CURR\", axis=1)\n\n    y_apps_test = calibrated_dt.predict_proba(X_apps_test)[:, 1]\n    test_res[f\"TARGET\"] = y_apps_test\n\n    return df_off_preds, test_res","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# isotonic, max_dept = 20\ndf_off_preds, test_res = KFold_DecisionTree_model(df=apps_train, nfolds=5, random_state=10, drop_columns_arr=['TARGET', 'SK_ID_CURR'], target_col='TARGET', apps_all_test=apps_all_test)\ndf_off_preds.to_csv(\"/kaggle/working/KFold_DecisionTree_train.csv\", index = False)\ntest_res.to_csv(\"/kaggle/working/KFold_DecisionTree_test.csv\", index = False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Random Over Sampling\ndef KFold_ROS_DecisionTree_model(df, nfolds, random_state, drop_columns_arr, target_col, apps_all_test):\n    df_off_preds = pd.DataFrame()\n    df_off_preds['SK_ID_CURR'] = df['SK_ID_CURR']\n\n    # deal with missing data\n    df = df.replace([np.inf, -np.inf], np.nan)\n    # Fill NaN with median value\n    df = df.fillna(-999)\n\n    ftr_app = df.drop(drop_columns_arr, axis=1)  # feature dateset\n    target_app = df[target_col]                  # target datasets\n    \n    # ROS\n    ros = RandomOverSampler()\n    ftr_app, target_app = ros.fit_resample(ftr_app, target_app)\n    \n    # Initialize the Decision Tree model\n    dt = DecisionTreeClassifier(max_depth=20, random_state=42)\n\n    # Initialize the CalibratedClassifierCV object with the Decision Tree model and 5-fold cross-validation\n    kf = KFold(n_splits=5)\n    calibrated_dt = CalibratedClassifierCV(dt, cv=kf, method='isotonic')\n\n    # Initialize the AUC score\n    auc_scores = []\n\n    # Fit the calibrated model on the data and calculate AUC on the testing data\n    calibrated_dt.fit(ftr_app, target_app)\n\n    # Predict probabilities on the testing data\n    y_pred_prob = calibrated_dt.predict_proba(ftr_app)[:, 1]\n\n    # Calculate the AUC score\n    auc = roc_auc_score(target_app, y_pred_prob)\n    auc_scores.append(auc)\n\n    # Print the mean and standard deviation of the AUC scores across all folds\n    print(f'Mean AUC: {np.mean(auc_scores):.4f}')\n\n    # apps_all_test \n    df_test = apps_all_test.copy()\n    test_res = pd.DataFrame()\n    # save SK_ID_CURR\n    test_res[\"SK_ID_CURR\"]=df_test[\"SK_ID_CURR\"]\n    # deal with missing value\n    df_test = df_test.replace([np.inf, -np.inf], np.nan)\n    # fill NaN with median value\n    df_test = df_test.fillna(-999)\n  \n    X_apps_test = df_test.drop(\"SK_ID_CURR\", axis=1)\n\n    y_apps_test = calibrated_dt.predict_proba(X_apps_test)[:, 1]\n    test_res[f\"TARGET\"] = y_apps_test\n\n    return df_off_preds, test_res","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# isotonic, max_dept = 20\ndf_off_preds, test_res = KFold_ROS_DecisionTree_model(df=apps_train, nfolds=5, random_state=10, drop_columns_arr=['TARGET', 'SK_ID_CURR'], target_col='TARGET', apps_all_test=apps_all_test)\ndf_off_preds.to_csv(\"/kaggle/working/KFold_ROS_DecisionTree_train.csv\", index = False)\ntest_res.to_csv(\"/kaggle/working/KFold_ROS_DecisionTree_test.csv\", index = False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Random Under Sampling\ndef KFold_RUS_DecisionTree_model(df, nfolds, random_state, drop_columns_arr, target_col, apps_all_test):\n    df_off_preds = pd.DataFrame()\n    df_off_preds['SK_ID_CURR'] = df['SK_ID_CURR']\n\n    # deal with missing data\n    df = df.replace([np.inf, -np.inf], np.nan)\n    # Fill NaN with median value\n    df = df.fillna(-999)\n\n    ftr_app = df.drop(drop_columns_arr, axis=1)  # feature dateset\n    target_app = df[target_col]                  # target datasets\n    \n    # RUS\n    rus = RandomUnderSampler(random_state=42)\n    ftr_app, target_app = rus.fit_resample(ftr_app, target_app)\n    \n    # Initialize the Decision Tree model\n    dt = DecisionTreeClassifier(max_depth=20, random_state=42)\n\n    # Initialize the CalibratedClassifierCV object with the Decision Tree model and 5-fold cross-validation\n    kf = KFold(n_splits=5)\n    calibrated_dt = CalibratedClassifierCV(dt, cv=kf, method='isotonic')\n\n    # Initialize the AUC score\n    auc_scores = []\n\n    # Fit the calibrated model on the data and calculate AUC on the testing data\n    calibrated_dt.fit(ftr_app, target_app)\n\n    # Predict probabilities on the testing data\n    y_pred_prob = calibrated_dt.predict_proba(ftr_app)[:, 1]\n\n    # Calculate the AUC score\n    auc = roc_auc_score(target_app, y_pred_prob)\n    auc_scores.append(auc)\n\n    # Print the mean and standard deviation of the AUC scores across all folds\n    print(f'Mean AUC: {np.mean(auc_scores):.4f}')\n\n    # apps_all_test \n    df_test = apps_all_test.copy()\n    test_res = pd.DataFrame()\n    # save SK_ID_CURR\n    test_res[\"SK_ID_CURR\"]=df_test[\"SK_ID_CURR\"]\n    # deal with missing value\n    df_test = df_test.replace([np.inf, -np.inf], np.nan)\n    # fill NaN with median value\n    df_test = df_test.fillna(-999)\n  \n    X_apps_test = df_test.drop(\"SK_ID_CURR\", axis=1)\n\n    y_apps_test = calibrated_dt.predict_proba(X_apps_test)[:, 1]\n    test_res[f\"TARGET\"] = y_apps_test\n\n    return df_off_preds, test_res","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# isotonic, max_dept = 20\ndf_off_preds, test_res = KFold_RUS_DecisionTree_model(df=apps_train, nfolds=5, random_state=10, drop_columns_arr=['TARGET', 'SK_ID_CURR'], target_col='TARGET', apps_all_test=apps_all_test)\ndf_off_preds.to_csv(\"/kaggle/working/KFold_RUS_DecisionTree_train.csv\", index = False)\ntest_res.to_csv(\"/kaggle/working/KFold_RUS_DecisionTree_test.csv\", index = False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# SMOTE\ndef KFold_SMOTE_DecisionTree_model(df, nfolds, random_state, drop_columns_arr, target_col, apps_all_test):\n    df_off_preds = pd.DataFrame()\n    df_off_preds['SK_ID_CURR'] = df['SK_ID_CURR']\n\n    # deal with missing data\n    df = df.replace([np.inf, -np.inf], np.nan)\n    # Fill NaN with median value\n    df = df.fillna(-999)\n\n    ftr_app = df.drop(drop_columns_arr, axis=1)  # feature dateset\n    target_app = df[target_col]                  # target datasets\n    \n    # SMOTE\n    smote = SMOTE()\n    ftr_app, target_app = smote.fit_resample(ftr_app, target_app)\n    \n    # Initialize the Decision Tree model\n    dt = DecisionTreeClassifier(max_depth=20, random_state=42)\n\n    # Initialize the CalibratedClassifierCV object with the Decision Tree model and 5-fold cross-validation\n    kf = KFold(n_splits=5)\n    calibrated_dt = CalibratedClassifierCV(dt, cv=kf, method='isotonic')\n\n    # Initialize the AUC score\n    auc_scores = []\n\n    # Fit the calibrated model on the data and calculate AUC on the testing data\n    calibrated_dt.fit(ftr_app, target_app)\n\n    # Predict probabilities on the testing data\n    y_pred_prob = calibrated_dt.predict_proba(ftr_app)[:, 1]\n\n    # Calculate the AUC score\n    auc = roc_auc_score(target_app, y_pred_prob)\n    auc_scores.append(auc)\n\n    # Print the mean and standard deviation of the AUC scores across all folds\n    print(f'Mean AUC: {np.mean(auc_scores):.4f}')\n\n    # apps_all_test \n    df_test = apps_all_test.copy()\n    test_res = pd.DataFrame()\n    # save SK_ID_CURR\n    test_res[\"SK_ID_CURR\"]=df_test[\"SK_ID_CURR\"]\n    # deal with missing value\n    df_test = df_test.replace([np.inf, -np.inf], np.nan)\n    # fill NaN with median value\n    df_test = df_test.fillna(-999)\n  \n    X_apps_test = df_test.drop(\"SK_ID_CURR\", axis=1)\n\n    y_apps_test = calibrated_dt.predict_proba(X_apps_test)[:, 1]\n    test_res[f\"TARGET\"] = y_apps_test\n\n    return df_off_preds, test_res","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# isotonic, max_dept = 20\ndf_off_preds, test_res = KFold_SMOTE_DecisionTree_model(df=apps_train, nfolds=5, random_state=10, drop_columns_arr=['TARGET', 'SK_ID_CURR'], target_col='TARGET', apps_all_test=apps_all_test)\ndf_off_preds.to_csv(\"/kaggle/working/KFold_SMOTE_DecisionTree_train.csv\", index = False)\ntest_res.to_csv(\"/kaggle/working/KFold_SMOTE_DecisionTree_test.csv\", index = False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Stratified K-Fold Cross-Validation","metadata":{}},{"cell_type":"code","source":"# No resampling method\ndef StratifiedKFold_DecisionTree_model(df, nfolds, random_state, drop_columns_arr, target_col, apps_all_test):\n    df_off_preds = pd.DataFrame()\n    df_off_preds['SK_ID_CURR'] = df['SK_ID_CURR']\n\n    # deal with missing data\n    df = df.replace([np.inf, -np.inf], np.nan)\n    # Fill NaN with median value\n    df = df.fillna(-999)\n\n    ftr_app = df.drop(drop_columns_arr, axis=1)  # feature dateset\n    target_app = df[target_col]                  # target datasets\n    \n    # Initialize the Decision Tree model\n    dt = DecisionTreeClassifier(max_depth=20, random_state=42)\n\n    # Initialize the CalibratedClassifierCV object with the Decision Tree model and 5-fold cross-validation\n    skf = StratifiedKFold(n_splits=5)\n    calibrated_dt = CalibratedClassifierCV(dt, cv=skf, method='isotonic')\n\n    # Initialize the AUC score\n    auc_scores = []\n\n    # Fit the calibrated model on the data and calculate AUC on the testing data\n    calibrated_dt.fit(ftr_app, target_app)\n\n    # Predict probabilities on the testing data\n    y_pred_prob = calibrated_dt.predict_proba(ftr_app)[:, 1]\n\n    # Calculate the AUC score\n    auc = roc_auc_score(target_app, y_pred_prob)\n    auc_scores.append(auc)\n\n    # Print the mean and standard deviation of the AUC scores across all folds\n    print(f'Mean AUC: {np.mean(auc_scores):.4f}')\n\n    # apps_all_test \n    df_test = apps_all_test.copy()\n    test_res = pd.DataFrame()\n    # save SK_ID_CURR\n    test_res[\"SK_ID_CURR\"]=df_test[\"SK_ID_CURR\"]\n    # deal with missing value\n    df_test = df_test.replace([np.inf, -np.inf], np.nan)\n    # fill NaN with median value\n    df_test = df_test.fillna(-999)\n  \n    X_apps_test = df_test.drop(\"SK_ID_CURR\", axis=1)\n\n    y_apps_test = calibrated_dt.predict_proba(X_apps_test)[:, 1]\n    test_res[f\"TARGET\"] = y_apps_test\n\n    return df_off_preds, test_res","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# isotonic, max_dept = 20\ndf_off_preds, test_res = StratifiedKFold_DecisionTree_model(df=apps_train, nfolds=5, random_state=10, drop_columns_arr=['TARGET', 'SK_ID_CURR'], target_col='TARGET', apps_all_test=apps_all_test)\ndf_off_preds.to_csv(\"/kaggle/working/StratifedKFold_DecisionTree_train.csv\", index = False)\ntest_res.to_csv(\"/kaggle/working/StratifedKFold_DecisionTree_test.csv\", index = False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Random Over Sampling\ndef StratifiedKFold_ROS_DecisionTree_model(df, nfolds, random_state, drop_columns_arr, target_col, apps_all_test):\n    df_off_preds = pd.DataFrame()\n    df_off_preds['SK_ID_CURR'] = df['SK_ID_CURR']\n\n    # deal with missing data\n    df = df.replace([np.inf, -np.inf], np.nan)\n    # Fill NaN with median value\n    df = df.fillna(-999)\n\n    ftr_app = df.drop(drop_columns_arr, axis=1)  # feature dateset\n    target_app = df[target_col]                  # target datasets\n    \n    # ROS\n    ros = RandomOverSampler()\n    ftr_app, target_app = ros.fit_resample(ftr_app, target_app)\n    \n    # Initialize the Decision Tree model\n    dt = DecisionTreeClassifier(max_depth=20, random_state=42)\n\n    # Initialize the CalibratedClassifierCV object with the Decision Tree model and 5-fold cross-validation\n    skf = StratifiedKFold(n_splits=5)\n    calibrated_dt = CalibratedClassifierCV(dt, cv=skf, method='isotonic')\n\n    # Initialize the AUC score\n    auc_scores = []\n\n    # Fit the calibrated model on the data and calculate AUC on the testing data\n    calibrated_dt.fit(ftr_app, target_app)\n\n    # Predict probabilities on the testing data\n    y_pred_prob = calibrated_dt.predict_proba(ftr_app)[:, 1]\n\n    # Calculate the AUC score\n    auc = roc_auc_score(target_app, y_pred_prob)\n    auc_scores.append(auc)\n\n    # Print the mean and standard deviation of the AUC scores across all folds\n    print(f'Mean AUC: {np.mean(auc_scores):.4f}')\n\n    # apps_all_test \n    df_test = apps_all_test.copy()\n    test_res = pd.DataFrame()\n    # save SK_ID_CURR\n    test_res[\"SK_ID_CURR\"]=df_test[\"SK_ID_CURR\"]\n    # deal with missing value\n    df_test = df_test.replace([np.inf, -np.inf], np.nan)\n    # fill NaN with median value\n    df_test = df_test.fillna(-999)\n  \n    X_apps_test = df_test.drop(\"SK_ID_CURR\", axis=1)\n\n    y_apps_test = calibrated_dt.predict_proba(X_apps_test)[:, 1]\n    test_res[f\"TARGET\"] = y_apps_test\n\n    return df_off_preds, test_res","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# isotonic, max_dept = 20\ndf_off_preds, test_res = StratifiedKFold_ROS_DecisionTree_model(df=apps_train, nfolds=5, random_state=10, drop_columns_arr=['TARGET', 'SK_ID_CURR'], target_col='TARGET', apps_all_test=apps_all_test)\ndf_off_preds.to_csv(\"/kaggle/working/StratifiedKFold_ROS_DecisionTree_train.csv\", index = False)\ntest_res.to_csv(\"/kaggle/working/StratifiedKFold_ROS_DecisionTree_test.csv\", index = False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Random Under Sampling\ndef StratifiedKFold_RUS_DecisionTree_model(df, nfolds, random_state, drop_columns_arr, target_col, apps_all_test):\n    df_off_preds = pd.DataFrame()\n    df_off_preds['SK_ID_CURR'] = df['SK_ID_CURR']\n\n    # deal with missing data\n    df = df.replace([np.inf, -np.inf], np.nan)\n    # Fill NaN with median value\n    df = df.fillna(-999)\n\n    ftr_app = df.drop(drop_columns_arr, axis=1)  # feature dateset\n    target_app = df[target_col]                  # target datasets\n    \n    # RUS\n    rus = RandomUnderSampler(random_state=42)\n    ftr_app, target_app = rus.fit_resample(ftr_app, target_app)\n    \n    # Initialize the Decision Tree model\n    dt = DecisionTreeClassifier(max_depth=20, random_state=42)\n\n    # Initialize the CalibratedClassifierCV object with the Decision Tree model and 5-fold cross-validation\n    skf = StratifiedKFold(n_splits=5)\n    calibrated_dt = CalibratedClassifierCV(dt, cv=skf, method='isotonic')\n\n    # Initialize the AUC score\n    auc_scores = []\n\n    # Fit the calibrated model on the data and calculate AUC on the testing data\n    calibrated_dt.fit(ftr_app, target_app)\n\n    # Predict probabilities on the testing data\n    y_pred_prob = calibrated_dt.predict_proba(ftr_app)[:, 1]\n\n    # Calculate the AUC score\n    auc = roc_auc_score(target_app, y_pred_prob)\n    auc_scores.append(auc)\n\n    # Print the mean and standard deviation of the AUC scores across all folds\n    print(f'Mean AUC: {np.mean(auc_scores):.4f}')\n\n    # apps_all_test \n    df_test = apps_all_test.copy()\n    test_res = pd.DataFrame()\n    # save SK_ID_CURR\n    test_res[\"SK_ID_CURR\"]=df_test[\"SK_ID_CURR\"]\n    # deal with missing value\n    df_test = df_test.replace([np.inf, -np.inf], np.nan)\n    # fill NaN with median value\n    df_test = df_test.fillna(-999)\n  \n    X_apps_test = df_test.drop(\"SK_ID_CURR\", axis=1)\n\n    y_apps_test = calibrated_dt.predict_proba(X_apps_test)[:, 1]\n    test_res[f\"TARGET\"] = y_apps_test\n\n    return df_off_preds, test_res","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# isotonic, max_dept = 20\ndf_off_preds, test_res = StratifiedKFold_RUS_DecisionTree_model(df=apps_train, nfolds=5, random_state=10, drop_columns_arr=['TARGET', 'SK_ID_CURR'], target_col='TARGET', apps_all_test=apps_all_test)\ndf_off_preds.to_csv(\"/kaggle/working/StratifiedKFold_RUS_DecisionTree_train.csv\", index = False)\ntest_res.to_csv(\"/kaggle/working/StratifiedKFold_RUS_DecisionTree_test.csv\", index = False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# SMOTE\ndef StratifiedKFold_SMOTE_DecisionTree_model(df, nfolds, random_state, drop_columns_arr, target_col, apps_all_test):\n    df_off_preds = pd.DataFrame()\n    df_off_preds['SK_ID_CURR'] = df['SK_ID_CURR']\n\n    # deal with missing data\n    df = df.replace([np.inf, -np.inf], np.nan)\n    # Fill NaN with median value\n    df = df.fillna(-999)\n\n    ftr_app = df.drop(drop_columns_arr, axis=1)  # feature dateset\n    target_app = df[target_col]                  # target datasets\n    \n    # SMOTE\n    smote = SMOTE()\n    ftr_app, target_app = smote.fit_resample(ftr_app, target_app)\n    \n    # Initialize the Decision Tree model\n    dt = DecisionTreeClassifier(max_depth=20, random_state=42)\n\n    # Initialize the CalibratedClassifierCV object with the Decision Tree model and 5-fold cross-validation\n    skf = StratifiedKFold(n_splits=5)\n    calibrated_dt = CalibratedClassifierCV(dt, cv=skf, method='isotonic')\n\n    # Initialize the AUC score\n    auc_scores = []\n\n    # Fit the calibrated model on the data and calculate AUC on the testing data\n    calibrated_dt.fit(ftr_app, target_app)\n\n    # Predict probabilities on the testing data\n    y_pred_prob = calibrated_dt.predict_proba(ftr_app)[:, 1]\n\n    # Calculate the AUC score\n    auc = roc_auc_score(target_app, y_pred_prob)\n    auc_scores.append(auc)\n\n    # Print the mean and standard deviation of the AUC scores across all folds\n    print(f'Mean AUC: {np.mean(auc_scores):.4f}')\n\n    # apps_all_test \n    df_test = apps_all_test.copy()\n    test_res = pd.DataFrame()\n    # save SK_ID_CURR\n    test_res[\"SK_ID_CURR\"]=df_test[\"SK_ID_CURR\"]\n    # deal with missing value\n    df_test = df_test.replace([np.inf, -np.inf], np.nan)\n    # fill NaN with median value\n    df_test = df_test.fillna(-999)\n  \n    X_apps_test = df_test.drop(\"SK_ID_CURR\", axis=1)\n\n    y_apps_test = calibrated_dt.predict_proba(X_apps_test)[:, 1]\n    test_res[f\"TARGET\"] = y_apps_test\n\n    return df_off_preds, test_res","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# isotonic, max_dept = 20\ndf_off_preds, test_res = StratifiedKFold_SMOTE_DecisionTree_model(df=apps_train, nfolds=5, random_state=10, drop_columns_arr=['TARGET', 'SK_ID_CURR'], target_col='TARGET', apps_all_test=apps_all_test)\ndf_off_preds.to_csv(\"/kaggle/working/SratifiedKFold_SMOTE_DecisionTree_train.csv\", index = False)\ntest_res.to_csv(\"/kaggle/working/SratifiedKFold_SMOTE_DecisionTree_test.csv\", index = False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Neural Networks","metadata":{}},{"cell_type":"markdown","source":"### K-Fold Cross-Validation","metadata":{}},{"cell_type":"code","source":"# No resampling method\ndef KFold_CNN_model(df, nfolds, random_state, drop_columns_arr, target_col, apps_all_test):\n    # deal with missing data\n    df = df.replace([np.inf, -np.inf], np.nan)\n    # Fill NaN with median value\n    df = df.fillna(-999)\n\n    df_off_preds = pd.DataFrame()\n    df_off_preds['SK_ID_CURR'] = df['SK_ID_CURR']\n\n    ftr_app = df.drop(drop_columns_arr, axis=1)  # feature dateset\n    target_app = df[target_col]                  # target datasets\n    # apply KFolds\n    folds = KFold(n_splits = nfolds, shuffle=True, random_state = random_state)\n\n    # Define the neural network architecture\n    clf = Sequential()\n    clf.add(Dense(128, input_dim=ftr_app.shape[1], activation='sigmoid'))\n    clf.add(Dropout(0.2))\n    clf.add(Dense(256, activation='sigmoid'))\n    clf.add(Dropout(0.2))\n    clf.add(Dense(512, activation='sigmoid'))\n    clf.add(Dropout(0.2))\n    clf.add(Dense(1024, activation='sigmoid'))\n    clf.add(Dropout(0.2))\n    clf.add(Dense(2048, activation='sigmoid'))\n    clf.add(Dropout(0.2))\n    clf.add(Dense(1, activation='softmax'))\n\n    # Compile the model\n    clf.compile(loss='categorical_crossentropy', optimizer='adam', metrics=[AUC()])\n    \n    auc_scores = []\n    oof_preds = np.zeros(ftr_app.shape[0])\n    oof_preds_proba = np.zeros(ftr_app.shape[0])\n\n    for fold_idx, (train_idx , valid_idx) in enumerate(folds.split(ftr_app, target_app)):\n        print(\"#iteration \", fold_idx, 'starts')\n        train_x = ftr_app.iloc[train_idx, :]\n        train_y = target_app.iloc[train_idx]\n        valid_x = ftr_app.iloc[valid_idx, :]\n        valid_y = target_app.iloc[valid_idx]\n\n        clf.fit(train_x, train_y, epochs=1, batch_size=32, validation_data=(valid_x, valid_y))\n        # Save predicted proba labels for validation set\n        valid_preds = clf.predict(valid_x)\n        oof_preds_proba[valid_idx] = valid_preds.ravel()\n        # compute AUC on validation set\n        auc_score = roc_auc_score(valid_y, valid_preds.ravel())\n        auc_scores.append(auc_score)\n        print(f\"AUC: {auc_score}\")\n\n    # compute mean AUC across all folds\n    mean_auc = np.mean(auc_scores)\n    print(f\"Mean AUC: {mean_auc}\")\n    \n    # Return target of training set\n    df_off_preds['TARGET'] = oof_preds_proba\n\n    # apps_all_test \n    df_test = apps_all_test.copy()\n    test_res = pd.DataFrame()\n    # save SK_ID_CURR\n    test_res[\"SK_ID_CURR\"]=df_test[\"SK_ID_CURR\"]\n    # deal with missing value\n    df_test = df_test.replace([np.inf, -np.inf], np.nan)\n    # fill NaN with median value\n    df_test = df_test.fillna(-999)\n  \n    X_apps_test = df_test.drop(\"SK_ID_CURR\", axis=1)\n\n    y_apps_test = clf.predict(X_apps_test)\n    test_res[f\"TARGET\"] = y_apps_test\n\n    return df_off_preds, clf, test_res","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 128 -> 2048\ndf_off_preds, clf, test_res = KFold_CNN_model(df=apps_train, nfolds=5, random_state=10, drop_columns_arr=['TARGET', 'SK_ID_CURR'], target_col='TARGET', apps_all_test=apps_all_test)\ndf_off_preds.to_csv(\"/kaggle/working/KFold_CNN_train.csv\", index = False)\ntest_res.to_csv(\"/kaggle/working/KFold_CNN_test.csv\", index = False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Random Over Sampling\ndef KFold_ROS_CNN_model(df, nfolds, random_state, drop_columns_arr, target_col, apps_all_test):\n    # deal with missing data\n    df = df.replace([np.inf, -np.inf], np.nan)\n    # Fill NaN with median value\n    df = df.fillna(-999)\n\n    df_off_preds = pd.DataFrame()\n    df_off_preds['SK_ID_CURR'] = df['SK_ID_CURR']\n\n    ftr_app = df.drop(drop_columns_arr, axis=1)  # feature dateset\n    target_app = df[target_col]                  # target datasets\n    # apply KFolds\n    folds = KFold(n_splits = nfolds, shuffle=True, random_state = random_state)\n    # ROS\n    ros = RandomOverSampler()\n\n    # Define the neural network architecture\n    clf = Sequential()\n    clf.add(Dense(128, input_dim=ftr_app.shape[1], activation='sigmoid'))\n    clf.add(Dropout(0.2))\n    clf.add(Dense(256, activation='sigmoid'))\n    clf.add(Dropout(0.2))\n    clf.add(Dense(512, activation='sigmoid'))\n    clf.add(Dropout(0.2))\n    clf.add(Dense(1024, activation='sigmoid'))\n    clf.add(Dropout(0.2))\n    clf.add(Dense(2048, activation='sigmoid'))\n    clf.add(Dropout(0.2))\n    clf.add(Dense(1, activation='softmax'))\n\n    # Compile the model\n    clf.compile(loss='categorical_crossentropy', optimizer='adam', metrics=[AUC()])\n    \n    auc_scores = []\n    oof_preds = np.zeros(ftr_app.shape[0])\n    oof_preds_proba = np.zeros(ftr_app.shape[0])\n\n    for fold_idx, (train_idx , valid_idx) in enumerate(folds.split(ftr_app, target_app)):\n        print(\"#iteration \", fold_idx, 'starts')\n        train_x = ftr_app.iloc[train_idx, :]\n        train_y = target_app.iloc[train_idx]\n        valid_x = ftr_app.iloc[valid_idx, :]\n        valid_y = target_app.iloc[valid_idx]\n        \n        train_x_resampled, train_y_resampled = ros.fit_resample(train_x, train_y)\n\n        clf.fit(train_x_resampled, train_y_resampled, epochs=1, batch_size=32, validation_data=(valid_x, valid_y))\n        # Save predicted proba labels for validation set\n        valid_preds = clf.predict(valid_x)\n        oof_preds_proba[valid_idx] = valid_preds.ravel()\n        # compute AUC on validation set\n        auc_score = roc_auc_score(valid_y, valid_preds.ravel())\n        auc_scores.append(auc_score)\n        print(f\"AUC: {auc_score}\")\n\n    # compute mean AUC across all folds\n    mean_auc = np.mean(auc_scores)\n    print(f\"Mean AUC: {mean_auc}\")\n    \n    # Return target of training set\n    df_off_preds['TARGET'] = oof_preds_proba\n\n    # apps_all_test \n    df_test = apps_all_test.copy()\n    test_res = pd.DataFrame()\n    # save SK_ID_CURR\n    test_res[\"SK_ID_CURR\"]=df_test[\"SK_ID_CURR\"]\n    # deal with missing value\n    df_test = df_test.replace([np.inf, -np.inf], np.nan)\n    # fill NaN with median value\n    df_test = df_test.fillna(-999)\n  \n    X_apps_test = df_test.drop(\"SK_ID_CURR\", axis=1)\n\n    y_apps_test = clf.predict(X_apps_test)\n    test_res[f\"TARGET\"] = y_apps_test\n\n    return df_off_preds, clf, test_res","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 128 -> 2048\ndf_off_preds, clf, test_res = KFold_ROS_CNN_model(df=apps_train, nfolds=5, random_state=10, drop_columns_arr=['TARGET', 'SK_ID_CURR'], target_col='TARGET', apps_all_test=apps_all_test)\ndf_off_preds.to_csv(\"/kaggle/working/KFold_ROS_CNN_train.csv\", index = False)\ntest_res.to_csv(\"/kaggle/working/KFold_ROS_CNN_test.csv\", index = False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Random Under Sampling\ndef KFold_RUS_CNN_model(df, nfolds, random_state, drop_columns_arr, target_col, apps_all_test):\n    # deal with missing data\n    df = df.replace([np.inf, -np.inf], np.nan)\n    # Fill NaN with median value\n    df = df.fillna(-999)\n\n    df_off_preds = pd.DataFrame()\n    df_off_preds['SK_ID_CURR'] = df['SK_ID_CURR']\n\n    ftr_app = df.drop(drop_columns_arr, axis=1)  # feature dateset\n    target_app = df[target_col]                  # target datasets\n    # apply KFolds\n    folds = KFold(n_splits = nfolds, shuffle=True, random_state = random_state)\n    # RUS\n    rus = RandomUnderSampler(random_state =42)\n\n    # Define the neural network architecture\n    clf = Sequential()\n    clf.add(Dense(128, input_dim=ftr_app.shape[1], activation='sigmoid'))\n    clf.add(Dropout(0.2))\n    clf.add(Dense(256, activation='sigmoid'))\n    clf.add(Dropout(0.2))\n    clf.add(Dense(512, activation='sigmoid'))\n    clf.add(Dropout(0.2))\n    clf.add(Dense(1024, activation='sigmoid'))\n    clf.add(Dropout(0.2))\n    clf.add(Dense(2048, activation='sigmoid'))\n    clf.add(Dropout(0.2))\n    clf.add(Dense(1, activation='softmax'))\n\n    # Compile the model\n    clf.compile(loss='categorical_crossentropy', optimizer='adam', metrics=[AUC()])\n    \n    auc_scores = []\n    oof_preds_proba = np.zeros(ftr_app.shape[0])\n\n    for fold_idx, (train_idx , valid_idx) in enumerate(folds.split(ftr_app, target_app)):\n        print(\"#iteration \", fold_idx, 'starts')\n        train_x = ftr_app.iloc[train_idx, :]\n        train_y = target_app.iloc[train_idx]\n        valid_x = ftr_app.iloc[valid_idx, :]\n        valid_y = target_app.iloc[valid_idx]\n        \n        train_x_resampled, train_y_resampled = rus.fit_resample(train_x, train_y)\n\n        clf.fit(train_x_resampled, train_y_resampled, epochs=1, batch_size=32, validation_data=(valid_x, valid_y))\n        # Save predicted proba labels for validation set\n        valid_preds = clf.predict(valid_x)\n        oof_preds_proba[valid_idx] = valid_preds.ravel()\n        # compute AUC on validation set\n        auc_score = roc_auc_score(valid_y, valid_preds.ravel())\n        auc_scores.append(auc_score)\n        print(f\"AUC: {auc_score}\")\n\n    # compute mean AUC across all folds\n    mean_auc = np.mean(auc_scores)\n    print(f\"Mean AUC: {mean_auc}\")\n    \n    # Return target of training set\n    df_off_preds['TARGET'] = oof_preds_proba\n\n    # apps_all_test \n    df_test = apps_all_test.copy()\n    test_res = pd.DataFrame()\n    # save SK_ID_CURR\n    test_res[\"SK_ID_CURR\"]=df_test[\"SK_ID_CURR\"]\n    # deal with missing value\n    df_test = df_test.replace([np.inf, -np.inf], np.nan)\n    # fill NaN with median value\n    df_test = df_test.fillna(-999)\n  \n    X_apps_test = df_test.drop(\"SK_ID_CURR\", axis=1)\n\n    y_apps_test = clf.predict(X_apps_test)\n    test_res[f\"TARGET\"] = y_apps_test\n\n    return df_off_preds, clf, test_res","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 128 -> 2048\ndf_off_preds, clf, test_res = KFold_RUS_CNN_model(df=apps_train, nfolds=5, random_state=10, drop_columns_arr=['TARGET', 'SK_ID_CURR'], target_col='TARGET', apps_all_test=apps_all_test)\ndf_off_preds.to_csv(\"/kaggle/working/KFold_RUS_CNN_train.csv\", index = False)\ntest_res.to_csv(\"/kaggle/working/KFold_RUS_CNN_test.csv\", index = False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# SMOTE\ndef KFold_SMOTE_CNN_model(df, nfolds, random_state, drop_columns_arr, target_col, apps_all_test):\n    # deal with missing data\n    df = df.replace([np.inf, -np.inf], np.nan)\n    # Fill NaN with median value\n    df = df.fillna(-999)\n\n    df_off_preds = pd.DataFrame()\n    df_off_preds['SK_ID_CURR'] = df['SK_ID_CURR']\n\n    ftr_app = df.drop(drop_columns_arr, axis=1)  # feature dateset\n    target_app = df[target_col]                  # target datasets\n    # apply KFolds\n    folds = KFold(n_splits = nfolds, shuffle=True, random_state = random_state)\n    # SMOTE\n    smote = SMOTE()\n\n    # Define the neural network architecture\n    clf = Sequential()\n    clf.add(Dense(128, input_dim=ftr_app.shape[1], activation='sigmoid'))\n    clf.add(Dropout(0.2))\n    clf.add(Dense(256, activation='sigmoid'))\n    clf.add(Dropout(0.2))\n    clf.add(Dense(512, activation='sigmoid'))\n    clf.add(Dropout(0.2))\n    clf.add(Dense(1024, activation='sigmoid'))\n    clf.add(Dropout(0.2))\n    clf.add(Dense(2048, activation='sigmoid'))\n    clf.add(Dropout(0.2))\n    clf.add(Dense(1, activation='softmax'))\n\n    # Compile the model\n    clf.compile(loss='categorical_crossentropy', optimizer='adam', metrics=[AUC()])\n    \n    auc_scores = []\n    oof_preds_proba = np.zeros(ftr_app.shape[0])\n\n    for fold_idx, (train_idx , valid_idx) in enumerate(folds.split(ftr_app, target_app)):\n        print(\"#iteration \", fold_idx, 'starts')\n        train_x = ftr_app.iloc[train_idx, :]\n        train_y = target_app.iloc[train_idx]\n        valid_x = ftr_app.iloc[valid_idx, :]\n        valid_y = target_app.iloc[valid_idx]\n        \n        train_x_resampled, train_y_resampled = smote.fit_resample(train_x, train_y)\n\n        clf.fit(train_x_resampled, train_y_resampled, epochs=1, batch_size=32, validation_data=(valid_x, valid_y))\n        # Save predicted proba labels for validation set\n        valid_preds = clf.predict(valid_x)\n        oof_preds_proba[valid_idx] = valid_preds.ravel()\n        # compute AUC on validation set\n        auc_score = roc_auc_score(valid_y, valid_preds.ravel())\n        auc_scores.append(auc_score)\n        print(f\"AUC: {auc_score}\")\n\n    # compute mean AUC across all folds\n    mean_auc = np.mean(auc_scores)\n    print(f\"Mean AUC: {mean_auc}\")\n    \n    # Return target of training set\n    df_off_preds['TARGET'] = oof_preds_proba\n\n    # apps_all_test \n    df_test = apps_all_test.copy()\n    test_res = pd.DataFrame()\n    # save SK_ID_CURR\n    test_res[\"SK_ID_CURR\"]=df_test[\"SK_ID_CURR\"]\n    # deal with missing value\n    df_test = df_test.replace([np.inf, -np.inf], np.nan)\n    # fill NaN with median value\n    df_test = df_test.fillna(-999)\n  \n    X_apps_test = df_test.drop(\"SK_ID_CURR\", axis=1)\n\n    y_apps_test = clf.predict(X_apps_test)\n    test_res[f\"TARGET\"] = y_apps_test\n\n    return df_off_preds, clf, test_res","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 128 -> 2048\ndf_off_preds, clf, test_res = KFold_SMOTE_CNN_model(df=apps_train, nfolds=5, random_state=10, drop_columns_arr=['TARGET', 'SK_ID_CURR'], target_col='TARGET', apps_all_test=apps_all_test)\ndf_off_preds.to_csv(\"/kaggle/working/KFold_SMOTE_CNN_train.csv\", index = False)\ntest_res.to_csv(\"/kaggle/working/KFold_SMOTE_CNN_test.csv\", index = False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Stratified K-Fold Cross-Validation","metadata":{}},{"cell_type":"code","source":"# No resampling method\ndef StratifiedKFold_CNN_model(df, nfolds, random_state, drop_columns_arr, target_col, apps_all_test):\n    # deal with missing data\n    df = df.replace([np.inf, -np.inf], np.nan)\n    # Fill NaN with median value\n    df = df.fillna(-999)\n\n    df_off_preds = pd.DataFrame()\n    df_off_preds['SK_ID_CURR'] = df['SK_ID_CURR']\n\n    ftr_app = df.drop(drop_columns_arr, axis=1)  # feature dateset\n    target_app = df[target_col]                  # target datasets\n    # apply Stratifed KFold\n    folds = StratifiedKFold(n_splits = nfolds, shuffle=True, random_state = random_state)\n\n    # Define the neural network architecture\n    clf = Sequential()\n    clf.add(Dense(128, input_dim=ftr_app.shape[1], activation='sigmoid'))\n    clf.add(Dropout(0.2))\n    clf.add(Dense(256, activation='sigmoid'))\n    clf.add(Dropout(0.2))\n    clf.add(Dense(512, activation='sigmoid'))\n    clf.add(Dropout(0.2))\n    clf.add(Dense(1024, activation='sigmoid'))\n    clf.add(Dropout(0.2))\n    clf.add(Dense(2048, activation='sigmoid'))\n    clf.add(Dropout(0.2))\n    clf.add(Dense(1, activation='softmax'))\n\n    # Compile the model\n    clf.compile(loss='categorical_crossentropy', optimizer='adam', metrics=[AUC()])\n    \n    auc_scores = []\n    oof_preds = np.zeros(ftr_app.shape[0])\n    oof_preds_proba = np.zeros(ftr_app.shape[0])\n\n    for fold_idx, (train_idx , valid_idx) in enumerate(folds.split(ftr_app, target_app)):\n        print(\"#iteration \", fold_idx, 'starts')\n        train_x = ftr_app.iloc[train_idx, :]\n        train_y = target_app.iloc[train_idx]\n        valid_x = ftr_app.iloc[valid_idx, :]\n        valid_y = target_app.iloc[valid_idx]\n\n        clf.fit(train_x, train_y, epochs=1, batch_size=32, validation_data=(valid_x, valid_y))\n        # Save predicted proba labels for validation set\n        valid_preds = clf.predict(valid_x)\n        oof_preds_proba[valid_idx] = valid_preds.ravel()\n        # compute AUC on validation set\n        auc_score = roc_auc_score(valid_y, valid_preds.ravel())\n        auc_scores.append(auc_score)\n        print(f\"AUC: {auc_score}\")\n\n    # compute mean AUC across all folds\n    mean_auc = np.mean(auc_scores)\n    print(f\"Mean AUC: {mean_auc}\")\n    \n    # Return target of training set\n    df_off_preds['TARGET'] = oof_preds_proba\n\n    # apps_all_test \n    df_test = apps_all_test.copy()\n    test_res = pd.DataFrame()\n    # save SK_ID_CURR\n    test_res[\"SK_ID_CURR\"]=df_test[\"SK_ID_CURR\"]\n    # deal with missing value\n    df_test = df_test.replace([np.inf, -np.inf], np.nan)\n    # fill NaN with median value\n    df_test = df_test.fillna(-999)\n  \n    X_apps_test = df_test.drop(\"SK_ID_CURR\", axis=1)\n\n    y_apps_test = clf.predict(X_apps_test)\n    test_res[f\"TARGET\"] = y_apps_test\n\n    return df_off_preds, clf, test_res","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 128 -> 2048\ndf_off_preds, clf, test_res = StratifiedKFold_CNN_model(df=apps_train, nfolds=5, random_state=10, drop_columns_arr=['TARGET', 'SK_ID_CURR'], target_col='TARGET', apps_all_test=apps_all_test)\ndf_off_preds.to_csv(\"/kaggle/working/StratifiedKFold_CNN_train.csv\", index = False)\ntest_res.to_csv(\"/kaggle/working/StratifiedKFold_CNN_test.csv\", index = False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Random Over Sampling\ndef StratifiedKFold_ROS_CNN_model(df, nfolds, random_state, drop_columns_arr, target_col, apps_all_test):\n    # deal with missing data\n    df = df.replace([np.inf, -np.inf], np.nan)\n    # Fill NaN with median value\n    df = df.fillna(-999)\n\n    df_off_preds = pd.DataFrame()\n    df_off_preds['SK_ID_CURR'] = df['SK_ID_CURR']\n\n    ftr_app = df.drop(drop_columns_arr, axis=1)  # feature dateset\n    target_app = df[target_col]                  # target datasets\n    # apply Stratified KFold\n    folds = StratifiedKFold(n_splits = nfolds, shuffle=True, random_state = random_state)\n    # ROS\n    ros = RandomOverSampler()\n\n    # Define the neural network architecture\n    clf = Sequential()\n    clf.add(Dense(128, input_dim=ftr_app.shape[1], activation='sigmoid'))\n    clf.add(Dropout(0.2))\n    clf.add(Dense(256, activation='sigmoid'))\n    clf.add(Dropout(0.2))\n    clf.add(Dense(512, activation='sigmoid'))\n    clf.add(Dropout(0.2))\n    clf.add(Dense(1024, activation='sigmoid'))\n    clf.add(Dropout(0.2))\n    clf.add(Dense(2048, activation='sigmoid'))\n    clf.add(Dropout(0.2))\n    clf.add(Dense(1, activation='softmax'))\n\n    # Compile the model\n    clf.compile(loss='categorical_crossentropy', optimizer='adam', metrics=[AUC()])\n    \n    auc_scores = []\n    oof_preds = np.zeros(ftr_app.shape[0])\n    oof_preds_proba = np.zeros(ftr_app.shape[0])\n\n    for fold_idx, (train_idx , valid_idx) in enumerate(folds.split(ftr_app, target_app)):\n        print(\"#iteration \", fold_idx, 'starts')\n        train_x = ftr_app.iloc[train_idx, :]\n        train_y = target_app.iloc[train_idx]\n        valid_x = ftr_app.iloc[valid_idx, :]\n        valid_y = target_app.iloc[valid_idx]\n        \n        train_x_resampled, train_y_resampled = ros.fit_resample(train_x, train_y)\n\n        clf.fit(train_x_resampled, train_y_resampled, epochs=1, batch_size=32, validation_data=(valid_x, valid_y))\n        # Save predicted proba labels for validation set\n        valid_preds = clf.predict(valid_x)\n        oof_preds_proba[valid_idx] = valid_preds.ravel()\n        # compute AUC on validation set\n        auc_score = roc_auc_score(valid_y, valid_preds.ravel())\n        auc_scores.append(auc_score)\n        print(f\"AUC: {auc_score}\")\n\n    # compute mean AUC across all folds\n    mean_auc = np.mean(auc_scores)\n    print(f\"Mean AUC: {mean_auc}\")\n    \n    # Return target of training set\n    df_off_preds['TARGET'] = oof_preds_proba\n\n    # apps_all_test \n    df_test = apps_all_test.copy()\n    test_res = pd.DataFrame()\n    # save SK_ID_CURR\n    test_res[\"SK_ID_CURR\"]=df_test[\"SK_ID_CURR\"]\n    # deal with missing value\n    df_test = df_test.replace([np.inf, -np.inf], np.nan)\n    # fill NaN with median value\n    df_test = df_test.fillna(-999)\n  \n    X_apps_test = df_test.drop(\"SK_ID_CURR\", axis=1)\n\n    y_apps_test = clf.predict(X_apps_test)\n    test_res[f\"TARGET\"] = y_apps_test\n\n    return df_off_preds, clf, test_res","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 128 -> 2048\ndf_off_preds, clf, test_res = StratifiedKFold_ROS_CNN_model(df=apps_train, nfolds=5, random_state=10, drop_columns_arr=['TARGET', 'SK_ID_CURR'], target_col='TARGET', apps_all_test=apps_all_test)\ndf_off_preds.to_csv(\"/kaggle/working/StratifiedKFold_ROS_CNN_train.csv\", index = False)\ntest_res.to_csv(\"/kaggle/working/StratifiedKFold_ROS_CNN_test.csv\", index = False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Random Under Sampling\ndef StratifiedKFold_RUS_CNN_model(df, nfolds, random_state, drop_columns_arr, target_col, apps_all_test):\n    # deal with missing data\n    df = df.replace([np.inf, -np.inf], np.nan)\n    # Fill NaN with median value\n    df = df.fillna(-999)\n\n    df_off_preds = pd.DataFrame()\n    df_off_preds['SK_ID_CURR'] = df['SK_ID_CURR']\n\n    ftr_app = df.drop(drop_columns_arr, axis=1)  # feature dateset\n    target_app = df[target_col]                  # target datasets\n    # apply Stratifed KFold\n    folds = StratifiedKFold(n_splits = nfolds, shuffle=True, random_state = random_state)\n    # RUS\n    rus = RandomUnderSampler(random_state =42)\n\n    # Define the neural network architecture\n    clf = Sequential()\n    clf.add(Dense(128, input_dim=ftr_app.shape[1], activation='sigmoid'))\n    clf.add(Dropout(0.2))\n    clf.add(Dense(256, activation='sigmoid'))\n    clf.add(Dropout(0.2))\n    clf.add(Dense(512, activation='sigmoid'))\n    clf.add(Dropout(0.2))\n    clf.add(Dense(1024, activation='sigmoid'))\n    clf.add(Dropout(0.2))\n    clf.add(Dense(2048, activation='sigmoid'))\n    clf.add(Dropout(0.2))\n    clf.add(Dense(1, activation='softmax'))\n\n    # Compile the model\n    clf.compile(loss='categorical_crossentropy', optimizer='adam', metrics=[AUC()])\n    \n    auc_scores = []\n    oof_preds_proba = np.zeros(ftr_app.shape[0])\n\n    for fold_idx, (train_idx , valid_idx) in enumerate(folds.split(ftr_app, target_app)):\n        print(\"#iteration \", fold_idx, 'starts')\n        train_x = ftr_app.iloc[train_idx, :]\n        train_y = target_app.iloc[train_idx]\n        valid_x = ftr_app.iloc[valid_idx, :]\n        valid_y = target_app.iloc[valid_idx]\n        \n        train_x_resampled, train_y_resampled = rus.fit_resample(train_x, train_y)\n\n        clf.fit(train_x_resampled, train_y_resampled, epochs=1, batch_size=32, validation_data=(valid_x, valid_y))\n        # Save predicted proba labels for validation set\n        valid_preds = clf.predict(valid_x)\n        oof_preds_proba[valid_idx] = valid_preds.ravel()\n        # compute AUC on validation set\n        auc_score = roc_auc_score(valid_y, valid_preds.ravel())\n        auc_scores.append(auc_score)\n        print(f\"AUC: {auc_score}\")\n\n    # compute mean AUC across all folds\n    mean_auc = np.mean(auc_scores)\n    print(f\"Mean AUC: {mean_auc}\")\n    \n    # Return target of training set\n    df_off_preds['TARGET'] = oof_preds_proba\n\n    # apps_all_test \n    df_test = apps_all_test.copy()\n    test_res = pd.DataFrame()\n    # save SK_ID_CURR\n    test_res[\"SK_ID_CURR\"]=df_test[\"SK_ID_CURR\"]\n    # deal with missing value\n    df_test = df_test.replace([np.inf, -np.inf], np.nan)\n    # fill NaN with median value\n    df_test = df_test.fillna(-999)\n  \n    X_apps_test = df_test.drop(\"SK_ID_CURR\", axis=1)\n\n    y_apps_test = clf.predict(X_apps_test)\n    test_res[f\"TARGET\"] = y_apps_test\n\n    return df_off_preds, clf, test_res","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 128 -> 2048\ndf_off_preds, clf, test_res = StratifiedKFold_RUS_CNN_model(df=apps_train, nfolds=5, random_state=10, drop_columns_arr=['TARGET', 'SK_ID_CURR'], target_col='TARGET', apps_all_test=apps_all_test)\ndf_off_preds.to_csv(\"/kaggle/working/StratifiedKFold_RUS_CNN_train.csv\", index = False)\ntest_res.to_csv(\"/kaggle/working/StratifiedKFold_RUS_CNN_test.csv\", index = False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# SMOTE\ndef StratifiedKFold_SMOTE_CNN_model(df, nfolds, random_state, drop_columns_arr, target_col, apps_all_test):\n    # deal with missing data\n    df = df.replace([np.inf, -np.inf], np.nan)\n    # Fill NaN with median value\n    df = df.fillna(-999)\n\n    df_off_preds = pd.DataFrame()\n    df_off_preds['SK_ID_CURR'] = df['SK_ID_CURR']\n\n    ftr_app = df.drop(drop_columns_arr, axis=1)  # feature dateset\n    target_app = df[target_col]                  # target datasets\n    # apply Stratified KFolds\n    folds = StratifiedKFold(n_splits = nfolds, shuffle=True, random_state = random_state)\n    # SMOTE\n    smote = SMOTE()\n\n    # Define the neural network architecture\n    clf = Sequential()\n    clf.add(Dense(128, input_dim=ftr_app.shape[1], activation='sigmoid'))\n    clf.add(Dropout(0.2))\n    clf.add(Dense(256, activation='sigmoid'))\n    clf.add(Dropout(0.2))\n    clf.add(Dense(512, activation='sigmoid'))\n    clf.add(Dropout(0.2))\n    clf.add(Dense(1024, activation='sigmoid'))\n    clf.add(Dropout(0.2))\n    clf.add(Dense(2048, activation='sigmoid'))\n    clf.add(Dropout(0.2))\n    clf.add(Dense(1, activation='softmax'))\n\n    # Compile the model\n    clf.compile(loss='categorical_crossentropy', optimizer='adam', metrics=[AUC()])\n    \n    auc_scores = []\n    oof_preds_proba = np.zeros(ftr_app.shape[0])\n\n    for fold_idx, (train_idx , valid_idx) in enumerate(folds.split(ftr_app, target_app)):\n        print(\"#iteration \", fold_idx, 'starts')\n        train_x = ftr_app.iloc[train_idx, :]\n        train_y = target_app.iloc[train_idx]\n        valid_x = ftr_app.iloc[valid_idx, :]\n        valid_y = target_app.iloc[valid_idx]\n        \n        train_x_resampled, train_y_resampled = smote.fit_resample(train_x, train_y)\n\n        clf.fit(train_x_resampled, train_y_resampled, epochs=1, batch_size=32, validation_data=(valid_x, valid_y))\n        # Save predicted proba labels for validation set\n        valid_preds = clf.predict(valid_x)\n        oof_preds_proba[valid_idx] = valid_preds.ravel()\n        # compute AUC on validation set\n        auc_score = roc_auc_score(valid_y, valid_preds.ravel())\n        auc_scores.append(auc_score)\n        print(f\"AUC: {auc_score}\")\n\n    # compute mean AUC across all folds\n    mean_auc = np.mean(auc_scores)\n    print(f\"Mean AUC: {mean_auc}\")\n    \n    # Return target of training set\n    df_off_preds['TARGET'] = oof_preds_proba\n\n    # apps_all_test \n    df_test = apps_all_test.copy()\n    test_res = pd.DataFrame()\n    # save SK_ID_CURR\n    test_res[\"SK_ID_CURR\"]=df_test[\"SK_ID_CURR\"]\n    # deal with missing value\n    df_test = df_test.replace([np.inf, -np.inf], np.nan)\n    # fill NaN with median value\n    df_test = df_test.fillna(-999)\n  \n    X_apps_test = df_test.drop(\"SK_ID_CURR\", axis=1)\n\n    y_apps_test = clf.predict(X_apps_test)\n    test_res[f\"TARGET\"] = y_apps_test\n\n    return df_off_preds, clf, test_res","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 128 -> 2048\ndf_off_preds, clf, test_res = StratifiedKFold_SMOTE_CNN_model(df=apps_train, nfolds=5, random_state=10, drop_columns_arr=['TARGET', 'SK_ID_CURR'], target_col='TARGET', apps_all_test=apps_all_test)\ndf_off_preds.to_csv(\"/kaggle/working/StratifiedKFold_SMOTE_CNN_train.csv\", index = False)\ntest_res.to_csv(\"/kaggle/working/StratifiedKFold_SMOTE_CNN_test.csv\", index = False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Bagging Algorithms","metadata":{}},{"cell_type":"markdown","source":"## Random Forest","metadata":{}},{"cell_type":"markdown","source":"### K-Fold Cross-Validation","metadata":{}},{"cell_type":"code","source":"# No resampling method\ndef KFold_RandomForest_model(df, nfolds, random_state, drop_columns_arr, target_col, apps_all_test):\n    df_off_preds = pd.DataFrame()\n    df_off_preds['SK_ID_CURR'] = df['SK_ID_CURR']\n\n    # deal with missing data\n    df = df.replace([np.inf, -np.inf], np.nan)\n    # Fill NaN with median value\n    df = df.fillna(-999)\n\n    ftr_app = df.drop(drop_columns_arr, axis=1)  # feature dateset\n    target_app = df[target_col]                  # target datasets\n    # apply KFolds\n    folds = KFold(n_splits = nfolds, shuffle=True, random_state = random_state)\n    \n    oof_preds_proba = np.zeros(ftr_app.shape[0])\n    auc_scores = []\n\n    clf = RandomForestClassifier(n_estimators=1000\n           , criterion='gini'\n           , max_depth=10\n           , min_samples_split=10\n           , min_samples_leaf=30\n           )\n    \n    for fold_idx, (train_idx , valid_idx) in enumerate(folds.split(ftr_app)):\n        print(\"# iteration\", fold_idx, 'starts')\n        train_x = ftr_app.iloc[train_idx, :]\n        train_y = target_app.iloc[train_idx]\n        valid_x = ftr_app.iloc[valid_idx, :]\n        valid_y = target_app.iloc[valid_idx]\n\n        clf.fit(train_x, train_y)\n        # Save predicted proba labels for validation set\n        oof_preds_proba[valid_idx] = clf.predict_proba(valid_x)[:, 1]\n\n        # compute AUC on validation set\n        auc_score = roc_auc_score(valid_y, oof_preds_proba[valid_idx])\n        auc_scores.append(auc_score)\n        print(f\"AUC: {auc_score}\")\n\n    print(f\"Mean AUC: {np.mean(auc_scores):.5f}\")\n\n    df_off_preds['KFold_RF_AUC_PROBA'] = oof_preds_proba\n\n    # apps_all_test \n    df_test = apps_all_test.copy()\n    test_res = pd.DataFrame()\n    # save SK_ID_CURR\n    test_res[\"SK_ID_CURR\"]=df_test[\"SK_ID_CURR\"]\n    # deal with missing value\n    df_test = df_test.replace([np.inf, -np.inf], np.nan)\n    # fill NaN with median value\n    df_test = df_test.fillna(-999)\n  \n    X_apps_test = df_test.drop(\"SK_ID_CURR\", axis=1)\n\n    y_apps_test = clf.predict_proba(X_apps_test)\n    test_res[f\"TARGET\"] = y_apps_test[:, 1]\n\n    return df_off_preds, clf, test_res","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_off_preds, clf, test_res = KFold_RandomForest_model(df=apps_train, nfolds=5, random_state=10, drop_columns_arr=['TARGET', 'SK_ID_CURR'], target_col='TARGET', apps_all_test=apps_all_test)\ndf_off_preds.to_csv(\"/kaggle/working/KFold_RandomForest_train.csv\", index=False)\ntest_res.to_csv(\"/kaggle/working/KFold_RandomForest_test.csv\", index=False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Random Over Sampling\ndef KFold_ROS_RandomForest_model(df, nfolds, random_state, drop_columns_arr, target_col, apps_all_test):\n    df_off_preds = pd.DataFrame()\n    df_off_preds['SK_ID_CURR'] = df['SK_ID_CURR']\n\n    # deal with missing data\n    df = df.replace([np.inf, -np.inf], np.nan)\n    # Fill NaN with median value\n    df = df.fillna(-999)\n\n    ftr_app = df.drop(drop_columns_arr, axis=1)  # feature dateset\n    target_app = df[target_col]                  # target datasets\n    # apply KFolds\n    folds = KFold(n_splits = nfolds, shuffle=True, random_state = random_state)\n    \n    oof_preds_proba = np.zeros(ftr_app.shape[0])\n    auc_scores = []\n\n    clf = RandomForestClassifier(n_estimators=1000\n           , criterion='gini'\n           , max_depth=10\n           , min_samples_split=10\n           , min_samples_leaf=30\n           )\n    \n    ros = RandomOverSampler()\n    \n    for fold_idx, (train_idx , valid_idx) in enumerate(folds.split(ftr_app, target_app)):\n        print(\"# iteration\", fold_idx, 'starts')\n        train_x = ftr_app.iloc[train_idx, :]\n        train_y = target_app.iloc[train_idx]\n        valid_x = ftr_app.iloc[valid_idx, :]\n        valid_y = target_app.iloc[valid_idx]\n        \n        train_x_resampled, train_y_resampled = ros.fit_resample(train_x, train_y)\n\n        clf.fit(train_x_resampled, train_y_resampled)\n        # Save predicted proba labels for validation set\n        oof_preds_proba[valid_idx] = clf.predict_proba(valid_x)[:, 1]\n\n        # compute AUC on validation set\n        auc_score = roc_auc_score(valid_y, oof_preds_proba[valid_idx])\n        auc_scores.append(auc_score)\n        print(f\"AUC: {auc_score}\")\n\n    print(f\"Mean AUC: {np.mean(auc_scores):.5f}\")\n\n    df_off_preds['KFold_RF_AUC_PROBA'] = oof_preds_proba\n\n    # apps_all_test \n    df_test = apps_all_test.copy()\n    test_res = pd.DataFrame()\n    # save SK_ID_CURR\n    test_res[\"SK_ID_CURR\"]=df_test[\"SK_ID_CURR\"]\n    # deal with missing value\n    df_test = df_test.replace([np.inf, -np.inf], np.nan)\n    # fill NaN with median value\n    df_test = df_test.fillna(-999)\n  \n    X_apps_test = df_test.drop(\"SK_ID_CURR\", axis=1)\n\n    y_apps_test = clf.predict_proba(X_apps_test)\n    test_res[f\"TARGET\"] = y_apps_test[:, 1]\n\n    return df_off_preds, clf, test_res","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_off_preds, clf, test_res = KFold_ROS_RandomForest_model(df=apps_train, nfolds=5, random_state=10, drop_columns_arr=['TARGET', 'SK_ID_CURR'], target_col='TARGET', apps_all_test=apps_all_test)\ndf_off_preds.to_csv(\"/kaggle/working/KFold_ROS_RandomForest_train.csv\", index=False)\ntest_res.to_csv(\"/kaggle/working/KFold_ROS_RandomForest_test.csv\", index=False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Random Under Sampling\ndef KFold_RUS_RandomForest_model(df, nfolds, random_state, drop_columns_arr, target_col, apps_all_test):\n    df_off_preds = pd.DataFrame()\n    df_off_preds['SK_ID_CURR'] = df['SK_ID_CURR']\n\n    # deal with missing data\n    df = df.replace([np.inf, -np.inf], np.nan)\n    # Fill NaN with median value\n    df = df.fillna(-999)\n\n    ftr_app = df.drop(drop_columns_arr, axis=1)  # feature dateset\n    target_app = df[target_col]                  # target datasets\n    # apply KFolds\n    folds = KFold(n_splits = nfolds, shuffle=True, random_state = random_state)\n    \n    oof_preds_proba = np.zeros(ftr_app.shape[0])\n    auc_scores = []\n\n    clf = RandomForestClassifier(n_estimators=1000\n           , criterion='gini'\n           , max_depth=10\n           , min_samples_split=10\n           , min_samples_leaf=30\n           )\n    \n    rus = RandomUnderSampler(random_state=42)\n    \n    for fold_idx, (train_idx , valid_idx) in enumerate(folds.split(ftr_app, target_app)):\n        print(\"# iteration\", fold_idx, 'starts')\n        train_x = ftr_app.iloc[train_idx, :]\n        train_y = target_app.iloc[train_idx]\n        valid_x = ftr_app.iloc[valid_idx, :]\n        valid_y = target_app.iloc[valid_idx]\n        \n        train_x_resampled, train_y_resampled = rus.fit_resample(train_x, train_y)\n\n        clf.fit(train_x_resampled, train_y_resampled)\n        # Save predicted proba labels for validation set\n        oof_preds_proba[valid_idx] = clf.predict_proba(valid_x)[:, 1]\n\n        # compute AUC on validation set\n        auc_score = roc_auc_score(valid_y, oof_preds_proba[valid_idx])\n        auc_scores.append(auc_score)\n        print(f\"AUC: {auc_score}\")\n\n    print(f\"Mean AUC: {np.mean(auc_scores):.5f}\")\n\n    df_off_preds['KFold_RF_AUC_PROBA'] = oof_preds_proba\n\n    # apps_all_test \n    df_test = apps_all_test.copy()\n    test_res = pd.DataFrame()\n    # save SK_ID_CURR\n    test_res[\"SK_ID_CURR\"]=df_test[\"SK_ID_CURR\"]\n    # deal with missing value\n    df_test = df_test.replace([np.inf, -np.inf], np.nan)\n    # fill NaN with median value\n    df_test = df_test.fillna(-999)\n  \n    X_apps_test = df_test.drop(\"SK_ID_CURR\", axis=1)\n\n    y_apps_test = clf.predict_proba(X_apps_test)\n    test_res[f\"TARGET\"] = y_apps_test[:, 1]\n\n    return df_off_preds, clf, test_res","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_off_preds, clf, test_res = KFold_RUS_RandomForest_model(df=apps_train, nfolds=5, random_state=10, drop_columns_arr=['TARGET', 'SK_ID_CURR'], target_col='TARGET', apps_all_test=apps_all_test)\ndf_off_preds.to_csv(\"/kaggle/working/KFold_RUS_RandomForest_train.csv\", index=False)\ntest_res.to_csv(\"/kaggle/working/KFold_RUS_RandomForest_test.csv\", index=False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# SMOTE\ndef KFold_SMOTE_RandomForest_model(df, nfolds, random_state, drop_columns_arr, target_col, apps_all_test):\n    df_off_preds = pd.DataFrame()\n    df_off_preds['SK_ID_CURR'] = df['SK_ID_CURR']\n\n    # deal with missing data\n    df = df.replace([np.inf, -np.inf], np.nan)\n    # Fill NaN with median value\n    df = df.fillna(-999)\n\n    ftr_app = df.drop(drop_columns_arr, axis=1)  # feature dateset\n    target_app = df[target_col]                  # target datasets\n    # apply KFolds\n    folds = KFold(n_splits = nfolds, shuffle=True, random_state = random_state)\n    \n    oof_preds_proba = np.zeros(ftr_app.shape[0])\n    auc_scores = []\n\n    clf = RandomForestClassifier(n_estimators=1000\n           , criterion='gini'\n           , max_depth=10\n           , min_samples_split=10\n           , min_samples_leaf=30\n           )\n    \n    smote = SMOTE()\n    \n    for fold_idx, (train_idx , valid_idx) in enumerate(folds.split(ftr_app, target_app)):\n        print(\"# iteration\", fold_idx, 'starts')\n        train_x = ftr_app.iloc[train_idx, :]\n        train_y = target_app.iloc[train_idx]\n        valid_x = ftr_app.iloc[valid_idx, :]\n        valid_y = target_app.iloc[valid_idx]\n        \n        train_x_resampled, train_y_resampled = smote.fit_resample(train_x, train_y)\n\n        clf.fit(train_x_resampled, train_y_resampled)\n        # Save predicted proba labels for validation set\n        oof_preds_proba[valid_idx] = clf.predict_proba(valid_x)[:, 1]\n\n        # compute AUC on validation set\n        auc_score = roc_auc_score(valid_y, oof_preds_proba[valid_idx])\n        auc_scores.append(auc_score)\n        print(f\"AUC: {auc_score}\")\n\n    print(f\"Mean AUC: {np.mean(auc_scores):.5f}\")\n\n    df_off_preds['KFold_RF_AUC_PROBA'] = oof_preds_proba\n\n    # apps_all_test \n    df_test = apps_all_test.copy()\n    test_res = pd.DataFrame()\n    # save SK_ID_CURR\n    test_res[\"SK_ID_CURR\"]=df_test[\"SK_ID_CURR\"]\n    # deal with missing value\n    df_test = df_test.replace([np.inf, -np.inf], np.nan)\n    # fill NaN with median value\n    df_test = df_test.fillna(-999)\n  \n    X_apps_test = df_test.drop(\"SK_ID_CURR\", axis=1)\n\n    y_apps_test = clf.predict_proba(X_apps_test)\n    test_res[f\"TARGET\"] = y_apps_test[:, 1]\n\n    return df_off_preds, clf, test_res","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_off_preds, clf, test_res = KFold_SMOTE_RandomForest_model(df=apps_train, nfolds=5, random_state=10, drop_columns_arr=['TARGET', 'SK_ID_CURR'], target_col='TARGET', apps_all_test=apps_all_test)\ndf_off_preds.to_csv(\"/kaggle/working/KFold_SMOTE_RandomForest_train.csv\", index=False)\ntest_res.to_csv(\"/kaggle/working/KFold_SMOTE_RandomForest_test.csv\", index=False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Stratified K-Fold Cross-Validation","metadata":{}},{"cell_type":"code","source":"# No resampling method\ndef StratifiedKFold_RandomForest_model(df, nfolds, random_state, drop_columns_arr, target_col, apps_all_test):\n    df_off_preds = pd.DataFrame()\n    df_off_preds['SK_ID_CURR'] = df['SK_ID_CURR']\n\n    # deal with missing data\n    df = df.replace([np.inf, -np.inf], np.nan)\n    # Fill NaN with median value\n    df = df.fillna(-999)\n\n    ftr_app = df.drop(drop_columns_arr, axis=1)  # feature dateset\n    target_app = df[target_col]                  # target datasets\n    # apply Stratified KFold\n    folds = StratifiedKFold(n_splits = nfolds, shuffle=True, random_state = random_state)\n    \n    oof_preds_proba = np.zeros(ftr_app.shape[0])\n    auc_scores = []\n\n    clf = RandomForestClassifier(n_estimators=1000\n           , criterion='gini'\n           , max_depth=10\n           , min_samples_split=10\n           , min_samples_leaf=30\n           )\n    \n    for fold_idx, (train_idx , valid_idx) in enumerate(folds.split(ftr_app, target_app)):\n        print(\"# iteration\", fold_idx, 'starts')\n        train_x = ftr_app.iloc[train_idx, :]\n        train_y = target_app.iloc[train_idx]\n        valid_x = ftr_app.iloc[valid_idx, :]\n        valid_y = target_app.iloc[valid_idx]\n\n        clf.fit(train_x, train_y)\n        # Save predicted proba labels for validation set\n        oof_preds_proba[valid_idx] = clf.predict_proba(valid_x)[:, 1]\n\n        # compute AUC on validation set\n        auc_score = roc_auc_score(valid_y, oof_preds_proba[valid_idx])\n        auc_scores.append(auc_score)\n        print(f\"AUC: {auc_score}\")\n\n    print(f\"Mean AUC: {np.mean(auc_scores):.5f}\")\n\n    df_off_preds['KFold_RF_AUC_PROBA'] = oof_preds_proba\n\n    # apps_all_test \n    df_test = apps_all_test.copy()\n    test_res = pd.DataFrame()\n    # save SK_ID_CURR\n    test_res[\"SK_ID_CURR\"]=df_test[\"SK_ID_CURR\"]\n    # deal with missing value\n    df_test = df_test.replace([np.inf, -np.inf], np.nan)\n    # fill NaN with median value\n    df_test = df_test.fillna(-999)\n  \n    X_apps_test = df_test.drop(\"SK_ID_CURR\", axis=1)\n\n    y_apps_test = clf.predict_proba(X_apps_test)\n    test_res[f\"TARGET\"] = y_apps_test[:, 1]\n\n    return df_off_preds, clf, test_res","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_off_preds, clf, test_res = StratifiedKFold_RandomForest_model(df=apps_train, nfolds=5, random_state=10, drop_columns_arr=['TARGET', 'SK_ID_CURR'], target_col='TARGET', apps_all_test=apps_all_test)\ndf_off_preds.to_csv(\"/kaggle/working/StratifiedKFold_RandomForest_train.csv\", index=False)\ntest_res.to_csv(\"/kaggle/working/StratifiedKFold_RandomForest_test.csv\", index=False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Random Over Sampling\ndef StratifiedKFold_ROS_RandomForest_model(df, nfolds, random_state, drop_columns_arr, target_col, apps_all_test):\n    df_off_preds = pd.DataFrame()\n    df_off_preds['SK_ID_CURR'] = df['SK_ID_CURR']\n\n    # deal with missing data\n    df = df.replace([np.inf, -np.inf], np.nan)\n    # Fill NaN with median value\n    df = df.fillna(-999)\n\n    ftr_app = df.drop(drop_columns_arr, axis=1)  # feature dateset\n    target_app = df[target_col]                  # target datasets\n    # apply Stratified KFold\n    folds = StratifiedKFold(n_splits = nfolds, shuffle=True, random_state = random_state)\n    \n    oof_preds_proba = np.zeros(ftr_app.shape[0])\n    auc_scores = []\n\n    clf = RandomForestClassifier(n_estimators=1000\n           , criterion='gini'\n           , max_depth=10\n           , min_samples_split=10\n           , min_samples_leaf=30\n           )\n    \n    ros = RandomOverSampler()\n    \n    for fold_idx, (train_idx , valid_idx) in enumerate(folds.split(ftr_app, target_app)):\n        print(\"# iteration\", fold_idx, 'starts')\n        train_x = ftr_app.iloc[train_idx, :]\n        train_y = target_app.iloc[train_idx]\n        valid_x = ftr_app.iloc[valid_idx, :]\n        valid_y = target_app.iloc[valid_idx]\n        \n        train_x_resampled, train_y_resampled = ros.fit_resample(train_x, train_y)\n\n        clf.fit(train_x_resampled, train_y_resampled)\n        # Save predicted proba labels for validation set\n        oof_preds_proba[valid_idx] = clf.predict_proba(valid_x)[:, 1]\n\n        # compute AUC on validation set\n        auc_score = roc_auc_score(valid_y, oof_preds_proba[valid_idx])\n        auc_scores.append(auc_score)\n        print(f\"AUC: {auc_score}\")\n\n    print(f\"Mean AUC: {np.mean(auc_scores):.5f}\")\n\n    df_off_preds['KFold_RF_AUC_PROBA'] = oof_preds_proba\n\n    # apps_all_test \n    df_test = apps_all_test.copy()\n    test_res = pd.DataFrame()\n    # save SK_ID_CURR\n    test_res[\"SK_ID_CURR\"]=df_test[\"SK_ID_CURR\"]\n    # deal with missing value\n    df_test = df_test.replace([np.inf, -np.inf], np.nan)\n    # fill NaN with median value\n    df_test = df_test.fillna(-999)\n  \n    X_apps_test = df_test.drop(\"SK_ID_CURR\", axis=1)\n\n    y_apps_test = clf.predict_proba(X_apps_test)\n    test_res[f\"TARGET\"] = y_apps_test[:, 1]\n\n    return df_off_preds, clf, test_res","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_off_preds, clf, test_res = StratifiedKFold_ROS_RandomForest_model(df=apps_train, nfolds=5, random_state=10, drop_columns_arr=['TARGET', 'SK_ID_CURR'], target_col='TARGET', apps_all_test=apps_all_test)\ndf_off_preds.to_csv(\"/kaggle/working/StratifiedKFold_ROS_RandomForest_train.csv\", index=False)\ntest_res.to_csv(\"/kaggle/working/StratifiedKFold_ROS_RandomForest_test.csv\", index=False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Random Under Sampling\ndef StratifiedKFold_RUS_RandomForest_model(df, nfolds, random_state, drop_columns_arr, target_col, apps_all_test):\n    df_off_preds = pd.DataFrame()\n    df_off_preds['SK_ID_CURR'] = df['SK_ID_CURR']\n\n    # deal with missing data\n    df = df.replace([np.inf, -np.inf], np.nan)\n    # Fill NaN with median value\n    df = df.fillna(-999)\n\n    ftr_app = df.drop(drop_columns_arr, axis=1)  # feature dateset\n    target_app = df[target_col]                  # target datasets\n    # apply Stratified KFold\n    folds = StratifiedKFold(n_splits = nfolds, shuffle=True, random_state = random_state)\n    \n    oof_preds_proba = np.zeros(ftr_app.shape[0])\n    auc_scores = []\n\n    clf = RandomForestClassifier(n_estimators=1000\n           , criterion='gini'\n           , max_depth=10\n           , min_samples_split=10\n           , min_samples_leaf=30\n           )\n    \n    rus = RandomUnderSampler(random_state=42)\n    \n    for fold_idx, (train_idx , valid_idx) in enumerate(folds.split(ftr_app, target_app)):\n        print(\"# iteration\", fold_idx, 'starts')\n        train_x = ftr_app.iloc[train_idx, :]\n        train_y = target_app.iloc[train_idx]\n        valid_x = ftr_app.iloc[valid_idx, :]\n        valid_y = target_app.iloc[valid_idx]\n        \n        train_x_resampled, train_y_resampled = rus.fit_resample(train_x, train_y)\n\n        clf.fit(train_x_resampled, train_y_resampled)\n        # Save predicted proba labels for validation set\n        oof_preds_proba[valid_idx] = clf.predict_proba(valid_x)[:, 1]\n\n        # compute AUC on validation set\n        auc_score = roc_auc_score(valid_y, oof_preds_proba[valid_idx])\n        auc_scores.append(auc_score)\n        print(f\"AUC: {auc_score}\")\n\n    print(f\"Mean AUC: {np.mean(auc_scores):.5f}\")\n\n    df_off_preds['KFold_RF_AUC_PROBA'] = oof_preds_proba\n\n    # apps_all_test \n    df_test = apps_all_test.copy()\n    test_res = pd.DataFrame()\n    # save SK_ID_CURR\n    test_res[\"SK_ID_CURR\"]=df_test[\"SK_ID_CURR\"]\n    # deal with missing value\n    df_test = df_test.replace([np.inf, -np.inf], np.nan)\n    # fill NaN with median value\n    df_test = df_test.fillna(-999)\n  \n    X_apps_test = df_test.drop(\"SK_ID_CURR\", axis=1)\n\n    y_apps_test = clf.predict_proba(X_apps_test)\n    test_res[f\"TARGET\"] = y_apps_test[:, 1]\n\n    return df_off_preds, clf, test_res","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_off_preds, clf, test_res = StratifiedKFold_RUS_RandomForest_model(df=apps_train, nfolds=5, random_state=10, drop_columns_arr=['TARGET', 'SK_ID_CURR'], target_col='TARGET', apps_all_test=apps_all_test)\ndf_off_preds.to_csv(\"/kaggle/working/StratifiedKFold_RUS_RandomForest_train.csv\", index=False)\ntest_res.to_csv(\"/kaggle/working/StratifiedKFold_RUS_RandomForest_test.csv\", index=False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# SMOTE\ndef StratifiedKFold_SMOTE_RandomForest_model(df, nfolds, random_state, drop_columns_arr, target_col, apps_all_test):\n    df_off_preds = pd.DataFrame()\n    df_off_preds['SK_ID_CURR'] = df['SK_ID_CURR']\n\n    # deal with missing data\n    df = df.replace([np.inf, -np.inf], np.nan)\n    # Fill NaN with median value\n    df = df.fillna(-999)\n\n    ftr_app = df.drop(drop_columns_arr, axis=1)  # feature dateset\n    target_app = df[target_col]                  # target datasets\n    # apply Stratified KFold\n    folds = StratifiedKFold(n_splits = nfolds, shuffle=True, random_state = random_state)\n    \n    oof_preds_proba = np.zeros(ftr_app.shape[0])\n    auc_scores = []\n\n    clf = RandomForestClassifier(n_estimators=1000\n           , criterion='gini'\n           , max_depth=10\n           , min_samples_split=10\n           , min_samples_leaf=30\n           )\n    \n    smote = SMOTE()\n    \n    for fold_idx, (train_idx , valid_idx) in enumerate(folds.split(ftr_app, target_app)):\n        print(\"# iteration\", fold_idx, 'starts')\n        train_x = ftr_app.iloc[train_idx, :]\n        train_y = target_app.iloc[train_idx]\n        valid_x = ftr_app.iloc[valid_idx, :]\n        valid_y = target_app.iloc[valid_idx]\n        \n        train_x_resampled, train_y_resampled = smote.fit_resample(train_x, train_y)\n\n        clf.fit(train_x_resampled, train_y_resampled)\n        # Save predicted proba labels for validation set\n        oof_preds_proba[valid_idx] = clf.predict_proba(valid_x)[:, 1]\n\n        # compute AUC on validation set\n        auc_score = roc_auc_score(valid_y, oof_preds_proba[valid_idx])\n        auc_scores.append(auc_score)\n        print(f\"AUC: {auc_score}\")\n\n    print(f\"Mean AUC: {np.mean(auc_scores):.5f}\")\n\n    df_off_preds['KFold_RF_AUC_PROBA'] = oof_preds_proba\n\n    # apps_all_test \n    df_test = apps_all_test.copy()\n    test_res = pd.DataFrame()\n    # save SK_ID_CURR\n    test_res[\"SK_ID_CURR\"]=df_test[\"SK_ID_CURR\"]\n    # deal with missing value\n    df_test = df_test.replace([np.inf, -np.inf], np.nan)\n    # fill NaN with median value\n    df_test = df_test.fillna(-999)\n  \n    X_apps_test = df_test.drop(\"SK_ID_CURR\", axis=1)\n\n    y_apps_test = clf.predict_proba(X_apps_test)\n    test_res[f\"TARGET\"] = y_apps_test[:, 1]\n\n    return df_off_preds, clf, test_res","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_off_preds, clf, test_res = StratifiedKFold_SMOTE_RandomForest_model(df=apps_train, nfolds=5, random_state=10, drop_columns_arr=['TARGET', 'SK_ID_CURR'], target_col='TARGET', apps_all_test=apps_all_test)\ndf_off_preds.to_csv(\"/kaggle/working/StratifiedKFold_SMOTE_RandomForest.csv\", index=False)\ntest_res.to_csv(\"/kaggle/working/StratifiedKFold_SMOTE_RandomForest_test.csv\", index=False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Bagged Neural Networks","metadata":{}},{"cell_type":"markdown","source":"### K-Fold Cross-Validation","metadata":{}},{"cell_type":"code","source":"# No resampling method\ndef KFold_MLP_CNN_model(df, nfolds, random_state, drop_columns_arr, target_col, apps_all_test):\n    # deal with missing data\n    df = df.replace([np.inf, -np.inf], np.nan)\n    # Fill NaN with median value\n    df = df.fillna(-999)\n\n    df_off_preds = pd.DataFrame()\n    df_off_preds['SK_ID_CURR'] = df['SK_ID_CURR']\n\n    ftr_app = df.drop(drop_columns_arr, axis=1)  # feature dateset\n    target_app = df[target_col]                  # target datasets\n    # apply KFold\n    folds = KFold(n_splits = nfolds, shuffle=True, random_state = random_state)\n\n    # Define the neural network architecture\n    nn = MLPClassifier(hidden_layer_sizes=(256, 128, 64, 32), activation='logistic', solver='adam', max_iter=200, early_stopping=True, verbose=500, learning_rate_init=0.008)\n\n    # Define the bagging classifier and fit the model\n    clf = BaggingClassifier(base_estimator=nn, n_estimators=100, bootstrap=True, random_state=42,verbose=500)\n    \n    auc_scores = []\n    oof_preds_proba = np.zeros((len(df), 2))\n\n    for fold_idx, (train_idx , valid_idx) in enumerate(folds.split(ftr_app, target_app)):\n        print(\"#iteration \", fold_idx, 'starts')\n        train_x = ftr_app.iloc[train_idx, :]\n        train_y = target_app.iloc[train_idx]\n        valid_x = ftr_app.iloc[valid_idx, :]\n        valid_y = target_app.iloc[valid_idx]\n\n        clf.fit(train_x, train_y)\n        # Save predicted proba labels for validation set\n        valid_preds = clf.predict_proba(valid_x)\n        valid_preds_reshaped = valid_preds.reshape(-1, 2)\n        oof_preds_proba[valid_idx] = valid_preds_reshaped\n        # compute AUC on validation set\n        auc_score = roc_auc_score(valid_y, valid_preds[:,1])\n        auc_scores.append(auc_score)\n        print(f\"AUC: {auc_score}\")\n\n    # compute mean AUC across all folds\n    mean_auc = np.mean(auc_scores)\n    print(f\"Mean AUC: {mean_auc}\")\n    \n    # Return target of training set\n    df_off_preds['TARGET'] = oof_preds_proba[:,1]\n    \n    # apps_all_test \n    df_test = apps_all_test.copy()\n    test_res = pd.DataFrame()\n    # save SK_ID_CURR\n    test_res[\"SK_ID_CURR\"]=df_test[\"SK_ID_CURR\"]\n    # deal with missing value\n    df_test = df_test.replace([np.inf, -np.inf], np.nan)\n    # fill NaN with median value\n    df_test = df_test.fillna(-999)\n  \n    X_apps_test = df_test.drop(\"SK_ID_CURR\", axis=1)\n    y_apps_test = clf.predict_proba(X_apps_test)\n    test_res[f\"TARGET\"] = y_apps_test[:,1]\n\n    return df_off_preds, clf, test_res","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 128 -> 2048\ndf_off_preds, clf, test_res = KFold_MLP_CNN_model(df=apps_train, nfolds=5, random_state=10, drop_columns_arr=['TARGET', 'SK_ID_CURR'], target_col='TARGET', apps_all_test=apps_all_test)\ndf_off_preds.to_csv(\"/kaggle/working/KFold_MLP_CNN_train.csv\", index = False)\ntest_res.to_csv(\"/kaggle/working/KFold_MLP_CNN_test.csv\", index = False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Random Under Sampling\ndef KFold_RUS_MLP_CNN_model(df, nfolds, random_state, drop_columns_arr, target_col, apps_all_test):\n    # deal with missing data\n    df = df.replace([np.inf, -np.inf], np.nan)\n    # Fill NaN with median value\n    df = df.fillna(-999)\n\n    df_off_preds = pd.DataFrame()\n    df_off_preds['SK_ID_CURR'] = df['SK_ID_CURR']\n\n    ftr_app = df.drop(drop_columns_arr, axis=1)  # feature dateset\n    target_app = df[target_col]                  # target datasets\n    # apply KFolds\n    folds = KFold(n_splits = nfolds, shuffle=True, random_state = random_state)\n    # RUS\n    rus = RandomUnderSampler()\n\n    # Define the neural network architecture\n    nn = MLPClassifier(hidden_layer_sizes=(256, 128, 64, 32), activation='logistic', solver='adam', max_iter=200, early_stopping=True, verbose=500, learning_rate_init=0.008)\n\n    # Define the bagging classifier and fit the model\n    clf = BaggingClassifier(base_estimator=nn, n_estimators=100, bootstrap=True, random_state=42,verbose=500)\n    \n    auc_scores = []\n    oof_preds_proba = np.zeros((len(df), 2))\n\n    for fold_idx, (train_idx , valid_idx) in enumerate(folds.split(ftr_app, target_app)):\n        print(\"#iteration \", fold_idx, 'starts')\n        train_x = ftr_app.iloc[train_idx, :]\n        train_y = target_app.iloc[train_idx]\n        valid_x = ftr_app.iloc[valid_idx, :]\n        valid_y = target_app.iloc[valid_idx]\n        \n        train_x_resampled, train_y_resampled = rus.fit_resample(train_x, train_y)\n\n        clf.fit(train_x_resampled, train_y_resampled)\n        # Save predicted proba labels for validation set\n        valid_preds = clf.predict_proba(valid_x)\n        valid_preds_reshaped = valid_preds.reshape(-1, 2)\n        oof_preds_proba[valid_idx] = valid_preds_reshaped\n        # compute AUC on validation set\n        auc_score = roc_auc_score(valid_y, valid_preds[:,1])\n        auc_scores.append(auc_score)\n        print(f\"AUC: {auc_score}\")\n\n    # compute mean AUC across all folds\n    mean_auc = np.mean(auc_scores)\n    print(f\"Mean AUC: {mean_auc}\")\n    \n    # Return target of training set\n    df_off_preds['TARGET'] = oof_preds_proba[:,1]\n    \n    # apps_all_test \n    df_test = apps_all_test.copy()\n    test_res = pd.DataFrame()\n    # save SK_ID_CURR\n    test_res[\"SK_ID_CURR\"]=df_test[\"SK_ID_CURR\"]\n    # deal with missing value\n    df_test = df_test.replace([np.inf, -np.inf], np.nan)\n    # fill NaN with median value\n    df_test = df_test.fillna(-999)\n  \n    X_apps_test = df_test.drop(\"SK_ID_CURR\", axis=1)\n    y_apps_test = clf.predict_proba(X_apps_test)\n    test_res[f\"TARGET\"] = y_apps_test[:,1]\n\n    return df_off_preds, clf, test_res","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 128 -> 2048\ndf_off_preds, clf, test_res = KFold_RUS_MLP_CNN_model(df=apps_train, nfolds=5, random_state=10, drop_columns_arr=['TARGET', 'SK_ID_CURR'], target_col='TARGET', apps_all_test=apps_all_test)\ndf_off_preds.to_csv(\"/kaggle/working/KFold_RUS_MLP_CNN_train.csv\", index = False)\ntest_res.to_csv(\"/kaggle/working/KFold_RUS_MLP_CNN_test.csv\", index = False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Stratified K-Fold Cross-Validation","metadata":{}},{"cell_type":"code","source":"# No resampling method\ndef StratifiedKFold_MLP_CNN_model(df, nfolds, random_state, drop_columns_arr, target_col, apps_all_test):\n    # deal with missing data\n    df = df.replace([np.inf, -np.inf], np.nan)\n    # Fill NaN with median value\n    df = df.fillna(-999)\n\n    df_off_preds = pd.DataFrame()\n    df_off_preds['SK_ID_CURR'] = df['SK_ID_CURR']\n\n    ftr_app = df.drop(drop_columns_arr, axis=1)  # feature dateset\n    target_app = df[target_col]                  # target datasets\n    # apply Stratified KFold\n    folds = StratifiedKFold(n_splits = nfolds, shuffle=True, random_state = random_state)\n\n    # Define the neural network architecture\n    nn = MLPClassifier(hidden_layer_sizes=(256, 128, 64, 32), activation='logistic', solver='adam', max_iter=200, early_stopping=True, verbose=500, learning_rate_init=0.008)\n\n    # Define the bagging classifier and fit the model\n    clf = BaggingClassifier(base_estimator=nn, n_estimators=100, bootstrap=True, random_state=42,verbose=500)\n    \n    auc_scores = []\n    oof_preds_proba = np.zeros((len(df), 2))\n\n    for fold_idx, (train_idx , valid_idx) in enumerate(folds.split(ftr_app, target_app)):\n        print(\"#iteration \", fold_idx, 'starts')\n        train_x = ftr_app.iloc[train_idx, :]\n        train_y = target_app.iloc[train_idx]\n        valid_x = ftr_app.iloc[valid_idx, :]\n        valid_y = target_app.iloc[valid_idx]\n\n        clf.fit(train_x, train_y)\n        # Save predicted proba labels for validation set\n        valid_preds = clf.predict_proba(valid_x)\n        valid_preds_reshaped = valid_preds.reshape(-1, 2)\n        oof_preds_proba[valid_idx] = valid_preds_reshaped\n        # compute AUC on validation set\n        auc_score = roc_auc_score(valid_y, valid_preds[:,1])\n        auc_scores.append(auc_score)\n        print(f\"AUC: {auc_score}\")\n\n    # compute mean AUC across all folds\n    mean_auc = np.mean(auc_scores)\n    print(f\"Mean AUC: {mean_auc}\")\n    \n    # Return target of training set\n    df_off_preds['TARGET'] = oof_preds_proba[:,1]\n    \n    # apps_all_test \n    df_test = apps_all_test.copy()\n    test_res = pd.DataFrame()\n    # save SK_ID_CURR\n    test_res[\"SK_ID_CURR\"]=df_test[\"SK_ID_CURR\"]\n    # deal with missing value\n    df_test = df_test.replace([np.inf, -np.inf], np.nan)\n    # fill NaN with median value\n    df_test = df_test.fillna(-999)\n  \n    X_apps_test = df_test.drop(\"SK_ID_CURR\", axis=1)\n    y_apps_test = clf.predict_proba(X_apps_test)\n    test_res[f\"TARGET\"] = y_apps_test[:,1]\n\n    return df_off_preds, clf, test_res","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 128 -> 2048\ndf_off_preds, clf, test_res = StratifiedKFold_MLP_CNN_model(df=apps_train, nfolds=5, random_state=10, drop_columns_arr=['TARGET', 'SK_ID_CURR'], target_col='TARGET', apps_all_test=apps_all_test)\ndf_off_preds.to_csv(\"/kaggle/working/StratifiedKFold_MLP_CNN_train.csv\", index = False)\ntest_res.to_csv(\"/kaggle/working/StratifiedKFold_MLP_CNN_test.csv\", index = False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Random Under Sampling\ndef StratifiedKFold_RUS_MLP_CNN_model(df, nfolds, random_state, drop_columns_arr, target_col, apps_all_test):\n    # deal with missing data\n    df = df.replace([np.inf, -np.inf], np.nan)\n    # Fill NaN with median value\n    df = df.fillna(-999)\n\n    df_off_preds = pd.DataFrame()\n    df_off_preds['SK_ID_CURR'] = df['SK_ID_CURR']\n\n    ftr_app = df.drop(drop_columns_arr, axis=1)  # feature dateset\n    target_app = df[target_col]                  # target datasets\n    # apply Stratified KFold\n    folds = StratifiedKFold(n_splits = nfolds, shuffle=True, random_state = random_state)\n    # RUS\n    rus = RandomUnderSampler()\n\n    # Define the neural network architecture\n    nn = MLPClassifier(hidden_layer_sizes=(256, 128, 64, 32), activation='logistic', solver='adam', max_iter=200, early_stopping=True, verbose=500, learning_rate_init=0.008)\n\n    # Define the bagging classifier and fit the model\n    clf = BaggingClassifier(base_estimator=nn, n_estimators=100, bootstrap=True, random_state=42,verbose=500)\n    \n    auc_scores = []\n    oof_preds_proba = np.zeros((len(df), 2))\n\n    for fold_idx, (train_idx , valid_idx) in enumerate(folds.split(ftr_app, target_app)):\n        print(\"#iteration \", fold_idx, 'starts')\n        train_x = ftr_app.iloc[train_idx, :]\n        train_y = target_app.iloc[train_idx]\n        valid_x = ftr_app.iloc[valid_idx, :]\n        valid_y = target_app.iloc[valid_idx]\n        \n        train_x_resampled, train_y_resampled = rus.fit_resample(train_x, train_y)\n\n        clf.fit(train_x_resampled, train_y_resampled)\n        # Save predicted proba labels for validation set\n        valid_preds = clf.predict_proba(valid_x)\n        valid_preds_reshaped = valid_preds.reshape(-1, 2)\n        oof_preds_proba[valid_idx] = valid_preds_reshaped\n        # compute AUC on validation set\n        auc_score = roc_auc_score(valid_y, valid_preds[:,1])\n        auc_scores.append(auc_score)\n        print(f\"AUC: {auc_score}\")\n\n    # compute mean AUC across all folds\n    mean_auc = np.mean(auc_scores)\n    print(f\"Mean AUC: {mean_auc}\")\n    \n    # Return target of training set\n    df_off_preds['TARGET'] = oof_preds_proba[:,1]\n    \n    # apps_all_test \n    df_test = apps_all_test.copy()\n    test_res = pd.DataFrame()\n    # save SK_ID_CURR\n    test_res[\"SK_ID_CURR\"]=df_test[\"SK_ID_CURR\"]\n    # deal with missing value\n    df_test = df_test.replace([np.inf, -np.inf], np.nan)\n    # fill NaN with median value\n    df_test = df_test.fillna(-999)\n  \n    X_apps_test = df_test.drop(\"SK_ID_CURR\", axis=1)\n    y_apps_test = clf.predict_proba(X_apps_test)\n    test_res[f\"TARGET\"] = y_apps_test[:,1]\n\n    return df_off_preds, clf, test_res","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 128 -> 2048\ndf_off_preds, clf, test_res = StratifiedKFold_RUS_MLP_CNN_model(df=apps_train, nfolds=5, random_state=10, drop_columns_arr=['TARGET', 'SK_ID_CURR'], target_col='TARGET', apps_all_test=apps_all_test)\ndf_off_preds.to_csv(\"/kaggle/working/StratifiedKFold_RUS_MLP_CNN_train.csv\", index = False)\ntest_res.to_csv(\"/kaggle/working/StratifiedKFold_RUS_MLP_CNN_test.csv\", index = False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Boosting Algorithms","metadata":{}},{"cell_type":"markdown","source":"## AdaBoost","metadata":{}},{"cell_type":"markdown","source":"### K-Fold Cross-Validation","metadata":{}},{"cell_type":"code","source":"# No resampling method\ndef KFold_AdaBoost_model(df, nfolds, random_state, drop_columns_arr, target_col, apps_all_test):\n    # deal with missing data\n    df = df.replace([np.inf, -np.inf], np.nan)\n    # Fill NaN with median value\n    df = df.fillna(-999)\n    \n    df_off_preds = pd.DataFrame()\n    df_off_preds['SK_ID_CURR'] = df['SK_ID_CURR']\n\n    ftr_app = df.drop(drop_columns_arr, axis=1)  # feature dateset\n    target_app = df[target_col]                  # target datasets\n    # apply KFold\n    folds = KFold(n_splits = nfolds, shuffle=True, random_state = random_state)\n    \n    clf = AdaBoostClassifier(\n                              DecisionTreeClassifier(max_depth=5), n_estimators=1000,\n                              algorithm=\"SAMME.R\", learning_rate=0.08\n    )\n    \n    oof_preds = np.zeros(ftr_app.shape[0])\n    auc_scores = []\n\n    for fold_idx, (train_idx , valid_idx) in enumerate(folds.split(ftr_app)):\n        print(\"#iteration \", fold_idx, 'starts')\n        train_x = ftr_app.iloc[train_idx, :]\n        train_y = target_app.iloc[train_idx]\n        valid_x = ftr_app.iloc[valid_idx, :]\n        valid_y = target_app.iloc[valid_idx]\n\n        clf.fit(train_x, train_y)\n        # Save predicted class labels for validation set\n        oof_preds[valid_idx] = clf.predict(valid_x)\n        \n        # compute AUC on validation set\n        auc_score = roc_auc_score(valid_y, oof_preds[valid_idx])\n        auc_scores.append(auc_score)\n        print(f\"AUC: {auc_score}\")\n\n    print(f\"Mean AUC: {np.mean(auc_scores):.5f}\")\n        \n    # return Target of train set\n    df_off_preds['TARGET'] = oof_preds\n\n    # apps_all_test \n    df_test = apps_all_test.copy()\n    test_res = pd.DataFrame()\n    # save SK_ID_CURR\n    test_res[\"SK_ID_CURR\"]=df_test[\"SK_ID_CURR\"]\n    # deal with missing value\n    df_test = df_test.replace([np.inf, -np.inf], np.nan)\n    # fill NaN with median value\n    df_test = df_test.fillna(-999)\n  \n    X_apps_test = df_test.drop(\"SK_ID_CURR\", axis=1)\n\n    y_apps_test = clf.predict(X_apps_test)\n    test_res[\"TARGET\"] = y_apps_test[:, 1]\n\n    return df_off_preds, clf, test_res","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# all data no dropping columns\ndf_off_preds, clf, test_res = KFold_AdaBoost_model(df=apps_train, nfolds=5, random_state=10, drop_columns_arr=['TARGET', 'SK_ID_CURR'], target_col='TARGET', apps_all_test=apps_all_test)\ndf_off_preds.to_csv(\"/kaggle/working/KFold_AdaBoost_train.csv\", index=False)\ntest_res.to_csv(\"/kaggle/working/KFold_AdaBoost_test.csv\", index=False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Random Over Sampling\ndef KFold_ROS_AdaBoost_model(df, nfolds, random_state, drop_columns_arr, target_col, apps_all_test):\n    # deal with missing data\n    df = df.replace([np.inf, -np.inf], np.nan)\n    # Fill NaN with median value\n    df = df.fillna(-999)\n    \n    df_off_preds = pd.DataFrame()\n    df_off_preds['SK_ID_CURR'] = df['SK_ID_CURR']\n\n    ftr_app = df.drop(drop_columns_arr, axis=1)  # feature dateset\n    target_app = df[target_col]                  # target datasets\n    # apply KFold\n    folds = KFold(n_splits = nfolds, shuffle=True, random_state = random_state)\n    \n    ros = RandomOverSampler()\n    clf = AdaBoostClassifier(\n                              DecisionTreeClassifier(max_depth=5), n_estimators=200,\n                              algorithm=\"SAMME.R\", learning_rate=0.08\n    )\n    \n    oof_preds = np.zeros(ftr_app.shape[0])\n    auc_scores = []\n\n    for fold_idx, (train_idx , valid_idx) in enumerate(folds.split(ftr_app, target_app)):\n        print(\"#iteration \", fold_idx, 'starts')\n        train_x = ftr_app.iloc[train_idx, :]\n        train_y = target_app.iloc[train_idx]\n        valid_x = ftr_app.iloc[valid_idx, :]\n        valid_y = target_app.iloc[valid_idx]\n        \n        train_x_resampled, train_y_resampled = ros.fit_resample(train_x, train_y)\n        \n        clf.fit(train_x_resampled, train_y_resampled)\n        # Save predicted class labels for validation set\n        oof_preds[valid_idx] = clf.predict(valid_x)\n        \n        # compute AUC on validation set\n        auc_score = roc_auc_score(valid_y, oof_preds[valid_idx])\n        auc_scores.append(auc_score)\n        print(f\"AUC: {auc_score}\")\n\n    print(f\"Mean AUC: {np.mean(auc_scores):.5f}\")\n        \n    # return Target of train set\n    df_off_preds['TARGET'] = oof_preds\n\n    # apps_all_test \n    df_test = apps_all_test.copy()\n    test_res = pd.DataFrame()\n    # save SK_ID_CURR\n    test_res[\"SK_ID_CURR\"]=df_test[\"SK_ID_CURR\"]\n    # deal with missing value\n    df_test = df_test.replace([np.inf, -np.inf], np.nan)\n    # fill NaN with median value\n    df_test = df_test.fillna(-999)\n  \n    X_apps_test = df_test.drop(\"SK_ID_CURR\", axis=1)\n\n    y_apps_test = clf.predict(X_apps_test)\n    test_res[\"TARGET\"] = y_apps_test\n\n    return df_off_preds, clf, test_res","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_off_preds, clf, test_res = KFold_ROS_AdaBoost_model(df=apps_train, nfolds=5, random_state=10, drop_columns_arr=['TARGET', 'SK_ID_CURR'], target_col='TARGET', apps_all_test=apps_all_test)\ndf_off_preds.to_csv(\"/kaggle/working/KFold_ROS_AdaBoost_WL_DT_train.csv\", index=False)\ntest_res.to_csv(\"/kaggle/working/KFold_ROS_AdaBoost_WL_DT_test.csv\", index=False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Random Under Sampling\ndef KFold_RUS_AdaBoost_model(df, nfolds, random_state, drop_columns_arr, target_col, apps_all_test):\n    # deal with missing data\n    df = df.replace([np.inf, -np.inf], np.nan)\n    # Fill NaN with median value\n    df = df.fillna(-999)\n    \n    df_off_preds = pd.DataFrame()\n    df_off_preds['SK_ID_CURR'] = df['SK_ID_CURR']\n\n    ftr_app = df.drop(drop_columns_arr, axis=1)  # feature dateset\n    target_app = df[target_col]                  # target datasets\n    # apply KFold\n    folds = KFold(n_splits = nfolds, shuffle=True, random_state = random_state)\n    \n    rus = RandomUnderSampler()\n    clf = AdaBoostClassifier(\n                              DecisionTreeClassifier(max_depth=5), n_estimators=200,\n                              algorithm=\"SAMME.R\", learning_rate=0.08\n    )\n    \n    oof_preds = np.zeros(ftr_app.shape[0])\n    auc_scores = []\n\n    for fold_idx, (train_idx , valid_idx) in enumerate(folds.split(ftr_app, target_app)):\n        print(\"#iteration \", fold_idx, 'starts')\n        train_x = ftr_app.iloc[train_idx, :]\n        train_y = target_app.iloc[train_idx]\n        valid_x = ftr_app.iloc[valid_idx, :]\n        valid_y = target_app.iloc[valid_idx]\n        \n        train_x_resampled, train_y_resampled = rus.fit_resample(train_x, train_y)\n        \n        clf.fit(train_x_resampled, train_y_resampled)\n        # Save predicted class labels for validation set\n        oof_preds[valid_idx] = clf.predict(valid_x)\n        \n        # compute AUC on validation set\n        auc_score = roc_auc_score(valid_y, oof_preds[valid_idx])\n        auc_scores.append(auc_score)\n        print(f\"AUC: {auc_score}\")\n\n    print(f\"Mean AUC: {np.mean(auc_scores):.5f}\")\n        \n    # return Target of train set\n    df_off_preds['TARGET'] = oof_preds\n\n    # apps_all_test \n    df_test = apps_all_test.copy()\n    test_res = pd.DataFrame()\n    # save SK_ID_CURR\n    test_res[\"SK_ID_CURR\"]=df_test[\"SK_ID_CURR\"]\n    # deal with missing value\n    df_test = df_test.replace([np.inf, -np.inf], np.nan)\n    # fill NaN with median value\n    df_test = df_test.fillna(-999)\n  \n    X_apps_test = df_test.drop(\"SK_ID_CURR\", axis=1)\n\n    y_apps_test = clf.predict(X_apps_test)\n    test_res[\"TARGET\"] = y_apps_test\n\n    return df_off_preds, clf, test_res","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_off_preds, clf, test_res = KFold_RUS_AdaBoost_model(df=apps_train, nfolds=5, random_state=10, drop_columns_arr=['TARGET', 'SK_ID_CURR'], target_col='TARGET', apps_all_test=apps_all_test)\ndf_off_preds.to_csv(\"/kaggle/working/KFold_RUS_AdaBoost_WL_DT_train.csv\", index=False)\ntest_res.to_csv(\"/kaggle/working/KFold_RUS_AdaBoost_WL_DT_test.csv\", index=False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# SMOTE\ndef KFold_SMOTE_AdaBoost_model(df, nfolds, random_state, drop_columns_arr, target_col, apps_all_test):\n    # deal with missing data\n    df = df.replace([np.inf, -np.inf], np.nan)\n    # Fill NaN with median value\n    df = df.fillna(-999)\n    \n    df_off_preds = pd.DataFrame()\n    df_off_preds['SK_ID_CURR'] = df['SK_ID_CURR']\n\n    ftr_app = df.drop(drop_columns_arr, axis=1)  # feature dateset\n    target_app = df[target_col]                  # target datasets\n    # apply KFold\n    folds = KFold(n_splits = nfolds, shuffle=True, random_state = random_state)\n    \n    smote = SMOTE()\n    clf = AdaBoostClassifier(\n                              DecisionTreeClassifier(max_depth=5), n_estimators=200,\n                              algorithm=\"SAMME.R\", learning_rate=0.08\n    )\n    \n    oof_preds = np.zeros(ftr_app.shape[0])\n    auc_scores = []\n\n    for fold_idx, (train_idx , valid_idx) in enumerate(folds.split(ftr_app, target_app)):\n        print(\"#iteration \", fold_idx, 'starts')\n        train_x = ftr_app.iloc[train_idx, :]\n        train_y = target_app.iloc[train_idx]\n        valid_x = ftr_app.iloc[valid_idx, :]\n        valid_y = target_app.iloc[valid_idx]\n        \n        train_x_resampled, train_y_resampled = smote.fit_resample(train_x, train_y)\n        \n        clf.fit(train_x_resampled, train_y_resampled)\n        # Save predicted class labels for validation set\n        oof_preds[valid_idx] = clf.predict(valid_x)\n        \n        # compute AUC on validation set\n        auc_score = roc_auc_score(valid_y, oof_preds[valid_idx])\n        auc_scores.append(auc_score)\n        print(f\"AUC: {auc_score}\")\n\n    print(f\"Mean AUC: {np.mean(auc_scores):.5f}\")\n        \n    # return Target of train set\n    df_off_preds['TARGET'] = oof_preds\n\n    # apps_all_test \n    df_test = apps_all_test.copy()\n    test_res = pd.DataFrame()\n    # save SK_ID_CURR\n    test_res[\"SK_ID_CURR\"]=df_test[\"SK_ID_CURR\"]\n    # deal with missing value\n    df_test = df_test.replace([np.inf, -np.inf], np.nan)\n    # fill NaN with median value\n    df_test = df_test.fillna(-999)\n  \n    X_apps_test = df_test.drop(\"SK_ID_CURR\", axis=1)\n\n    y_apps_test = clf.predict(X_apps_test)\n    test_res[\"TARGET\"] = y_apps_test\n\n    return df_off_preds, clf, test_res","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_off_preds, clf, test_res = KFold_SMOTE_AdaBoost_model(df=apps_train, nfolds=5, random_state=10, drop_columns_arr=['TARGET', 'SK_ID_CURR'], target_col='TARGET', apps_all_test=apps_all_test)\ndf_off_preds.to_csv(\"/kaggle/working/KFold_SMOTE_AdaBoost_WL_DT_train.csv\", index=False)\ntest_res.to_csv(\"/kaggle/working/KFold_SMOTE_AdaBoost_WL_DT_test.csv\", index=False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Stratified K-Fold Cross-Validation","metadata":{}},{"cell_type":"code","source":"# No resampling method\ndef StratifiedKFold_AdaBoost_model(df, nfolds, random_state, drop_columns_arr, target_col, apps_all_test):\n    # deal with missing data\n    df = df.replace([np.inf, -np.inf], np.nan)\n    # Fill NaN with median value\n    df = df.fillna(-999)\n    \n    df_off_preds = pd.DataFrame()\n    df_off_preds['SK_ID_CURR'] = df['SK_ID_CURR']\n\n    ftr_app = df.drop(drop_columns_arr, axis=1)  # feature dateset\n    target_app = df[target_col]                  # target datasets\n    # apply StratifiedKFold\n    folds = StratifiedKFold(n_splits = nfolds, shuffle=True, random_state = random_state)\n    \n    clf = AdaBoostClassifier(\n                              DecisionTreeClassifier(max_depth=5), n_estimators=200,\n                              algorithm=\"SAMME.R\", learning_rate=0.08\n    )\n    \n    oof_preds = np.zeros(ftr_app.shape[0])\n    auc_scores = []\n\n    for fold_idx, (train_idx , valid_idx) in enumerate(folds.split(ftr_app, target_app)):\n        print(\"#iteration \", fold_idx, 'starts')\n        train_x = ftr_app.iloc[train_idx, :]\n        train_y = target_app.iloc[train_idx]\n        valid_x = ftr_app.iloc[valid_idx, :]\n        valid_y = target_app.iloc[valid_idx]\n\n        clf.fit(train_x, train_y)\n        # Save predicted class labels for validation set\n        oof_preds[valid_idx] = clf.predict(valid_x)\n        \n        # compute AUC on validation set\n        auc_score = roc_auc_score(valid_y, oof_preds[valid_idx])\n        auc_scores.append(auc_score)\n        print(f\"AUC: {auc_score}\")\n\n    print(f\"Mean AUC: {np.mean(auc_scores):.5f}\")\n        \n    # return Target of train set\n    df_off_preds['TARGET'] = oof_preds\n\n    # apps_all_test \n    df_test = apps_all_test.copy()\n    test_res = pd.DataFrame()\n    # save SK_ID_CURR\n    test_res[\"SK_ID_CURR\"]=df_test[\"SK_ID_CURR\"]\n    # deal with missing value\n    df_test = df_test.replace([np.inf, -np.inf], np.nan)\n    # fill NaN with median value\n    df_test = df_test.fillna(-999)\n  \n    X_apps_test = df_test.drop(\"SK_ID_CURR\", axis=1)\n\n    y_apps_test = clf.predict(X_apps_test)\n    test_res[\"TARGET\"] = y_apps_test\n\n    return df_off_preds, clf, test_res","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_off_preds, clf, test_res = StratifiedKFold_AdaBoost_model(df=apps_train, nfolds=5, random_state=10, drop_columns_arr=['TARGET', 'SK_ID_CURR'], target_col='TARGET', apps_all_test=apps_all_test)\ndf_off_preds.to_csv(\"/kaggle/working/StratifiedKFold_AdaBoost_train.csv\", index=False)\ntest_res.to_csv(\"/kaggle/working/StratifiedKFold_AdaBoost_test.csv\", index=False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Random Over Sampling\ndef StratifiedKFold_ROS_AdaBoost_model(df, nfolds, random_state, drop_columns_arr, target_col, apps_all_test):\n    # deal with missing data\n    df = df.replace([np.inf, -np.inf], np.nan)\n    # Fill NaN with median value\n    df = df.fillna(-999)\n    \n    df_off_preds = pd.DataFrame()\n    df_off_preds['SK_ID_CURR'] = df['SK_ID_CURR']\n\n    ftr_app = df.drop(drop_columns_arr, axis=1)  # feature dataset\n    target_app = df[target_col]                  # target dataset\n    # apply StratifiedKFold\n    folds = StratifiedKFold(n_splits=nfolds, shuffle=True, random_state=random_state)\n    \n    ros = RandomOverSampler()\n    \n    clf = AdaBoostClassifier(\n                              DecisionTreeClassifier(max_depth=10), n_estimators=1000,\n                              algorithm=\"SAMME.R\", learning_rate=0.08\n          )\n    \n    auc_scores = []\n    oof_preds = np.zeros(ftr_app.shape[0])\n\n    for fold_idx, (train_idx , valid_idx) in enumerate(folds.split(ftr_app, target_app)):\n        print(f\"Fold {fold_idx+1} starts\")\n        train_x = ftr_app.iloc[train_idx, :]\n        train_y = target_app.iloc[train_idx]\n        valid_x = ftr_app.iloc[valid_idx, :]\n        valid_y = target_app.iloc[valid_idx]\n        \n        train_x_resampled, train_y_resampled = ros.fit_resample(train_x, train_y)\n\n        clf.fit(train_x_resampled, train_y_resampled)\n        # Save predicted proba labels for validation set\n        oof_preds[valid_idx] = clf.predict_proba(valid_x)[:, 1]\n        \n        # compute AUC on validation set\n        auc_score = roc_auc_score(valid_y, oof_preds[valid_idx])\n        auc_scores.append(auc_score)\n        print(f\"AUC: {auc_score:.5f}\")\n\n    mean_auc = np.mean(auc_scores)\n    print(f\"Mean AUC: {mean_auc:.5f}\")\n    \n    # return Target of train set\n    df_off_preds['TARGET'] = oof_preds\n\n    # apps_all_test \n    df_test = apps_all_test.copy()\n    test_res = pd.DataFrame()\n    # save SK_ID_CURR\n    test_res[\"SK_ID_CURR\"] = df_test[\"SK_ID_CURR\"]\n    # replace infinity values with a large negative number\n    # deal with missing data\n    df_test = df_test.replace([np.inf, -np.inf], np.nan)\n    # Fill NaN with median value\n    df_test = df_test.fillna(-999)\n  \n    X_apps_test = df_test.drop(\"SK_ID_CURR\", axis=1)\n\n    y_apps_test = clf.predict_proba(X_apps_test)\n    test_res[\"TARGET\"] = y_apps_test[:, 1]\n\n    return df_off_preds, clf, test_res","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# all data no dropping columns\ndf_off_preds, clf, test_res = StratifiedKFold_ROS_AdaBoost_model(df=apps_train, nfolds=5, random_state=10, drop_columns_arr=['TARGET', 'SK_ID_CURR'], target_col='TARGET', apps_all_test=apps_all_test)\ndf_off_preds.to_csv(\"/kaggle/working/StratifiedKFold_ROS_AdaBoost_WL_DT_train.csv\", index=False)\ntest_res.to_csv(\"/kaggle/working/StratifiedKFold_ROS_AdaBoost_WL_DT_test.csv\", index=False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Random Under Sampling\ndef StratifiedKFold_RUS_AdaBoost_model(df, nfolds, random_state, drop_columns_arr, target_col, apps_all_test):\n    # deal with missing data\n    df = df.replace([np.inf, -np.inf], np.nan)\n    # Fill NaN with median value\n    df = df.fillna(-999)\n    \n    df_off_preds = pd.DataFrame()\n    df_off_preds['SK_ID_CURR'] = df['SK_ID_CURR']\n\n    ftr_app = df.drop(drop_columns_arr, axis=1)  # feature dateset\n    target_app = df[target_col]                  # target datasets\n    # apply StratifiedKFold\n    folds = StratifiedKFold(n_splits = nfolds, shuffle=True, random_state = random_state)\n    \n    rus = RandomUnderSampler()\n    clf = AdaBoostClassifier(\n                              DecisionTreeClassifier(max_depth=5), n_estimators=200,\n                              algorithm=\"SAMME.R\", learning_rate=0.08\n    )\n    \n    oof_preds = np.zeros(ftr_app.shape[0])\n    auc_scores = []\n\n    for fold_idx, (train_idx , valid_idx) in enumerate(folds.split(ftr_app, target_app)):\n        print(\"#iteration \", fold_idx, 'starts')\n        train_x = ftr_app.iloc[train_idx, :]\n        train_y = target_app.iloc[train_idx]\n        valid_x = ftr_app.iloc[valid_idx, :]\n        valid_y = target_app.iloc[valid_idx]\n        \n        train_x_resampled, train_y_resampled = rus.fit_resample(train_x, train_y)\n        \n        clf.fit(train_x_resampled, train_y_resampled)\n        # Save predicted class labels for validation set\n        oof_preds[valid_idx] = clf.predict(valid_x)\n        \n        # compute AUC on validation set\n        auc_score = roc_auc_score(valid_y, oof_preds[valid_idx])\n        auc_scores.append(auc_score)\n        print(f\"AUC: {auc_score}\")\n\n    print(f\"Mean AUC: {np.mean(auc_scores):.5f}\")\n        \n    # return Target of train set\n    df_off_preds['TARGET'] = oof_preds\n\n    # apps_all_test \n    df_test = apps_all_test.copy()\n    test_res = pd.DataFrame()\n    # save SK_ID_CURR\n    test_res[\"SK_ID_CURR\"]=df_test[\"SK_ID_CURR\"]\n    # deal with missing value\n    df_test = df_test.replace([np.inf, -np.inf], np.nan)\n    # fill NaN with median value\n    df_test = df_test.fillna(-999)\n  \n    X_apps_test = df_test.drop(\"SK_ID_CURR\", axis=1)\n\n    y_apps_test = clf.predict(X_apps_test)\n    test_res[\"TARGET\"] = y_apps_test\n\n    return df_off_preds, clf, test_res","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_off_preds, clf, test_res = StratifiedKFold_RUS_AdaBoost_model(df=apps_train, nfolds=5, random_state=10, drop_columns_arr=['TARGET', 'SK_ID_CURR'], target_col='TARGET', apps_all_test=apps_all_test)\ndf_off_preds.to_csv(\"/kaggle/working/StratifiedKFold_RUS_AdaBoost_WL_DT_train.csv\", index=False)\ntest_res.to_csv(\"/kaggle/working/StratifiedKFold_RUS_AdaBoost_WL_DT_test.csv\", index=False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# SMOTE\ndef StratifiedKFold_SMOTE_AdaBoost_model(df, nfolds, random_state, drop_columns_arr, target_col, apps_all_test):\n    # deal with missing data\n    df = df.replace([np.inf, -np.inf], np.nan)\n    # Fill NaN with median value\n    df = df.fillna(-999)\n    \n    df_off_preds = pd.DataFrame()\n    df_off_preds['SK_ID_CURR'] = df['SK_ID_CURR']\n\n    ftr_app = df.drop(drop_columns_arr, axis=1)  # feature dateset\n    target_app = df[target_col]                  # target datasets\n    # apply StratifiedKFold\n    folds = StratifiedKFold(n_splits = nfolds, shuffle=True, random_state = random_state)\n    \n    smote = SMOTE()\n    clf = AdaBoostClassifier(\n                              DecisionTreeClassifier(max_depth=5), n_estimators=200,\n                              algorithm=\"SAMME.R\", learning_rate=0.08\n    )\n    \n    oof_preds = np.zeros(ftr_app.shape[0])\n    auc_scores = []\n\n    for fold_idx, (train_idx , valid_idx) in enumerate(folds.split(ftr_app, target_app)):\n        print(\"#iteration \", fold_idx, 'starts')\n        train_x = ftr_app.iloc[train_idx, :]\n        train_y = target_app.iloc[train_idx]\n        valid_x = ftr_app.iloc[valid_idx, :]\n        valid_y = target_app.iloc[valid_idx]\n        \n        train_x_resampled, train_y_resampled = smote.fit_resample(train_x, train_y)\n        \n        clf.fit(train_x_resampled, train_y_resampled)\n        # Save predicted class labels for validation set\n        oof_preds[valid_idx] = clf.predict(valid_x)\n        \n        # compute AUC on validation set\n        auc_score = roc_auc_score(valid_y, oof_preds[valid_idx])\n        auc_scores.append(auc_score)\n        print(f\"AUC: {auc_score}\")\n\n    print(f\"Mean AUC: {np.mean(auc_scores):.5f}\")\n        \n    # return Target of train set\n    df_off_preds['TARGET'] = oof_preds\n\n    # apps_all_test \n    df_test = apps_all_test.copy()\n    test_res = pd.DataFrame()\n    # save SK_ID_CURR\n    test_res[\"SK_ID_CURR\"]=df_test[\"SK_ID_CURR\"]\n    # deal with missing value\n    df_test = df_test.replace([np.inf, -np.inf], np.nan)\n    # fill NaN with median value\n    df_test = df_test.fillna(-999)\n  \n    X_apps_test = df_test.drop(\"SK_ID_CURR\", axis=1)\n\n    y_apps_test = clf.predict(X_apps_test)\n    test_res[\"TARGET\"] = y_apps_test\n\n    return df_off_preds, clf, test_res","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_off_preds, clf, test_res = StratifiedKFold_SMOTE_AdaBoost_model(df=apps_train, nfolds=5, random_state=10, drop_columns_arr=['TARGET', 'SK_ID_CURR'], target_col='TARGET', apps_all_test=apps_all_test)\ndf_off_preds.to_csv(\"/kaggle/working/StratifiedKFold_SMOTE_AdaBoost_WL_DT_train.csv\", index=False)\ntest_res.to_csv(\"/kaggle/working/StratifiedKFold_SMOTE_AdaBoost_WL_DT_test.csv\", index=False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Gradient Boosting","metadata":{}},{"cell_type":"markdown","source":"### K-Fold Cross-Validation","metadata":{}},{"cell_type":"code","source":"# No resampling method\ndef KFold_GBoosting_model(df, nfolds, random_state, drop_columns_arr, target_col, apps_all_test):\n    # deal with missing data\n    df = df.replace([np.inf, -np.inf], np.nan)\n    # Fill NaN with median value\n    df = df.fillna(-999)\n    \n    df_off_preds = pd.DataFrame()\n    df_off_preds['SK_ID_CURR'] = df['SK_ID_CURR']\n\n    ftr_app = df.drop(drop_columns_arr, axis=1)  # feature dateset\n    target_app = df[target_col]                  # target datasets\n    # apply KFold\n    folds = KFold(n_splits = nfolds, shuffle=True, random_state = random_state)\n    \n    clf = GradientBoostingClassifier(n_estimators=100, learning_rate=0.008, max_depth=5, random_state=0, loss='deviance')\n    \n    print(\"AUC:\")\n    oof_preds_proba = np.zeros(ftr_app.shape[0])\n    auc_scores = []\n\n    for fold_idx, (train_idx , valid_idx) in enumerate(folds.split(ftr_app, target_app)):\n        print(\"#iteration \", fold_idx, 'starts')\n        train_x = ftr_app.iloc[train_idx, :]\n        train_y = target_app.iloc[train_idx]\n        valid_x = ftr_app.iloc[valid_idx, :]\n        valid_y = target_app.iloc[valid_idx]\n\n        clf.fit(train_x, train_y)\n        # Save predicted proba labels for validation set\n        oof_preds_proba[valid_idx] = clf.predict_proba(valid_x)[:, 1]\n        \n        # compute AUC on validation set\n        auc_score = roc_auc_score(valid_y, oof_preds_proba[valid_idx])\n        auc_scores.append(auc_score)\n        print(f\"AUC: {auc_score}\")\n\n    print(f\"Mean AUC: {np.mean(auc_scores):.5f}\")\n        \n    # return Target of train set\n    df_off_preds['TARGET'] = oof_preds_proba\n\n    # apps_all_test \n    df_test = apps_all_test.copy()\n    test_res = pd.DataFrame()\n    # save SK_ID_CURR\n    test_res[\"SK_ID_CURR\"]=df_test[\"SK_ID_CURR\"]\n    # deal with missing value\n    df_test = df_test.replace([np.inf, -np.inf], np.nan)\n    # fill NaN with median value\n    df_test = df_test.fillna(-999)\n  \n    X_apps_test = df_test.drop(\"SK_ID_CURR\", axis=1)\n\n    y_apps_test = clf.predict_proba(X_apps_test)\n    test_res[\"TARGET\"] = y_apps_test[:, 1]\n\n    return df_off_preds, clf, test_res","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_off_preds, clf, test_res = KFold_GBoosting_model(df=apps_train, nfolds=5, random_state=10, drop_columns_arr=['TARGET', 'SK_ID_CURR'], target_col='TARGET', apps_all_test=apps_all_test)\ndf_off_preds.to_csv(\"/kaggle/working/KFold_GBoosting_train.csv\", index=False)\ntest_res.to_csv(\"/kaggle/working/KFold_GBoosting_test.csv\", index=False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Random Over Sampling\ndef KFold_ROS_GBoosting_model(df, nfolds, random_state, drop_columns_arr, target_col, apps_all_test):\n    # deal with missing data\n    df = df.replace([np.inf, -np.inf], np.nan)\n    # Fill NaN with median value\n    df = df.fillna(-999)\n    \n    df_off_preds = pd.DataFrame()\n    df_off_preds['SK_ID_CURR'] = df['SK_ID_CURR']\n\n    ftr_app = df.drop(drop_columns_arr, axis=1)  # feature dateset\n    target_app = df[target_col]                  # target datasets\n    # apply KFold\n    folds = KFold(n_splits = nfolds, shuffle=True, random_state = random_state)\n    \n    ros = RandomOverSampler()\n    \n    clf = GradientBoostingClassifier(n_estimators=100, learning_rate=0.008, max_depth=5, random_state=0, loss='deviance')\n    \n    print(\"AUC:\")\n    oof_preds_proba = np.zeros(ftr_app.shape[0])\n    auc_scores = []\n\n    for fold_idx, (train_idx , valid_idx) in enumerate(folds.split(ftr_app, target_app)):\n        print(\"#iteration \", fold_idx, 'starts')\n        train_x = ftr_app.iloc[train_idx, :]\n        train_y = target_app.iloc[train_idx]\n        valid_x = ftr_app.iloc[valid_idx, :]\n        valid_y = target_app.iloc[valid_idx]\n        \n        train_x_resampled, train_y_resampled = ros.fit_resample(train_x, train_y)\n\n        clf.fit(train_x_resampled, train_y_resampled)\n        # Save predicted proba labels for validation set\n        oof_preds_proba[valid_idx] = clf.predict_proba(valid_x)[:, 1]\n        \n        # compute AUC on validation set\n        auc_score = roc_auc_score(valid_y, oof_preds_proba[valid_idx])\n        auc_scores.append(auc_score)\n        print(f\"AUC: {auc_score}\")\n\n    print(f\"Mean AUC: {np.mean(auc_scores):.5f}\")\n        \n    # return Target of train set\n    df_off_preds['TARGET'] = oof_preds_proba\n\n    # apps_all_test \n    df_test = apps_all_test.copy()\n    test_res = pd.DataFrame()\n    # save SK_ID_CURR\n    test_res[\"SK_ID_CURR\"]=df_test[\"SK_ID_CURR\"]\n    # deal with missing value\n    df_test = df_test.replace([np.inf, -np.inf], np.nan)\n    # fill NaN with median value\n    df_test = df_test.fillna(-999)\n  \n    X_apps_test = df_test.drop(\"SK_ID_CURR\", axis=1)\n\n    y_apps_test = clf.predict_proba(X_apps_test)\n    test_res[\"TARGET\"] = y_apps_test[:, 1]\n\n    return df_off_preds, clf, test_res","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_off_preds, clf, test_res = KFold_ROS_GBoosting_model(df=apps_train, nfolds=5, random_state=10, drop_columns_arr=['TARGET', 'SK_ID_CURR'], target_col='TARGET', apps_all_test=apps_all_test)\ndf_off_preds.to_csv(\"/kaggle/working/KFold_ROS_GBoosting_train.csv\", index=False)\ntest_res.to_csv(\"/kaggle/working/KFold_ROS_GBoosting_test.csv\", index=False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Random Under Sampling\ndef KFold_RUS_GBoosting_model(df, nfolds, random_state, drop_columns_arr, target_col, apps_all_test):\n    # deal with missing data\n    df = df.replace([np.inf, -np.inf], np.nan)\n    # Fill NaN with median value\n    df = df.fillna(-999)\n    \n    df_off_preds = pd.DataFrame()\n    df_off_preds['SK_ID_CURR'] = df['SK_ID_CURR']\n\n    ftr_app = df.drop(drop_columns_arr, axis=1)  # feature dateset\n    target_app = df[target_col]                  # target datasets\n    # apply KFold\n    folds = KFold(n_splits = nfolds, shuffle=True, random_state = random_state)\n    \n    rus = RandomUnderSampler(random_state = 42)\n    \n    clf = GradientBoostingClassifier(n_estimators=100, learning_rate=0.008, max_depth=5, random_state=0, loss='deviance')\n    \n    print(\"AUC:\")\n    oof_preds_proba = np.zeros(ftr_app.shape[0])\n    auc_scores = []\n\n    for fold_idx, (train_idx , valid_idx) in enumerate(folds.split(ftr_app)):\n        print(\"#iteration \", fold_idx, 'starts')\n        train_x = ftr_app.iloc[train_idx, :]\n        train_y = target_app.iloc[train_idx]\n        valid_x = ftr_app.iloc[valid_idx, :]\n        valid_y = target_app.iloc[valid_idx]\n        \n        train_x_resampled, train_y_resampled = rus.fit_resample(train_x, train_y)\n\n        clf.fit(train_x_resampled, train_y_resampled)\n        # Save predicted proba labels for validation set\n        oof_preds_proba[valid_idx] = clf.predict_proba(valid_x)[:, 1]\n        \n        # compute AUC on validation set\n        auc_score = roc_auc_score(valid_y, oof_preds_proba[valid_idx])\n        auc_scores.append(auc_score)\n        print(f\"AUC: {auc_score}\")\n\n    print(f\"Mean AUC: {np.mean(auc_scores):.5f}\")\n        \n    # return Target of train set\n    df_off_preds['TARGET'] = oof_preds_proba\n\n    # apps_all_test \n    df_test = apps_all_test.copy()\n    test_res = pd.DataFrame()\n    # save SK_ID_CURR\n    test_res[\"SK_ID_CURR\"]=df_test[\"SK_ID_CURR\"]\n    # deal with missing value\n    df_test = df_test.replace([np.inf, -np.inf], np.nan)\n    # fill NaN with median value\n    df_test = df_test.fillna(-999)\n  \n    X_apps_test = df_test.drop(\"SK_ID_CURR\", axis=1)\n\n    y_apps_test = clf.predict_proba(X_apps_test)\n    test_res[\"TARGET\"] = y_apps_test[:, 1]\n\n    return df_off_preds, clf, test_res","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_off_preds, clf, test_res = KFold_RUS_GBoosting_model(df=apps_train, nfolds=5, random_state=10, drop_columns_arr=['TARGET', 'SK_ID_CURR'], target_col='TARGET', apps_all_test=apps_all_test)\ndf_off_preds.to_csv(\"/kaggle/working/KFold_RUS_GBoosting_train.csv\", index=False)\ntest_res.to_csv(\"/kaggle/working/KFold_RUS_GBoosting_test.csv\", index=False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# SMOTE\ndef KFold_SMOTE_GBoosting_model(df, nfolds, random_state, drop_columns_arr, target_col, apps_all_test):\n    # deal with missing data\n    df = df.replace([np.inf, -np.inf], np.nan)\n    # Fill NaN with median value\n    df = df.fillna(-999)\n    \n    df_off_preds = pd.DataFrame()\n    df_off_preds['SK_ID_CURR'] = df['SK_ID_CURR']\n\n    ftr_app = df.drop(drop_columns_arr, axis=1)  # feature dateset\n    target_app = df[target_col]                  # target datasets\n    # apply KFold\n    folds = KFold(n_splits = nfolds, shuffle=True, random_state = random_state)\n    \n    smote = SMOTE()\n    \n    clf = GradientBoostingClassifier(n_estimators=100, learning_rate=0.008, max_depth=5, random_state=0, loss='deviance')\n    \n    print(\"AUC:\")\n    oof_preds_proba = np.zeros(ftr_app.shape[0])\n    auc_scores = []\n\n    for fold_idx, (train_idx , valid_idx) in enumerate(folds.split(ftr_app, target_app)):\n        print(\"#iteration \", fold_idx, 'starts')\n        train_x = ftr_app.iloc[train_idx, :]\n        train_y = target_app.iloc[train_idx]\n        valid_x = ftr_app.iloc[valid_idx, :]\n        valid_y = target_app.iloc[valid_idx]\n        \n        train_x_resampled, train_y_resampled = smote.fit_resample(train_x, train_y)\n\n        clf.fit(train_x_resampled, train_y_resampled)\n        # Save predicted proba labels for validation set\n        oof_preds_proba[valid_idx] = clf.predict_proba(valid_x)[:, 1]\n        \n        # compute AUC on validation set\n        auc_score = roc_auc_score(valid_y, oof_preds_proba[valid_idx])\n        auc_scores.append(auc_score)\n        print(f\"AUC: {auc_score}\")\n\n    print(f\"Mean AUC: {np.mean(auc_scores):.5f}\")\n        \n    # return Target of train set\n    df_off_preds['TARGET'] = oof_preds_proba\n\n    # apps_all_test \n    df_test = apps_all_test.copy()\n    test_res = pd.DataFrame()\n    # save SK_ID_CURR\n    test_res[\"SK_ID_CURR\"]=df_test[\"SK_ID_CURR\"]\n    # deal with missing value\n    df_test = df_test.replace([np.inf, -np.inf], np.nan)\n    # fill NaN with median value\n    df_test = df_test.fillna(-999)\n  \n    X_apps_test = df_test.drop(\"SK_ID_CURR\", axis=1)\n\n    y_apps_test = clf.predict_proba(X_apps_test)\n    test_res[\"TARGET\"] = y_apps_test[:, 1]\n\n    return df_off_preds, clf, test_res","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_off_preds, clf, test_res = KFold_SMOTE_GBoosting_model(df=apps_train, nfolds=5, random_state=10, drop_columns_arr=['TARGET', 'SK_ID_CURR'], target_col='TARGET', apps_all_test=apps_all_test)\ndf_off_preds.to_csv(\"/kaggle/working/KFold_SMOTE_GBoosting_train.csv\", index=False)\ntest_res.to_csv(\"/kaggle/working/KFold_SMOTE_GBoosting_test.csv\", index=False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Stratified K-Fold Cross-Validation","metadata":{}},{"cell_type":"code","source":"# No resampling method\ndef StratifiedKFold_GBoosting_model(df, nfolds, random_state, drop_columns_arr, target_col, apps_all_test):\n    # deal with missing data\n    df = df.replace([np.inf, -np.inf], np.nan)\n    # Fill NaN with median value\n    df = df.fillna(-999)\n    \n    df_off_preds = pd.DataFrame()\n    df_off_preds['SK_ID_CURR'] = df['SK_ID_CURR']\n\n    ftr_app = df.drop(drop_columns_arr, axis=1)  # feature dateset\n    target_app = df[target_col]                  # target datasets\n    # apply Stratified KFold\n    folds = StratifiedKFold(n_splits = nfolds, shuffle=True, random_state = random_state)\n    \n    clf = GradientBoostingClassifier(n_estimators=100, learning_rate=0.008, max_depth=5, random_state=0, loss='deviance')\n    \n    print(\"AUC:\")\n    oof_preds_proba = np.zeros(ftr_app.shape[0])\n    auc_scores = []\n\n    for fold_idx, (train_idx , valid_idx) in enumerate(folds.split(ftr_app, target_app)):\n        print(\"#iteration \", fold_idx, 'starts')\n        train_x = ftr_app.iloc[train_idx, :]\n        train_y = target_app.iloc[train_idx]\n        valid_x = ftr_app.iloc[valid_idx, :]\n        valid_y = target_app.iloc[valid_idx]\n\n        clf.fit(train_x, train_y)\n        # Save predicted proba labels for validation set\n        oof_preds_proba[valid_idx] = clf.predict_proba(valid_x)[:, 1]\n        \n        # compute AUC on validation set\n        auc_score = roc_auc_score(valid_y, oof_preds_proba[valid_idx])\n        auc_scores.append(auc_score)\n        print(f\"AUC: {auc_score}\")\n\n    print(f\"Mean AUC: {np.mean(auc_scores):.5f}\")\n        \n    # return Target of train set\n    df_off_preds['TARGET'] = oof_preds_proba\n\n    # apps_all_test \n    df_test = apps_all_test.copy()\n    test_res = pd.DataFrame()\n    # save SK_ID_CURR\n    test_res[\"SK_ID_CURR\"]=df_test[\"SK_ID_CURR\"]\n    # deal with missing value\n    df_test = df_test.replace([np.inf, -np.inf], np.nan)\n    # fill NaN with median value\n    df_test = df_test.fillna(-999)\n  \n    X_apps_test = df_test.drop(\"SK_ID_CURR\", axis=1)\n\n    y_apps_test = clf.predict_proba(X_apps_test)\n    test_res[\"TARGET\"] = y_apps_test[:, 1]\n\n    return df_off_preds, clf, test_res","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_off_preds, clf, test_res = StratifiedKFold_GBoosting_model(df=apps_train, nfolds=5, random_state=10, drop_columns_arr=['TARGET', 'SK_ID_CURR'], target_col='TARGET', apps_all_test=apps_all_test)\ndf_off_preds.to_csv(\"/kaggle/working/StratifiedKFold_GBoosting_train.csv\", index=False)\ntest_res.to_csv(\"/kaggle/working/StratifiedKFold_GBoosting_test.csv\", index=False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Random Over Sampling\ndef StratifiedKFold_ROS_GBoosting_model(df, nfolds, random_state, drop_columns_arr, target_col, apps_all_test):\n    # deal with missing data\n    df = df.replace([np.inf, -np.inf], np.nan)\n    # Fill NaN with median value\n    df = df.fillna(-999)\n    \n    df_off_preds = pd.DataFrame()\n    df_off_preds['SK_ID_CURR'] = df['SK_ID_CURR']\n\n    ftr_app = df.drop(drop_columns_arr, axis=1)  # feature dateset\n    target_app = df[target_col]                  # target datasets\n    # apply StratifiedKFold\n    folds = StratifiedKFold(n_splits = nfolds, shuffle=True, random_state = random_state)\n    \n    ros = RandomOverSampler()\n    \n    clf = GradientBoostingClassifier(n_estimators=100, learning_rate=0.008, max_depth=5, random_state=0, loss='deviance')\n    \n    print(\"AUC:\")\n    oof_preds_proba = np.zeros(ftr_app.shape[0])\n    auc_scores = []\n\n    for fold_idx, (train_idx , valid_idx) in enumerate(folds.split(ftr_app, target_app)):\n        print(\"#iteration \", fold_idx, 'starts')\n        train_x = ftr_app.iloc[train_idx, :]\n        train_y = target_app.iloc[train_idx]\n        valid_x = ftr_app.iloc[valid_idx, :]\n        valid_y = target_app.iloc[valid_idx]\n        \n        train_x_resampled, train_y_resampled = ros.fit_resample(train_x, train_y)\n\n        clf.fit(train_x_resampled, train_y_resampled)\n        # Save predicted proba labels for validation set\n        oof_preds_proba[valid_idx] = clf.predict_proba(valid_x)[:, 1]\n        \n        # compute AUC on validation set\n        auc_score = roc_auc_score(valid_y, oof_preds_proba[valid_idx])\n        auc_scores.append(auc_score)\n        print(f\"AUC: {auc_score}\")\n\n    print(f\"Mean AUC: {np.mean(auc_scores):.5f}\")\n        \n    # return Target of train set\n    df_off_preds['TARGET'] = oof_preds_proba\n\n    # apps_all_test \n    df_test = apps_all_test.copy()\n    test_res = pd.DataFrame()\n    # save SK_ID_CURR\n    test_res[\"SK_ID_CURR\"]=df_test[\"SK_ID_CURR\"]\n    # deal with missing value\n    df_test = df_test.replace([np.inf, -np.inf], np.nan)\n    # fill NaN with median value\n    df_test = df_test.fillna(-999)\n  \n    X_apps_test = df_test.drop(\"SK_ID_CURR\", axis=1)\n\n    y_apps_test = clf.predict_proba(X_apps_test)\n    test_res[\"TARGET\"] = y_apps_test[:, 1]\n\n    return df_off_preds, clf, test_res","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# all data no dropping columns\ndf_off_preds, clf, test_res = StratifiedKFold_ROS_GBoosting_model(df=apps_train, nfolds=5, random_state=10, drop_columns_arr=['TARGET', 'SK_ID_CURR'], target_col='TARGET', apps_all_test=apps_all_test)\ndf_off_preds.to_csv(\"/kaggle/working/StratifiedKFold_ROS_GBoosting_train.csv\", index=False)\ntest_res.to_csv(\"/kaggle/working/StratifiedKFold_ROS_GBoosting_test.csv\", index=False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Random Under Sampling\ndef StratifiedKFold_RUS_GBoosting_model(df, nfolds, random_state, drop_columns_arr, target_col, apps_all_test):\n    # deal with missing data\n    df = df.replace([np.inf, -np.inf], np.nan)\n    # Fill NaN with median value\n    df = df.fillna(-999)\n    \n    df_off_preds = pd.DataFrame()\n    df_off_preds['SK_ID_CURR'] = df['SK_ID_CURR']\n\n    ftr_app = df.drop(drop_columns_arr, axis=1)  # feature dateset\n    target_app = df[target_col]                  # target datasets\n    # apply StratifiedKFold\n    folds = StratifiedKFold(n_splits = nfolds, shuffle=True, random_state = random_state)\n    \n    rus = RandomUnderSampler(random_state = 42)\n    \n    clf = GradientBoostingClassifier(n_estimators=100, learning_rate=0.008, max_depth=5, random_state=0, loss='deviance')\n    \n    print(\"AUC:\")\n    oof_preds_proba = np.zeros(ftr_app.shape[0])\n    auc_scores = []\n\n    for fold_idx, (train_idx , valid_idx) in enumerate(folds.split(ftr_app, target_app)):\n        print(\"#iteration \", fold_idx, 'starts')\n        train_x = ftr_app.iloc[train_idx, :]\n        train_y = target_app.iloc[train_idx]\n        valid_x = ftr_app.iloc[valid_idx, :]\n        valid_y = target_app.iloc[valid_idx]\n        \n        train_x_resampled, train_y_resampled = rus.fit_resample(train_x, train_y)\n\n        clf.fit(train_x_resampled, train_y_resampled)\n        # Save predicted proba labels for validation set\n        oof_preds_proba[valid_idx] = clf.predict_proba(valid_x)[:, 1]\n        \n        # compute AUC on validation set\n        auc_score = roc_auc_score(valid_y, oof_preds_proba[valid_idx])\n        auc_scores.append(auc_score)\n        print(f\"AUC: {auc_score}\")\n\n    print(f\"Mean AUC: {np.mean(auc_scores):.5f}\")\n        \n    # return Target of train set\n    df_off_preds['TARGET'] = oof_preds_proba\n\n    # apps_all_test \n    df_test = apps_all_test.copy()\n    test_res = pd.DataFrame()\n    # save SK_ID_CURR\n    test_res[\"SK_ID_CURR\"]=df_test[\"SK_ID_CURR\"]\n    # deal with missing value\n    df_test = df_test.replace([np.inf, -np.inf], np.nan)\n    # fill NaN with median value\n    df_test = df_test.fillna(-999)\n  \n    X_apps_test = df_test.drop(\"SK_ID_CURR\", axis=1)\n\n    y_apps_test = clf.predict_proba(X_apps_test)\n    test_res[\"TARGET\"] = y_apps_test[:, 1]\n\n    return df_off_preds, clf, test_res","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_off_preds, clf, test_res = StratifiedKFold_RUS_GBoosting_model(df=apps_train, nfolds=5, random_state=10, drop_columns_arr=['TARGET', 'SK_ID_CURR'], target_col='TARGET', apps_all_test=apps_all_test)\ndf_off_preds.to_csv(\"/kaggle/working/StratifiedKFold_RUS_GBoosting_train.csv\", index=False)\ntest_res.to_csv(\"/kaggle/working/StratifiedKFold_RUS_GBoosting_test.csv\", index=False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# SMOTE\ndef StratifiedKFold_SMOTE_GBoosting_model(df, nfolds, random_state, drop_columns_arr, target_col, apps_all_test):\n    # deal with missing data\n    df = df.replace([np.inf, -np.inf], np.nan)\n    # Fill NaN with median value\n    df = df.fillna(-999)\n    \n    df_off_preds = pd.DataFrame()\n    df_off_preds['SK_ID_CURR'] = df['SK_ID_CURR']\n\n    ftr_app = df.drop(drop_columns_arr, axis=1)  # feature dateset\n    target_app = df[target_col]                  # target datasets\n    # apply Stratified KFold\n    folds = StratifiedKFold(n_splits = nfolds, shuffle=True, random_state = random_state)\n    \n    smote = SMOTE()\n    \n    clf = GradientBoostingClassifier(n_estimators=100, learning_rate=0.008, max_depth=5, random_state=0, loss='deviance')\n    \n    print(\"AUC:\")\n    oof_preds_proba = np.zeros(ftr_app.shape[0])\n    auc_scores = []\n\n    for fold_idx, (train_idx , valid_idx) in enumerate(folds.split(ftr_app, target_app)):\n        print(\"#iteration \", fold_idx, 'starts')\n        train_x = ftr_app.iloc[train_idx, :]\n        train_y = target_app.iloc[train_idx]\n        valid_x = ftr_app.iloc[valid_idx, :]\n        valid_y = target_app.iloc[valid_idx]\n        \n        train_x_resampled, train_y_resampled = smote.fit_resample(train_x, train_y)\n\n        clf.fit(train_x_resampled, train_y_resampled)\n        # Save predicted proba labels for validation set\n        oof_preds_proba[valid_idx] = clf.predict_proba(valid_x)[:, 1]\n        \n        # compute AUC on validation set\n        auc_score = roc_auc_score(valid_y, oof_preds_proba[valid_idx])\n        auc_scores.append(auc_score)\n        print(f\"AUC: {auc_score}\")\n\n    print(f\"Mean AUC: {np.mean(auc_scores):.5f}\")\n        \n    # return Target of train set\n    df_off_preds['TARGET'] = oof_preds_proba\n\n    # apps_all_test \n    df_test = apps_all_test.copy()\n    test_res = pd.DataFrame()\n    # save SK_ID_CURR\n    test_res[\"SK_ID_CURR\"]=df_test[\"SK_ID_CURR\"]\n    # deal with missing value\n    df_test = df_test.replace([np.inf, -np.inf], np.nan)\n    # fill NaN with median value\n    df_test = df_test.fillna(-999)\n  \n    X_apps_test = df_test.drop(\"SK_ID_CURR\", axis=1)\n\n    y_apps_test = clf.predict_proba(X_apps_test)\n    test_res[\"TARGET\"] = y_apps_test[:, 1]\n\n    return df_off_preds, clf, test_res","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_off_preds, clf, test_res = StratifiedKFold_SMOTE_GBoosting_model(df=apps_train, nfolds=5, random_state=10, drop_columns_arr=['TARGET', 'SK_ID_CURR'], target_col='TARGET', apps_all_test=apps_all_test)\ndf_off_preds.to_csv(\"/kaggle/working/StratifiedKFold_SMOTE_GBoosting_train.csv\", index=False)\ntest_res.to_csv(\"/kaggle/working/StratifiedKFold_SMOTE_GBoosting_test.csv\", index=False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## XGBoost","metadata":{}},{"cell_type":"markdown","source":"### K-Fold Cross-Validation","metadata":{}},{"cell_type":"code","source":"# No resampling method\ndef KFold_XGBoosting_model(df, nfolds, cutoff_threshold, random_state, drop_columns_arr, target_col, apps_all_test):\n    # deal with missing data\n    df = df.replace([np.inf, -np.inf], np.nan)\n    # Fill NaN with median value\n    df = df.fillna(-999)\n    \n    df_off_preds = pd.DataFrame()\n    df_off_preds['SK_ID_CURR'] = df['SK_ID_CURR']\n\n    ftr_app = df.drop(drop_columns_arr, axis=1)  # feature dateset\n    target_app = df[target_col]                  # target datasets\n    # apply KFold\n    folds = KFold(n_splits = nfolds, shuffle=True, random_state = random_state)\n    \n    clf = XGBClassifier(\n                nthread=5,\n                n_estimators=50000,\n                learning_rate=0.008,\n                max_depth = 15,\n                num_leaves=100,\n                colsample_bytree=0.5,\n                subsample=0.5,\n                max_bin=407,\n                reg_alpha=4,\n                reg_lambda=5,\n                min_child_weight= 6,\n                min_child_samples=165,\n                silent=-1,\n                verbose=-1,\n                )\n    \n    print(\"AUC:\")\n    oof_preds = np.zeros(ftr_app.shape[0])\n    oof_preds_proba = np.zeros(ftr_app.shape[0])\n\n    # Create an empty dictionary to store the feature importance scores\n    importances = {}\n\n    for fold_idx, (train_idx , valid_idx) in enumerate(folds.split(ftr_app)):\n        print(\"#iteration \", fold_idx, 'starts')\n        train_x = ftr_app.iloc[train_idx, :]\n        train_y = target_app.iloc[train_idx]\n        valid_x = ftr_app.iloc[valid_idx, :]\n        valid_y = target_app.iloc[valid_idx]\n\n        clf.fit(train_x, train_y, eval_set=[(train_x, train_y), (valid_x, valid_y)], eval_metric= 'auc', verbose= 200, early_stopping_rounds= 200)\n        # Save predicted class labels for validation set\n        oof_preds[valid_idx] = clf.predict(valid_x)\n        # Save predicted proba labels for validation set\n        oof_preds_proba[valid_idx] = clf.predict_proba(valid_x)[:, 1]\n        \n    # return Target of train set\n    df_off_preds['TARGET'] = oof_preds_proba\n\n    # apps_all_test \n    df_test = apps_all_test.copy()\n    test_res = pd.DataFrame()\n    # save SK_ID_CURR\n    test_res[\"SK_ID_CURR\"]=df_test[\"SK_ID_CURR\"]\n    # deal with missing value\n    df_test = df_test.replace([np.inf, -np.inf], np.nan)\n    # fill NaN with median value\n    df_test = df_test.fillna(-999)\n  \n    X_apps_test = df_test.drop(\"SK_ID_CURR\", axis=1)\n\n    y_apps_test = clf.predict_proba(X_apps_test)\n    test_res[\"TARGET\"] = y_apps_test[:, 1]\n\n    return df_off_preds, clf, test_res, importances","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_off_preds, clf, test_res, importances = KFold_XGBoosting_model(df=apps_train, nfolds=5, cutoff_threshold = 0.3, random_state=10, drop_columns_arr=['TARGET', 'SK_ID_CURR'], target_col='TARGET', apps_all_test=apps_all_test)\ndf_off_preds.to_csv(\"/kaggle/working/KFold_XGBoost_train.csv\", index=False)\nimportances.to_csv(\"/kaggle/working/KFold_XGBoost_test.csv\", index=False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Random Over Sampling\ndef KFold_ROS_XGBoosting_model(df, nfolds, cutoff_threshold, random_state, drop_columns_arr, target_col, apps_all_test):\n    # deal with missing data\n    df = df.replace([np.inf, -np.inf], np.nan)\n    # Fill NaN with median value\n    df = df.fillna(-999)\n    \n    df_off_preds = pd.DataFrame()\n    df_off_preds['SK_ID_CURR'] = df['SK_ID_CURR']\n\n    ftr_app = df.drop(drop_columns_arr, axis=1)  # feature dateset\n    target_app = df[target_col]                  # target datasets\n    # appl KFold\n    folds = KFold(n_splits = nfolds, shuffle=True, random_state = random_state)\n    \n    ros = RandomOverSampler()\n    \n    clf = XGBClassifier(\n                nthread=5,\n                n_estimators=50000,\n                learning_rate=0.008,\n                max_depth = 15,\n                num_leaves=100,\n                colsample_bytree=0.5,\n                subsample=0.5,\n                max_bin=407,\n                reg_alpha=4,\n                reg_lambda=5,\n                min_child_weight= 6,\n                min_child_samples=165,\n                silent=-1,\n                verbose=-1,\n                )\n    \n    print(\"AUC:\")\n    oof_preds = np.zeros(ftr_app.shape[0])\n    oof_preds_proba = np.zeros(ftr_app.shape[0])\n\n    for fold_idx, (train_idx , valid_idx) in enumerate(folds.split(ftr_app)):\n        print(\"#iteration \", fold_idx, 'starts')\n        train_x = ftr_app.iloc[train_idx, :]\n        train_y = target_app.iloc[train_idx]\n        valid_x = ftr_app.iloc[valid_idx, :]\n        valid_y = target_app.iloc[valid_idx]\n        \n        train_x_resampled, train_y_resampled = ros.fit_resample(train_x, train_y)\n\n        clf.fit(train_x_resampled, train_y_resampled, eval_set=[(train_x_resampled, train_y_resampled), (valid_x, valid_y)], eval_metric= 'auc', verbose= 200, early_stopping_rounds= 200)\n        # Save predicted class labels for validation set\n        oof_preds[valid_idx] = clf.predict(valid_x)\n        # Save predicted proba labels for validation set\n        oof_preds_proba[valid_idx] = clf.predict_proba(valid_x)[:, 1]\n        \n    # return Target of train set\n    df_off_preds['TARGET'] = oof_preds_proba\n\n    # apps_all_test \n    df_test = apps_all_test.copy()\n    test_res = pd.DataFrame()\n    # save SK_ID_CURR\n    test_res[\"SK_ID_CURR\"]=df_test[\"SK_ID_CURR\"]\n    # deal with missing value\n    df_test = df_test.replace([np.inf, -np.inf], np.nan)\n    # fill NaN with median value\n    df_test = df_test.fillna(-999)\n  \n    X_apps_test = df_test.drop(\"SK_ID_CURR\", axis=1)\n\n    y_apps_test = clf.predict_proba(X_apps_test)\n    test_res[\"TARGET\"] = y_apps_test[:, 1]\n\n    return df_off_preds, clf, test_res","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_off_preds, clf, test_res = KFold_ROS_XGBoosting_model(df=apps_train, nfolds=5, cutoff_threshold = 0.3, random_state=10, drop_columns_arr=['TARGET', 'SK_ID_CURR'], target_col='TARGET', apps_all_test=apps_all_test)\ndf_off_preds.to_csv(\"/kaggle/working/KFold_ROS_XGBoost_train.csv\", index=False)\ntest_res.to_csv(\"/kaggle/working/KFold_ROS_XGBoost_test.csv\", index=False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Random Under Sampling\ndef KFold_RUS_XGBoosting_model(df, nfolds, random_state, drop_columns_arr, target_col, apps_all_test):\n    # deal with missing data\n    df = df.replace([np.inf, -np.inf], np.nan)\n    # Fill NaN with median value\n    df = df.fillna(-999)\n    \n    df_off_preds = pd.DataFrame()\n    df_off_preds['SK_ID_CURR'] = df['SK_ID_CURR']\n\n    ftr_app = df.drop(drop_columns_arr, axis=1)  # feature dateset\n    target_app = df[target_col]                  # target datasets\n    # apply StratifiedKFold\n    folds = KFold(n_splits = nfolds, shuffle=True, random_state = random_state)\n    \n    rus = RandomUnderSampler(random_state = 42)\n    \n    clf = XGBClassifier(\n                nthread=5,\n                n_estimators=50000,\n                learning_rate=0.008,\n                max_depth = 15,\n                num_leaves=100,\n                colsample_bytree=0.5,\n                subsample=0.5,\n                max_bin=407,\n                reg_alpha=4,\n                reg_lambda=5,\n                min_child_weight= 6,\n                min_child_samples=165,\n                silent=-1,\n                verbose=-1\n                )\n    \n    print(\"AUC:\")\n    oof_preds = np.zeros(ftr_app.shape[0])\n    oof_preds_proba = np.zeros(ftr_app.shape[0])\n\n    for fold_idx, (train_idx , valid_idx) in enumerate(folds.split(ftr_app, target_app)):\n        print(\"#iteration \", fold_idx, 'starts')\n        train_x = ftr_app.iloc[train_idx, :]\n        train_y = target_app.iloc[train_idx]\n        valid_x = ftr_app.iloc[valid_idx, :]\n        valid_y = target_app.iloc[valid_idx]\n        \n        train_x_resampled, train_y_resampled = rus.fit_resample(train_x, train_y)\n\n        clf.fit(train_x_resampled, train_y_resampled, eval_set=[(train_x_resampled, train_y_resampled), (valid_x, valid_y)], eval_metric= 'auc', verbose= 200, early_stopping_rounds= 200)\n        # Save predicted class labels for validation set\n        oof_preds[valid_idx] = clf.predict(valid_x)\n        # Save predicted proba labels for validation set\n        oof_preds_proba[valid_idx] = clf.predict_proba(valid_x)[:, 1]\n        \n    # return Target of train set\n    df_off_preds['TARGET'] = oof_preds_proba\n\n    # apps_all_test \n    df_test = apps_all_test.copy()\n    test_res = pd.DataFrame()\n    # save SK_ID_CURR\n    test_res[\"SK_ID_CURR\"]=df_test[\"SK_ID_CURR\"]\n    # deal with missing value\n    df_test = df_test.replace([np.inf, -np.inf], np.nan)\n    # fill NaN with median value\n    df_test = df_test.fillna(-999)\n  \n    X_apps_test = df_test.drop(\"SK_ID_CURR\", axis=1)\n\n    y_apps_test = clf.predict_proba(X_apps_test)\n    test_res[\"TARGET\"] = y_apps_test[:, 1]\n\n    return df_off_preds, clf, test_res","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_off_preds, clf, test_res = KFold_RUS_XGBoosting_model(df=apps_train, nfolds=5, random_state=10, drop_columns_arr=['TARGET', 'SK_ID_CURR'], target_col='TARGET', apps_all_test=apps_all_test)\ndf_off_preds.to_csv(\"/kaggle/working/KFold_RUS_XGBoost_train.csv\", index=False)\ntest_res.to_csv(\"/kaggle/working/KFold_RUS_XGBoost_test.csv\", index=False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# SMOTE\ndef KFold_SMOTE_XGBoosting_model(df, nfolds, random_state, drop_columns_arr, target_col, apps_all_test):\n    # deal with missing data\n    df = df.replace([np.inf, -np.inf], np.nan)\n    # Fill NaN with median value\n    df = df.fillna(-999)\n    \n    df_off_preds = pd.DataFrame()\n    df_off_preds['SK_ID_CURR'] = df['SK_ID_CURR']\n\n    ftr_app = df.drop(drop_columns_arr, axis=1)  # feature dateset\n    target_app = df[target_col]                  # target datasets\n    # apply KFold\n    folds = KFold(n_splits = nfolds, shuffle=True, random_state = random_state)\n    \n    smote = SMOTE()\n    \n    clf = XGBClassifier(\n                nthread=5,\n                n_estimators=50000,\n                learning_rate=0.008,\n                max_depth = 15,\n                num_leaves=100,\n                colsample_bytree=0.5,\n                subsample=0.5,\n                max_bin=407,\n                reg_alpha=4,\n                reg_lambda=5,\n                min_child_weight= 6,\n                min_child_samples=165,\n                silent=-1,\n                verbose=-1\n                )\n    \n    print(\"AUC:\")\n    oof_preds = np.zeros(ftr_app.shape[0])\n    oof_preds_proba = np.zeros(ftr_app.shape[0])\n\n    for fold_idx, (train_idx , valid_idx) in enumerate(folds.split(ftr_app, target_app)):\n        print(\"#iteration \", fold_idx, 'starts')\n        train_x = ftr_app.iloc[train_idx, :]\n        train_y = target_app.iloc[train_idx]\n        valid_x = ftr_app.iloc[valid_idx, :]\n        valid_y = target_app.iloc[valid_idx]\n        \n        train_x_resampled, train_y_resampled = smote.fit_resample(train_x, train_y)\n\n        clf.fit(train_x_resampled, train_y_resampled, eval_set=[(train_x_resampled, train_y_resampled), (valid_x, valid_y)], eval_metric= 'auc', verbose= 200, early_stopping_rounds= 200)\n        # Save predicted class labels for validation set\n        oof_preds[valid_idx] = clf.predict(valid_x)\n        # Save predicted proba labels for validation set\n        oof_preds_proba[valid_idx] = clf.predict_proba(valid_x)[:, 1]\n        \n    # return Target of train set\n    df_off_preds['TARGET'] = oof_preds_proba\n\n    # apps_all_test \n    df_test = apps_all_test.copy()\n    test_res = pd.DataFrame()\n    # save SK_ID_CURR\n    test_res[\"SK_ID_CURR\"]=df_test[\"SK_ID_CURR\"]\n    # deal with missing value\n    df_test = df_test.replace([np.inf, -np.inf], np.nan)\n    # fill NaN with median value\n    df_test = df_test.fillna(-999)\n  \n    X_apps_test = df_test.drop(\"SK_ID_CURR\", axis=1)\n\n    y_apps_test = clf.predict_proba(X_apps_test)\n    test_res[\"TARGET\"] = y_apps_test[:, 1]\n\n    return df_off_preds, clf, test_res","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_off_preds, clf, test_res = KFold_SMOTE_XGBoosting_model(df=apps_train, nfolds=5, random_state=10, drop_columns_arr=['TARGET', 'SK_ID_CURR'], target_col='TARGET', apps_all_test=apps_all_test)\ndf_off_preds.to_csv(\"/kaggle/working/KFold_SMOTE_XGBoost_train.csv\", index=False)\ntest_res.to_csv(\"/kaggle/working/KFold_SMOTE_XGBoost_test.csv\", index=False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Stratified K-Fold Cross-Validation","metadata":{}},{"cell_type":"code","source":"# No resampling method\ndef StratifiedKFold_XGBoosting_model(df, nfolds, cutoff_threshold, random_state, drop_columns_arr, target_col, apps_all_test):\n    # deal with missing data\n    df = df.replace([np.inf, -np.inf], np.nan)\n    # Fill NaN with median value\n    df = df.fillna(-999)\n    \n    df_off_preds = pd.DataFrame()\n    df_off_preds['SK_ID_CURR'] = df['SK_ID_CURR']\n\n    ftr_app = df.drop(drop_columns_arr, axis=1)  # feature dateset\n    target_app = df[target_col]                  # target datasets\n    # apply StratifiedKFold\n    folds = StratifiedKFold(n_splits = nfolds, shuffle=True, random_state = random_state)\n    \n    clf = XGBClassifier(\n                nthread=5,\n                n_estimators=50000,\n                learning_rate=0.008,\n                max_depth = 15,\n                num_leaves=100,\n                colsample_bytree=0.5,\n                subsample=0.5,\n                max_bin=407,\n                reg_alpha=4,\n                reg_lambda=5,\n                min_child_weight= 6,\n                min_child_samples=165,\n                silent=-1,\n                verbose=-1,\n                )\n    \n    print(\"AUC:\")\n    oof_preds = np.zeros(ftr_app.shape[0])\n    oof_preds_proba = np.zeros(ftr_app.shape[0])\n\n    # Create an empty dictionary to store the feature importance scores\n    importances = {}\n\n    for fold_idx, (train_idx , valid_idx) in enumerate(folds.split(ftr_app, target_app)):\n        print(\"#iteration \", fold_idx, 'starts')\n        train_x = ftr_app.iloc[train_idx, :]\n        train_y = target_app.iloc[train_idx]\n        valid_x = ftr_app.iloc[valid_idx, :]\n        valid_y = target_app.iloc[valid_idx]\n\n        clf.fit(train_x, train_y, eval_set=[(train_x, train_y), (valid_x, valid_y)], eval_metric= 'auc', verbose= 200, early_stopping_rounds= 200)\n        # Save predicted class labels for validation set\n        oof_preds[valid_idx] = clf.predict(valid_x)\n        # Save predicted proba labels for validation set\n        oof_preds_proba[valid_idx] = clf.predict_proba(valid_x)[:, 1]\n        \n    # return Target of train set\n    df_off_preds['TARGET'] = oof_preds_proba\n\n    # apps_all_test \n    df_test = apps_all_test.copy()\n    test_res = pd.DataFrame()\n    # save SK_ID_CURR\n    test_res[\"SK_ID_CURR\"]=df_test[\"SK_ID_CURR\"]\n    # deal with missing value\n    df_test = df_test.replace([np.inf, -np.inf], np.nan)\n    # fill NaN with median value\n    df_test = df_test.fillna(-999)\n  \n    X_apps_test = df_test.drop(\"SK_ID_CURR\", axis=1)\n\n    y_apps_test = clf.predict_proba(X_apps_test)\n    test_res[\"TARGET\"] = y_apps_test[:, 1]\n\n    return df_off_preds, clf, test_res, importances","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_off_preds, clf, test_res, importances = StratifiedKFold_XGBoosting_model(df=apps_train, nfolds=5, cutoff_threshold = 0.3, random_state=10, drop_columns_arr=['TARGET', 'SK_ID_CURR'], target_col='TARGET', apps_all_test=apps_all_test)\ndf_off_preds.to_csv(\"/kaggle/working/StratifiedKFold_XGBoost_train.csv\", index=False)\ntest_res.to_csv(\"/kaggle/working/StratifiedKFold_XGBoost_test.csv\", index=False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Random Over Sampling\ndef StratifiedKFold_ROS_XGBoosting_model(df, nfolds, random_state, drop_columns_arr, target_col, apps_all_test):\n    # deal with missing data\n    df = df.replace([np.inf, -np.inf], np.nan)\n    # Fill NaN with median value\n    df = df.fillna(-999)\n    \n    df_off_preds = pd.DataFrame()\n    df_off_preds['SK_ID_CURR'] = df['SK_ID_CURR']\n\n    ftr_app = df.drop(drop_columns_arr, axis=1)  # feature dateset\n    target_app = df[target_col]                  # target datasets\n    # apply Stratified KFold\n    folds = StratifiedKFold(n_splits = nfolds, shuffle=True, random_state = random_state)\n    \n    ros = RandomOverSampler()\n    \n    clf = XGBClassifier(\n                nthread=5,\n                n_estimators=50000,\n                learning_rate=0.008,\n                max_depth = 15,\n                num_leaves=100,\n                colsample_bytree=0.5,\n                subsample=0.5,\n                max_bin=407,\n                reg_alpha=4,\n                reg_lambda=5,\n                min_child_weight= 6,\n                min_child_samples=165,\n                silent=-1,\n                verbose=-1\n                )\n    \n    print(\"AUC:\")\n    oof_preds = np.zeros(ftr_app.shape[0])\n    oof_preds_proba = np.zeros(ftr_app.shape[0])\n\n    for fold_idx, (train_idx , valid_idx) in enumerate(folds.split(ftr_app, target_app)):\n        print(\"#iteration \", fold_idx, 'starts')\n        train_x = ftr_app.iloc[train_idx, :]\n        train_y = target_app.iloc[train_idx]\n        valid_x = ftr_app.iloc[valid_idx, :]\n        valid_y = target_app.iloc[valid_idx]\n        \n        train_x_resampled, train_y_resampled = ros.fit_resample(train_x, train_y)\n\n        clf.fit(train_x_resampled, train_y_resampled, eval_set=[(train_x_resampled, train_y_resampled), (valid_x, valid_y)], eval_metric= 'auc', verbose= 200, early_stopping_rounds= 200)\n        # Save predicted class labels for validation set\n        oof_preds[valid_idx] = clf.predict(valid_x)\n        # Save predicted proba labels for validation set\n        oof_preds_proba[valid_idx] = clf.predict_proba(valid_x)[:, 1]\n        \n    # return Target of train set\n    df_off_preds['TARGET'] = oof_preds_proba\n\n    # apps_all_test \n    df_test = apps_all_test.copy()\n    test_res = pd.DataFrame()\n    # save SK_ID_CURR\n    test_res[\"SK_ID_CURR\"]=df_test[\"SK_ID_CURR\"]\n    # deal with missing value\n    df_test = df_test.replace([np.inf, -np.inf], np.nan)\n    # fill NaN with median value\n    df_test = df_test.fillna(-999)\n  \n    X_apps_test = df_test.drop(\"SK_ID_CURR\", axis=1)\n\n    y_apps_test = clf.predict_proba(X_apps_test)\n    test_res[\"TARGET\"] = y_apps_test[:, 1]\n\n    return df_off_preds, clf, test_res","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_off_preds, clf, test_res = StratifiedKFold_ROS_XGBoosting_model(df=apps_train, nfolds=5, random_state=10, drop_columns_arr=['TARGET', 'SK_ID_CURR'], target_col='TARGET', apps_all_test=apps_all_test)\ndf_off_preds.to_csv(\"/kaggle/working/StratifiedKFold_ROS_XGBoost_train.csv\", index=False)\ntest_res.to_csv(\"/kaggle/working/StratifiedKFold_ROS_XGBoost_test.csv\", index=False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Random Under Sampling\ndef StratifiedKFold_RUS_XGBoosting_model(df, nfolds, random_state, drop_columns_arr, target_col, apps_all_test):\n    # deal with missing data\n    df = df.replace([np.inf, -np.inf], np.nan)\n    # Fill NaN with median value\n    df = df.fillna(-999)\n    \n    df_off_preds = pd.DataFrame()\n    df_off_preds['SK_ID_CURR'] = df['SK_ID_CURR']\n\n    ftr_app = df.drop(drop_columns_arr, axis=1)  # feature dateset\n    target_app = df[target_col]                  # target datasets\n    # apply Stratified KFold\n    folds = StratifiedKFold(n_splits = nfolds, shuffle=True, random_state = random_state)\n    \n    rus = RandomUnderSampler(random_state = 42)\n    \n    clf = XGBClassifier(\n                nthread=5,\n                n_estimators=50000,\n                learning_rate=0.008,\n                max_depth = 15,\n                num_leaves=100,\n                colsample_bytree=0.5,\n                subsample=0.5,\n                max_bin=407,\n                reg_alpha=4,\n                reg_lambda=5,\n                min_child_weight= 6,\n                min_child_samples=165,\n                silent=-1,\n                verbose=-1\n                )\n    \n    print(\"AUC:\")\n    oof_preds = np.zeros(ftr_app.shape[0])\n    oof_preds_proba = np.zeros(ftr_app.shape[0])\n\n    for fold_idx, (train_idx , valid_idx) in enumerate(folds.split(ftr_app, target_app)):\n        print(\"#iteration \", fold_idx, 'starts')\n        train_x = ftr_app.iloc[train_idx, :]\n        train_y = target_app.iloc[train_idx]\n        valid_x = ftr_app.iloc[valid_idx, :]\n        valid_y = target_app.iloc[valid_idx]\n        \n        train_x_resampled, train_y_resampled = rus.fit_resample(train_x, train_y)\n\n        clf.fit(train_x_resampled, train_y_resampled, eval_set=[(train_x_resampled, train_y_resampled), (valid_x, valid_y)], eval_metric= 'auc', verbose= 200, early_stopping_rounds= 200)\n        # Save predicted class labels for validation set\n        oof_preds[valid_idx] = clf.predict(valid_x)\n        # Save predicted proba labels for validation set\n        oof_preds_proba[valid_idx] = clf.predict_proba(valid_x)[:, 1]\n        \n    # return Target of train set\n    df_off_preds['TARGET'] = oof_preds_proba\n\n    # apps_all_test \n    df_test = apps_all_test.copy()\n    test_res = pd.DataFrame()\n    # save SK_ID_CURR\n    test_res[\"SK_ID_CURR\"]=df_test[\"SK_ID_CURR\"]\n    # deal with missing value\n    df_test = df_test.replace([np.inf, -np.inf], np.nan)\n    # fill NaN with median value\n    df_test = df_test.fillna(-999)\n  \n    X_apps_test = df_test.drop(\"SK_ID_CURR\", axis=1)\n\n    y_apps_test = clf.predict_proba(X_apps_test)\n    test_res[\"TARGET\"] = y_apps_test[:, 1]\n\n    return df_off_preds, clf, test_res","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_off_preds, clf, test_res = StratifiedKFold_RUS_XGBoosting_model(df=apps_train, nfolds=5, random_state=10, drop_columns_arr=['TARGET', 'SK_ID_CURR'], target_col='TARGET', apps_all_test=apps_all_test)\ndf_off_preds.to_csv(\"/kaggle/working/StratifiedKFold_RUS_XGBoost_train.csv\", index=False)\ntest_res.to_csv(\"/kaggle/working/StratifiedKFold_RUS_XGBoost_test.csv\", index=False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# SMOTE\ndef StratifiedKFold_SMOTE_XGBoosting_model(df, nfolds, random_state, drop_columns_arr, target_col, apps_all_test):\n    # deal with missing data\n    df = df.replace([np.inf, -np.inf], np.nan)\n    # Fill NaN with median value\n    df = df.fillna(-999)\n    \n    df_off_preds = pd.DataFrame()\n    df_off_preds['SK_ID_CURR'] = df['SK_ID_CURR']\n\n    ftr_app = df.drop(drop_columns_arr, axis=1)  # feature dateset\n    target_app = df[target_col]                  # target datasets\n    # apply Stratified KFold\n    folds = StratifiedKFold(n_splits = nfolds, shuffle=True, random_state = random_state)\n    \n    smote = SMOTE()\n    \n    clf = XGBClassifier(\n                nthread=5,\n                n_estimators=50000,\n                learning_rate=0.008,\n                max_depth = 15,\n                num_leaves=100,\n                colsample_bytree=0.5,\n                subsample=0.5,\n                max_bin=407,\n                reg_alpha=4,\n                reg_lambda=5,\n                min_child_weight= 6,\n                min_child_samples=165,\n                silent=-1,\n                verbose=-1\n                )\n    \n    print(\"AUC:\")\n    oof_preds = np.zeros(ftr_app.shape[0])\n    oof_preds_proba = np.zeros(ftr_app.shape[0])\n\n    for fold_idx, (train_idx , valid_idx) in enumerate(folds.split(ftr_app, target_app)):\n        print(\"#iteration \", fold_idx, 'starts')\n        train_x = ftr_app.iloc[train_idx, :]\n        train_y = target_app.iloc[train_idx]\n        valid_x = ftr_app.iloc[valid_idx, :]\n        valid_y = target_app.iloc[valid_idx]\n        \n        train_x_resampled, train_y_resampled = smote.fit_resample(train_x, train_y)\n\n        clf.fit(train_x_resampled, train_y_resampled, eval_set=[(train_x_resampled, train_y_resampled), (valid_x, valid_y)], eval_metric= 'auc', verbose= 200, early_stopping_rounds= 200)\n        # Save predicted class labels for validation set\n        oof_preds[valid_idx] = clf.predict(valid_x)\n        # Save predicted proba labels for validation set\n        oof_preds_proba[valid_idx] = clf.predict_proba(valid_x)[:, 1]\n        \n    # return Target of train set\n    df_off_preds['TARGET'] = oof_preds_proba\n\n    # apps_all_test \n    df_test = apps_all_test.copy()\n    test_res = pd.DataFrame()\n    # save SK_ID_CURR\n    test_res[\"SK_ID_CURR\"]=df_test[\"SK_ID_CURR\"]\n    # deal with missing value\n    df_test = df_test.replace([np.inf, -np.inf], np.nan)\n    # fill NaN with median value\n    df_test = df_test.fillna(-999)\n  \n    X_apps_test = df_test.drop(\"SK_ID_CURR\", axis=1)\n\n    y_apps_test = clf.predict_proba(X_apps_test)\n    test_res[\"TARGET\"] = y_apps_test[:, 1]\n\n    return df_off_preds, clf, test_res","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_off_preds, clf, test_res = StratifiedKFold_SMOTE_XGBoosting_model(df=apps_train, nfolds=5, random_state=10, drop_columns_arr=['TARGET', 'SK_ID_CURR'], target_col='TARGET', apps_all_test=apps_all_test)\ndf_off_preds.to_csv(\"/kaggle/working/StratifiedKFold_SMOTE_XGBoost_train.csv\", index=False)\ntest_res.to_csv(\"/kaggle/working/StratifiedKFold_SMOTE_XGBoost_test.csv\", index=False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Light GBM","metadata":{}},{"cell_type":"markdown","source":"### K-Fold Cross-Validation","metadata":{}},{"cell_type":"code","source":"# No resampling method\ndef KFold_LightGBMC_model(df, nfolds, random_state, drop_columns_arr, target_col, apps_all_test):\n    df_off_preds = pd.DataFrame()\n    df_off_preds['SK_ID_CURR'] = df['SK_ID_CURR']\n\n    ftr_app = df.drop(drop_columns_arr, axis=1)  # feature dateset\n    target_app = df[target_col]                  # target datasets\n    # apply KFold\n    folds = KFold(n_splits = nfolds, shuffle=True, random_state = random_state)\n    \n    oof_preds = np.zeros(ftr_app.shape[0])\n    \n    clf = LGBMClassifier(\n                nthread=5,\n                n_estimators=100000,\n                learning_rate=0.008,\n                max_depth=12,\n                num_leaves=58,\n                colsample_bytree=0.613,\n                subsample=0.8,\n                max_bin=410,\n                reg_alpha=3.564,\n                reg_lambda=4.930,\n                min_child_weight= 6,\n                min_child_samples=165,\n                silent=-1,\n                verbose=-1,\n                )\n    \n    for fold_idx, (train_idx , valid_idx) in enumerate(folds.split(ftr_app)):\n        print(\"# iteration\", fold_idx, 'starts')\n        train_x = ftr_app.iloc[train_idx, :]\n        train_y = target_app.iloc[train_idx]\n        valid_x = ftr_app.iloc[valid_idx, :]\n        valid_y = target_app.iloc[valid_idx]\n\n        clf.fit(train_x, train_y, eval_set=[(train_x, train_y), (valid_x, valid_y)], eval_metric= 'auc', verbose= 200, early_stopping_rounds= 200)\n        \n        oof_preds[valid_idx] = clf.predict_proba(valid_x, num_iteration = clf.best_iteration_)[:, 1]\n\n    df_off_preds['TARGET'] = oof_preds\n\n    # test set\n    df_test = apps_all_test.copy() \n    test_res = pd.DataFrame()\n    test_res[\"SK_ID_CURR\"] = df_test[\"SK_ID_CURR\"]\n    # save SK_ID_CURR\n    # test_res[\"SK_ID_CURR\"]=df_test[\"SK_ID_CURR\"]\n    X_apps_test = df_test.drop(\"SK_ID_CURR\", axis=1)\n\n    y_apps_test = clf.predict_proba(X_apps_test)\n    test_res[\"TARGET\"] = y_apps_test[:, 1]\n    return df_off_preds, clf, test_res","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_off_preds, clf, test_res = LightGBMC_model(df=apps_train, nfolds=5, random_state=10, drop_columns_arr=['TARGET', 'SK_ID_CURR'], target_col='TARGET', apps_all_test=apps_all_test)\ndf_off_preds.to_csv(\"/kaggle/working/KFold_LightGBM_train.csv\", index = False)\ntest_res.to_csv(\"/kaggle/working/KFold_LightGBM_test.csv\", index = False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Random Over Sampling\ndef KFold_ROS_LightGBMC_model(df, nfolds, random_state, drop_columns_arr, target_col, apps_all_test):\n    # deal with missing data\n    df = df.replace([np.inf, -np.inf], np.nan)\n    # Fill NaN with median value\n    df = df.fillna(-999)\n    \n    df_off_preds = pd.DataFrame()\n    df_off_preds['SK_ID_CURR'] = df['SK_ID_CURR']\n\n    ftr_app = df.drop(drop_columns_arr, axis=1)  # feature dateset\n    target_app = df[target_col]                  # target datasets\n    # apply KFold\n    folds = KFold(n_splits = nfolds, shuffle=True, random_state = random_state)\n    \n    oof_preds = np.zeros(ftr_app.shape[0])\n    \n    clf = LGBMClassifier(\n                nthread=5,\n                n_estimators=50000,\n                learning_rate=0.008,\n                max_depth=12,\n                num_leaves=58,\n                colsample_bytree=0.613,\n                subsample=0.8,\n                max_bin=410,\n                reg_alpha=3.564,\n                reg_lambda=4.930,\n                min_child_weight= 6,\n                min_child_samples=165,\n                silent=-1,\n                verbose=-1,\n                )\n    \n    # ROS\n    ros = RandomOverSampler()\n    \n    for fold_idx, (train_idx , valid_idx) in enumerate(folds.split(ftr_app, target_app)):\n        print(\"# iteration\", fold_idx, 'starts')\n        train_x = ftr_app.iloc[train_idx, :]\n        train_y = target_app.iloc[train_idx]\n        valid_x = ftr_app.iloc[valid_idx, :]\n        valid_y = target_app.iloc[valid_idx]\n\n        train_x_resampled, train_y_resampled = ros.fit_resample(train_x, train_y)\n\n        clf.fit(train_x_resampled, train_y_resampled, eval_set=[(train_x_resampled, train_y_resampled), (valid_x, valid_y)], eval_metric= 'auc', verbose= 200, early_stopping_rounds= 200)\n        \n        oof_preds[valid_idx] = clf.predict_proba(valid_x, num_iteration = clf.best_iteration_)[:, 1]\n\n    df_off_preds['TARGET'] = oof_preds\n\n    # test set\n    df_test = apps_all_test.copy() \n    test_res = pd.DataFrame()\n    # save SK_ID_CURR\n    test_res[\"SK_ID_CURR\"]=df_test[\"SK_ID_CURR\"]\n    X_apps_test = df_test.drop(\"SK_ID_CURR\", axis=1)\n\n    y_apps_test = clf.predict_proba(X_apps_test)\n    test_res[f\"TARGET\"] = y_apps_test[:, 1]\n    return df_off_preds, clf, test_res","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_off_preds, clf, test_res = KFold_ROS_LightGBMC_model(df=apps_train, nfolds=5, random_state=10, drop_columns_arr=['TARGET', 'SK_ID_CURR'], target_col='TARGET', apps_all_test=apps_all_test)\ndf_off_preds.to_csv(\"/kaggle/working/KFold_ROS_LightGBM_train.csv\", index=False)\ntest_res.to_csv(\"/kaggle/working/KFold_ROS_LightGBM_test.csv\", index=False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Random Under Sampling\ndef KFold_RUS_LightGBMC_model(df, nfolds, random_state, drop_columns_arr, target_col, apps_all_test):\n    # deal with missing data\n    df = df.replace([np.inf, -np.inf], np.nan)\n    # Fill NaN with median value\n    df = df.fillna(-999)\n    \n    df_off_preds = pd.DataFrame()\n    df_off_preds['SK_ID_CURR'] = df['SK_ID_CURR']\n\n    ftr_app = df.drop(drop_columns_arr, axis=1)  # feature dateset\n    target_app = df[target_col]                  # target datasets\n    # apply KFold\n    folds = KFold(n_splits = nfolds, shuffle=True, random_state = random_state)\n    \n    oof_preds = np.zeros(ftr_app.shape[0])\n    \n    clf = LGBMClassifier(\n                nthread=5,\n                n_estimators=50000,\n                learning_rate=0.008,\n                max_depth=12,\n                num_leaves=58,\n                colsample_bytree=0.613,\n                subsample=0.8,\n                max_bin=410,\n                reg_alpha=3.564,\n                reg_lambda=4.930,\n                min_child_weight= 6,\n                min_child_samples=165,\n                silent=-1,\n                verbose=-1,\n                )\n    \n    # Apply RUS to the training set\n    rus = RandomUnderSampler(random_state=42)\n    \n    for fold_idx, (train_idx , valid_idx) in enumerate(folds.split(ftr_app, target_app)):\n        print(\"# iteration\", fold_idx, 'starts')\n        train_x = ftr_app.iloc[train_idx, :]\n        train_y = target_app.iloc[train_idx]\n        valid_x = ftr_app.iloc[valid_idx, :]\n        valid_y = target_app.iloc[valid_idx]\n\n        train_x_resampled, train_y_resampled = rus.fit_resample(train_x, train_y)\n\n        clf.fit(train_x_resampled, train_y_resampled, eval_set=[(train_x_resampled, train_y_resampled), (valid_x, valid_y)], eval_metric= 'auc', verbose= 200, early_stopping_rounds= 200)\n        \n        oof_preds[valid_idx] = clf.predict_proba(valid_x, num_iteration = clf.best_iteration_)[:, 1]\n\n    df_off_preds['TARGET'] = oof_preds\n\n    # test set\n    df_test = apps_all_test.copy() \n    test_res = pd.DataFrame()\n    # save SK_ID_CURR\n    test_res[\"SK_ID_CURR\"]=df_test[\"SK_ID_CURR\"]\n    X_apps_test = df_test.drop(\"SK_ID_CURR\", axis=1)\n\n    y_apps_test = clf.predict_proba(X_apps_test)\n    test_res[f\"TARGET\"] = y_apps_test[:, 1]\n    return df_off_preds, clf, test_res","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_off_preds, clf, test_res = KFold_RUS_LightGBMC_model(df=apps_train, nfolds=5, random_state=10, drop_columns_arr=['TARGET', 'SK_ID_CURR'], target_col='TARGET', apps_all_test=apps_all_test)\ndf_off_preds.to_csv(\"/kaggle/working/KFold_RUS_LightGBM_train.csv\", index=False)\ntest_res.to_csv(\"/kaggle/working/KFold_RUS_LightGBM_test.csv\", index=False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# SMOTE\ndef KFold_SMOTE_LightGBMC_model(df, nfolds, random_state, drop_columns_arr, target_col, apps_all_test):\n    # deal with missing data\n    df = df.replace([np.inf, -np.inf], np.nan)\n    # Fill NaN with median value\n    df = df.fillna(-999)\n    \n    df_off_preds = pd.DataFrame()\n    df_off_preds['SK_ID_CURR'] = df['SK_ID_CURR']\n\n    ftr_app = df.drop(drop_columns_arr, axis=1)  # feature dateset\n    target_app = df[target_col]                  # target datasets\n    # apply KFold\n    folds = KFold(n_splits = nfolds, shuffle=True, random_state = random_state)\n    \n    oof_preds = np.zeros(ftr_app.shape[0])\n    \n    clf = LGBMClassifier(\n                nthread=5,\n                n_estimators=50000,\n                learning_rate=0.008,\n                max_depth=12,\n                num_leaves=58,\n                colsample_bytree=0.613,\n                subsample=0.8,\n                max_bin=410,\n                reg_alpha=3.564,\n                reg_lambda=4.930,\n                min_child_weight= 6,\n                min_child_samples=165,\n                silent=-1,\n                verbose=-1,\n                )\n    \n    # SMOTE\n    smote = SMOTE()\n    \n    for fold_idx, (train_idx , valid_idx) in enumerate(folds.split(ftr_app, target_app)):\n        print(\"# iteration\", fold_idx, 'starts')\n        train_x = ftr_app.iloc[train_idx, :]\n        train_y = target_app.iloc[train_idx]\n        valid_x = ftr_app.iloc[valid_idx, :]\n        valid_y = target_app.iloc[valid_idx]\n\n        train_x_resampled, train_y_resampled = smote.fit_resample(train_x, train_y)\n\n        clf.fit(train_x_resampled, train_y_resampled, eval_set=[(train_x_resampled, train_y_resampled), (valid_x, valid_y)], eval_metric= 'auc', verbose= 200, early_stopping_rounds= 200)\n        \n        oof_preds[valid_idx] = clf.predict_proba(valid_x, num_iteration = clf.best_iteration_)[:, 1]\n\n    df_off_preds['TARGET'] = oof_preds\n\n    # test set\n    df_test = apps_all_test.copy() \n    test_res = pd.DataFrame()\n    # save SK_ID_CURR\n    test_res[\"SK_ID_CURR\"]=df_test[\"SK_ID_CURR\"]\n    X_apps_test = df_test.drop(\"SK_ID_CURR\", axis=1)\n\n    y_apps_test = clf.predict_proba(X_apps_test)\n    test_res[f\"TARGET\"] = y_apps_test[:, 1]\n    return df_off_preds, clf, test_res","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_off_preds, clf, test_res = KFold_SMOTE_LightGBMC_model(df=apps_train, nfolds=5, random_state=10, drop_columns_arr=['TARGET', 'SK_ID_CURR'], target_col='TARGET', apps_all_test=apps_all_test)\ndf_off_preds.to_csv(\"/kaggle/working/KFold_SMOTE_LightGBM_train.csv\", index=False)\ntest_res.to_csv(\"/kaggle/working/KFold_SMOTE_LightGBM_test.csv\", index=False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Stratified K-Fold Cross-Validation","metadata":{}},{"cell_type":"code","source":"# No resampling method\ndef StratifiedKFold_LightGBMC_model(df, nfolds, random_state, drop_columns_arr, target_col, apps_all_test):\n    df_off_preds = pd.DataFrame()\n    df_off_preds['SK_ID_CURR'] = df['SK_ID_CURR']\n\n    ftr_app = df.drop(drop_columns_arr, axis=1)  # feature dateset\n    target_app = df[target_col]                  # target datasets\n    # apply KFolds\n    folds = StratifiedKFold(n_splits = nfolds, shuffle=True, random_state = random_state)\n    \n    oof_preds = np.zeros(ftr_app.shape[0])\n    \n    clf = LGBMClassifier(\n                nthread=5,\n                n_estimators=100000,\n                learning_rate=0.008,\n                max_depth=12,\n                num_leaves=58,\n                colsample_bytree=0.613,\n                subsample=0.8,\n                max_bin=410,\n                reg_alpha=3.564,\n                reg_lambda=4.930,\n                min_child_weight= 6,\n                min_child_samples=165,\n                silent=-1,\n                verbose=-1,\n                )\n    \n    for fold_idx, (train_idx , valid_idx) in enumerate(folds.split(ftr_app, target_app)):\n        print(\"# iteration\", fold_idx, 'starts')\n        train_x = ftr_app.iloc[train_idx, :]\n        train_y = target_app.iloc[train_idx]\n        valid_x = ftr_app.iloc[valid_idx, :]\n        valid_y = target_app.iloc[valid_idx]\n\n        clf.fit(train_x, train_y, eval_set=[(train_x, train_y), (valid_x, valid_y)], eval_metric= 'auc', verbose= 200, early_stopping_rounds= 200)\n        \n        oof_preds[valid_idx] = clf.predict_proba(valid_x, num_iteration = clf.best_iteration_)[:, 1]\n\n    df_off_preds['TARGET'] = oof_preds\n\n    # test set\n    df_test = apps_all_test.copy() \n    test_res = pd.DataFrame()\n    test_res[\"SK_ID_CURR\"] = df_test[\"SK_ID_CURR\"]\n    # save SK_ID_CURR\n    # test_res[\"SK_ID_CURR\"]=df_test[\"SK_ID_CURR\"]\n    X_apps_test = df_test.drop(\"SK_ID_CURR\", axis=1)\n\n    y_apps_test = clf.predict_proba(X_apps_test)\n    test_res[\"TARGET\"] = y_apps_test[:, 1]\n    return df_off_preds, clf, test_res","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_off_preds, clf, test_res = StratifiedKFold_LightGBMC_model(df=apps_train, nfolds=5, random_state=10, drop_columns_arr=['TARGET', 'SK_ID_CURR'], target_col='TARGET', apps_all_test=apps_all_test)\ndf_off_preds.to_csv(\"/kaggle/working/StratifiedKFold_LightGBM_train.csv\", index=False)\ntest_res.to_csv(\"/kaggle/working/StratifiedKFold_LightGBM_test.csv\", index=False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Random Over Sampling\ndef StraifiedKFold_ROS_LightGBMC_model(df, nfolds, random_state, drop_columns_arr, target_col, apps_all_test):\n    # deal with missing data\n    df = df.replace([np.inf, -np.inf], np.nan)\n    # Fill NaN with median value\n    df = df.fillna(-999)\n    \n    df_off_preds = pd.DataFrame()\n    df_off_preds['SK_ID_CURR'] = df['SK_ID_CURR']\n\n    ftr_app = df.drop(drop_columns_arr, axis=1)  # feature dateset\n    target_app = df[target_col]                  # target datasets\n    # apply Straified KFold\n    folds = StratifiedKFold(n_splits = nfolds, shuffle=True, random_state = random_state)\n    \n    oof_preds = np.zeros(ftr_app.shape[0])\n    \n    clf = LGBMClassifier(\n                nthread=5,\n                n_estimators=50000,\n                learning_rate=0.008,\n                max_depth=12,\n                num_leaves=58,\n                colsample_bytree=0.613,\n                subsample=0.8,\n                max_bin=410,\n                reg_alpha=3.564,\n                reg_lambda=4.930,\n                min_child_weight= 6,\n                min_child_samples=165,\n                silent=-1,\n                verbose=-1,\n                )\n    \n    # ROS\n    ros = RandomOverSampler()\n    \n    for fold_idx, (train_idx , valid_idx) in enumerate(folds.split(ftr_app, target_app)):\n        print(\"# iteration\", fold_idx, 'starts')\n        train_x = ftr_app.iloc[train_idx, :]\n        train_y = target_app.iloc[train_idx]\n        valid_x = ftr_app.iloc[valid_idx, :]\n        valid_y = target_app.iloc[valid_idx]\n\n        train_x_resampled, train_y_resampled = ros.fit_resample(train_x, train_y)\n\n        clf.fit(train_x_resampled, train_y_resampled, eval_set=[(train_x_resampled, train_y_resampled), (valid_x, valid_y)], eval_metric= 'auc', verbose= 200, early_stopping_rounds= 200)\n        \n        oof_preds[valid_idx] = clf.predict_proba(valid_x, num_iteration = clf.best_iteration_)[:, 1]\n\n    df_off_preds['TARGET'] = oof_preds\n\n    # test set\n    df_test = apps_all_test.copy() \n    test_res = pd.DataFrame()\n    # save SK_ID_CURR\n    test_res[\"SK_ID_CURR\"]=df_test[\"SK_ID_CURR\"]\n    X_apps_test = df_test.drop(\"SK_ID_CURR\", axis=1)\n\n    y_apps_test = clf.predict_proba(X_apps_test)\n    test_res[f\"TARGET\"] = y_apps_test[:, 1]\n    return df_off_preds, clf, test_res","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_off_preds, clf, test_res = StraifiedKFold_ROS_LightGBMC_model(df=apps_train, nfolds=5, random_state=10, drop_columns_arr=['TARGET', 'SK_ID_CURR'], target_col='TARGET', apps_all_test=apps_all_test)\ndf_off_preds.to_csv(\"/kaggle/working/StratifiedKFold_ROS_LightGBM_train.csv\", index=False)\ntest_res.to_csv(\"/kaggle/working/StratifiedKFold_ROS_LightGBM_test.csv\", index=False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Random Under Sampling\ndef StraifiedKFold_RUS_LightGBMC_model(df, nfolds, random_state, drop_columns_arr, target_col, apps_all_test):\n    # deal with missing data\n    df = df.replace([np.inf, -np.inf], np.nan)\n    # Fill NaN with median value\n    df = df.fillna(-999)\n    \n    df_off_preds = pd.DataFrame()\n    df_off_preds['SK_ID_CURR'] = df['SK_ID_CURR']\n\n    ftr_app = df.drop(drop_columns_arr, axis=1)  # feature dateset\n    target_app = df[target_col]                  # target datasets\n    # apply StraifiedKFold\n    folds = StratifiedKFold(n_splits = nfolds, shuffle=True, random_state = random_state)\n    \n    oof_preds = np.zeros(ftr_app.shape[0])\n    \n    clf = LGBMClassifier(\n                nthread=5,\n                n_estimators=50000,\n                learning_rate=0.008,\n                max_depth=12,\n                num_leaves=58,\n                colsample_bytree=0.613,\n                subsample=0.8,\n                max_bin=410,\n                reg_alpha=3.564,\n                reg_lambda=4.930,\n                min_child_weight= 6,\n                min_child_samples=165,\n                silent=-1,\n                verbose=-1,\n                )\n    \n    # Apply RUS to the training set\n    rus = RandomUnderSampler(random_state=42)\n    \n    for fold_idx, (train_idx , valid_idx) in enumerate(folds.split(ftr_app, target_app)):\n        print(\"# iteration\", fold_idx, 'starts')\n        train_x = ftr_app.iloc[train_idx, :]\n        train_y = target_app.iloc[train_idx]\n        valid_x = ftr_app.iloc[valid_idx, :]\n        valid_y = target_app.iloc[valid_idx]\n\n        train_x_resampled, train_y_resampled = rus.fit_resample(train_x, train_y)\n\n        clf.fit(train_x_resampled, train_y_resampled, eval_set=[(train_x_resampled, train_y_resampled), (valid_x, valid_y)], eval_metric= 'auc', verbose= 200, early_stopping_rounds= 200)\n        \n        oof_preds[valid_idx] = clf.predict_proba(valid_x, num_iteration = clf.best_iteration_)[:, 1]\n\n    df_off_preds['TARGET'] = oof_preds\n\n    # test set\n    df_test = apps_all_test.copy() \n    test_res = pd.DataFrame()\n    # save SK_ID_CURR\n    test_res[\"SK_ID_CURR\"]=df_test[\"SK_ID_CURR\"]\n    X_apps_test = df_test.drop(\"SK_ID_CURR\", axis=1)\n\n    y_apps_test = clf.predict_proba(X_apps_test)\n    test_res[f\"TARGET\"] = y_apps_test[:, 1]\n    return df_off_preds, clf, test_res","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_off_preds, clf, test_res = StraifiedKFold_RUS_LightGBMC_model(df=apps_train, nfolds=5, random_state=10, drop_columns_arr=['TARGET', 'SK_ID_CURR'], target_col='TARGET', apps_all_test=apps_all_test)\ndf_off_preds.to_csv(\"/kaggle/working/StratifiedKFold_RUS_LightGBM_train.csv\", index=False)\ntest_res.to_csv(\"/kaggle/working/StratifiedKFold_RUS_LightGBM_test.csv\", index=False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# SMOTE\ndef StraifiedKFold_SMOTE_LightGBMC_model(df, nfolds, random_state, drop_columns_arr, target_col, apps_all_test):\n    # deal with missing data\n    df = df.replace([np.inf, -np.inf], np.nan)\n    # Fill NaN with median value\n    df = df.fillna(-999)\n    \n    df_off_preds = pd.DataFrame()\n    df_off_preds['SK_ID_CURR'] = df['SK_ID_CURR']\n\n    ftr_app = df.drop(drop_columns_arr, axis=1)  # feature dateset\n    target_app = df[target_col]                  # target datasets\n    # apply StraifiedKFold\n    folds = StratifiedKFold(n_splits = nfolds, shuffle=True, random_state = random_state)\n    \n    oof_preds = np.zeros(ftr_app.shape[0])\n    \n    clf = LGBMClassifier(\n                nthread=5,\n                n_estimators=50000,\n                learning_rate=0.008,\n                max_depth=12,\n                num_leaves=58,\n                colsample_bytree=0.613,\n                subsample=0.8,\n                max_bin=410,\n                reg_alpha=3.564,\n                reg_lambda=4.930,\n                min_child_weight= 6,\n                min_child_samples=165,\n                silent=-1,\n                verbose=-1,\n                )\n    \n    # SMOTE\n    smote = SMOTE()\n    \n    for fold_idx, (train_idx , valid_idx) in enumerate(folds.split(ftr_app, target_app)):\n        print(\"# iteration\", fold_idx, 'starts')\n        train_x = ftr_app.iloc[train_idx, :]\n        train_y = target_app.iloc[train_idx]\n        valid_x = ftr_app.iloc[valid_idx, :]\n        valid_y = target_app.iloc[valid_idx]\n\n        train_x_resampled, train_y_resampled = smote.fit_resample(train_x, train_y)\n\n        clf.fit(train_x_resampled, train_y_resampled, eval_set=[(train_x_resampled, train_y_resampled), (valid_x, valid_y)], eval_metric= 'auc', verbose= 200, early_stopping_rounds= 200)\n        \n        oof_preds[valid_idx] = clf.predict_proba(valid_x, num_iteration = clf.best_iteration_)[:, 1]\n\n    df_off_preds['TARGET'] = oof_preds\n\n    # test set\n    df_test = apps_all_test.copy() \n    test_res = pd.DataFrame()\n    # save SK_ID_CURR\n    test_res[\"SK_ID_CURR\"]=df_test[\"SK_ID_CURR\"]\n    X_apps_test = df_test.drop(\"SK_ID_CURR\", axis=1)\n\n    y_apps_test = clf.predict_proba(X_apps_test)\n    test_res[f\"TARGET\"] = y_apps_test[:, 1]\n    return df_off_preds, clf, test_res","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_off_preds, clf, test_res = StraifiedKFold_SMOTE_LightGBMC_model(df=apps_train, nfolds=5, random_state=10, drop_columns_arr=['TARGET', 'SK_ID_CURR'], target_col='TARGET', apps_all_test=apps_all_test)\ndf_off_preds.to_csv(\"/kaggle/working/StratifiedKFold_SMOTE_LightGBM_train.csv\", index=False)\ntest_res.to_csv(\"/kaggle/working/StratifiedKFold_SMOTE_LightGBM_test.csv\", index=False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Stacking","metadata":{}},{"cell_type":"markdown","source":"## Import dataframe (Top 8 AUC model results)","metadata":{}},{"cell_type":"markdown","source":"### Training data","metadata":{}},{"cell_type":"code","source":"KFold_LightGBM_train = pd.read_csv(\"/kaggle/input/home-credit-default-risk-apps-all-full/KFold_LightGBM_train.csv\")\nKFold_LightGBM_train.rename(columns = {'TARGET':'KFold_LightGBM'}, inplace = True)\nKFold_ROS_XGBoost_train = pd.read_csv(\"/kaggle/input/home-credit-default-risk-apps-all-full/KFold_ROS_XGBoost_train.csv\")\nKFold_ROS_XGBoost_train.rename(columns = {'TARGET':'KFold_ROS_XGBoost'}, inplace = True)\nKFold_RUS_XGBoost_train = pd.read_csv(\"/kaggle/input/home-credit-default-risk-apps-all-full/KFold_RUS_XGBoost_train.csv\")\nKFold_RUS_XGBoost_train.rename(columns = {'TARGET':'KFold_RUS_XGBoost'}, inplace = True)\nKFold_SMOTE_XGBoost_train = pd.read_csv(\"/kaggle/input/home-credit-default-risk-apps-all-full/KFold_SMOTE_XGBoost_train.csv\")\nKFold_SMOTE_XGBoost_train.rename(columns = {'TARGET':'KFold_SMOTE_XGBoost'}, inplace = True)\nStratifiedKFold_LightGBM_train = pd.read_csv(\"/kaggle/input/home-credit-default-risk-apps-all-full/StratifiedKFold_LightGBM_train.csv\")\nStratifiedKFold_LightGBM_train.rename(columns = {'TARGET':'StratifiedKFold_LightGBM'}, inplace = True)\nStratifiedKFold_ROS_XGBoost_train = pd.read_csv(\"/kaggle/input/home-credit-default-risk-apps-all-full/StratifiedKFold_ROS_XGBoost_train.csv\")\nStratifiedKFold_ROS_XGBoost_train.rename(columns = {'TARGET':'StratifiedKFold_ROS_XGBoost'}, inplace = True)\nStratifiedKFold_RUS_XGBoost_train = pd.read_csv(\"/kaggle/input/home-credit-default-risk-apps-all-full/StratifiedKFold_RUS_XGBoost_train.csv\")\nStratifiedKFold_RUS_XGBoost_train.rename(columns = {'TARGET':'StratifiedKFold_RUS_XGBoost'}, inplace = True)\nStratifiedKFold_SMOTE_XGBoost_train = pd.read_csv(\"/kaggle/input/home-credit-default-risk-apps-all-full/StratifiedKFold_SMOTE_XGBoost_train.csv\")\nStratifiedKFold_SMOTE_XGBoost_train.rename(columns = {'TARGET':'StratifiedKFold_SMOTE_XGBoost'}, inplace = True)\n\n# Merge the datasets using a common key column\nmerged_df_train = pd.merge(KFold_LightGBM_train, KFold_ROS_XGBoost_train, how = \"inner\", on='SK_ID_CURR')\nmerged_df_train = pd.merge(merged_df_train, KFold_RUS_XGBoost_train, how = \"inner\", on='SK_ID_CURR')\nmerged_df_train = pd.merge(merged_df_train, KFold_SMOTE_XGBoost_train, how = \"inner\", on='SK_ID_CURR')\nmerged_df_train = pd.merge(merged_df_train, StratifiedKFold_LightGBM_train, how = \"inner\", on='SK_ID_CURR')\nmerged_df_train = pd.merge(merged_df_train, StratifiedKFold_ROS_XGBoost_train, how = \"inner\", on='SK_ID_CURR')\nmerged_df_train = pd.merge(merged_df_train, StratifiedKFold_RUS_XGBoost_train, how = \"inner\", on='SK_ID_CURR')\nmerged_df_train = pd.merge(merged_df_train, StratifiedKFold_SMOTE_XGBoost_train, how = \"inner\", on='SK_ID_CURR')\n\nmerged_df_train = pd.merge(merged_df_train, apps_train[[\"SK_ID_CURR\", \"TARGET\"]], how = \"inner\", on='SK_ID_CURR')\n\nprint(len(merged_df_train))\nprint()\nmerged_df_train.head()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Testing data","metadata":{}},{"cell_type":"code","source":"KFold_LightGBM_test = pd.read_csv(\"/kaggle/input/home-credit-default-risk-apps-all-full/KFold_LightGBM_test.csv\")\nKFold_LightGBM_test.rename(columns = {'TARGET':'KFold_LightGBM'}, inplace = True)\nKFold_ROS_XGBoost_test = pd.read_csv(\"/kaggle/input/home-credit-default-risk-apps-all-full/KFold_ROS_XGBoost_test.csv\")\nKFold_ROS_XGBoost_test.rename(columns = {'TARGET':'KFold_ROS_XGBoost'}, inplace = True)\nKFold_RUS_XGBoost_test = pd.read_csv(\"/kaggle/input/home-credit-default-risk-apps-all-full/KFold_RUS_XGBoost_test.csv\")\nKFold_RUS_XGBoost_test.rename(columns = {'TARGET':'KFold_RUS_XGBoost'}, inplace = True)\nKFold_SMOTE_XGBoost_test = pd.read_csv(\"/kaggle/input/home-credit-default-risk-apps-all-full/KFold_SMOTE_XGBoost_test.csv\")\nKFold_SMOTE_XGBoost_test.rename(columns = {'TARGET':'KFold_SMOTE_XGBoost'}, inplace = True)\nStratifiedKFold_LightGBM_test = pd.read_csv(\"/kaggle/input/home-credit-default-risk-apps-all-full/StratifiedKFold_LightGBM_test.csv\")\nStratifiedKFold_LightGBM_test.rename(columns = {'TARGET':'StratifiedKFold_LightGBM'}, inplace = True)\nStratifiedKFold_ROS_XGBoost_test = pd.read_csv(\"/kaggle/input/home-credit-default-risk-apps-all-full/StratifiedKFold_ROS_XGBoost_test.csv\")\nStratifiedKFold_ROS_XGBoost_test.rename(columns = {'TARGET':'StratifiedKFold_ROS_XGBoost'}, inplace = True)\nStratifiedKFold_RUS_XGBoost_test = pd.read_csv(\"/kaggle/input/home-credit-default-risk-apps-all-full/StratifiedKFold_RUS_XGBoost_test.csv\")\nStratifiedKFold_RUS_XGBoost_test.rename(columns = {'TARGET':'StratifiedKFold_RUS_XGBoost'}, inplace = True)\nStratifiedKFold_SMOTE_XGBoost_test = pd.read_csv(\"/kaggle/input/home-credit-default-risk-apps-all-full/StratifiedKFold_SMOTE_XGBoost_test.csv\")\nStratifiedKFold_SMOTE_XGBoost_test.rename(columns = {'TARGET':'StratifiedKFold_SMOTE_XGBoost'}, inplace = True)\n\n# Merge the datasets using a common key column\nmerged_df_test = pd.merge(KFold_LightGBM_test, KFold_ROS_XGBoost_test, how = \"inner\", on='SK_ID_CURR')\nmerged_df_test = pd.merge(merged_df_test, KFold_RUS_XGBoost_test, how = \"inner\", on='SK_ID_CURR')\nmerged_df_test = pd.merge(merged_df_test, KFold_SMOTE_XGBoost_test, how = \"inner\", on='SK_ID_CURR')\nmerged_df_test = pd.merge(merged_df_test, StratifiedKFold_LightGBM_test, how = \"inner\", on='SK_ID_CURR')\nmerged_df_test = pd.merge(merged_df_test, StratifiedKFold_ROS_XGBoost_test, how = \"inner\", on='SK_ID_CURR')\nmerged_df_test = pd.merge(merged_df_test, StratifiedKFold_RUS_XGBoost_test, how = \"inner\", on='SK_ID_CURR')\nmerged_df_test = pd.merge(merged_df_test, StratifiedKFold_SMOTE_XGBoost_test, how = \"inner\", on='SK_ID_CURR')\n\nprint(len(merged_df_test))\nprint()\nmerged_df_test.head()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Logistic regression","metadata":{}},{"cell_type":"markdown","source":"### K-Fold Cross-Validation","metadata":{}},{"cell_type":"code","source":"# No resampling method\ndef KFold_Stacking_LogisticReg_model(df, nfolds, random_state, drop_columns_arr, target_col, apps_all_test):\n  # Data Frame\n  df_off_preds = pd.DataFrame()\n  df_off_preds['SK_ID_CURR'] = df['SK_ID_CURR']\n\n  ftr_app = df.drop(drop_columns_arr, axis=1)  # feature dateset\n  target_app = df[target_col]                  # target datasets\n  \n  # KFold\n  folds = KFold(n_splits = nfolds, shuffle=True, random_state = random_state)\n\n  clf = LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n                           intercept_scaling=1, max_iter=5000, multi_class='ovr', n_jobs=1,\n                           penalty='l1', random_state=None, solver='saga', tol=0.0001,\n                           verbose=0, warm_start=False)\n  \n  oof_preds_proba = np.zeros(ftr_app.shape[0])\n  auc_scores = []\n\n  for fold_idx, (train_idx , valid_idx) in enumerate(folds.split(ftr_app)):\n        print(\"# iteration\", fold_idx, 'starts')\n        train_x = ftr_app.iloc[train_idx, :]\n        train_y = target_app.iloc[train_idx]\n        valid_x = ftr_app.iloc[valid_idx, :]\n        valid_y = target_app.iloc[valid_idx]\n        \n        clf.fit(train_x, train_y)\n\n        # Save predicted proba labels for validation set\n        oof_preds_proba[valid_idx] = clf.predict_proba(valid_x)[:, 1]\n\n        # compute AUC on validation set\n        auc_score = roc_auc_score(valid_y, oof_preds_proba[valid_idx])\n        auc_scores.append(auc_score)\n        print(f\"AUC: {auc_score}\")\n\n  print(f\"Mean AUC: {np.mean(auc_scores):.5f}\")  \n\n  df_off_preds['TARGET'] = oof_preds_proba\n\n  # SUMMARY\n  # calculate p-values\n  X2 = sm.add_constant(ftr_app)\n  target_app_arr = np.array(target_app)\n  est = sm.Logit(target_app_arr, X2)\n  est2 = est.fit()\n  print(est2.summary())\n\n  # app test \n  res = pd.DataFrame()\n  res[\"SK_ID_CURR\"] = apps_all_test[\"SK_ID_CURR\"]\n    \n  # apps_all_test \n  df_test = apps_all_test.copy()\n  X_apps_test = df_test.drop(\"SK_ID_CURR\", axis=1)\n\n  y_pred_test = clf.predict_proba(X_apps_test)[:, 1]\n  res[\"TARGET\"] = y_pred_test\n  \n  return df_off_preds, clf, res","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_off_preds, clf, test_res = KFold_Stacking_LogisticReg_model(df=merged_df_train, nfolds=5, random_state=10, drop_columns_arr=['TARGET', 'SK_ID_CURR'], target_col='TARGET', apps_all_test=merged_df_test)\ndf_off_preds.to_csv(\"/kaggle/working/KFold_Stacking_LogisticReg_train.csv\", index = False)\ntest_res.to_csv(\"/kaggle/working/KFold_Stacking_LogisticReg_test.csv\", index = False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Random Over Sampling\ndef KFold_ROS_Stacking_LogisticReg_model(df, nfolds, random_state, drop_columns_arr, target_col, apps_all_test):\n  # Data Frame\n  df_off_preds = pd.DataFrame()\n  df_off_preds['SK_ID_CURR'] = df['SK_ID_CURR']\n\n  ftr_app = df.drop(drop_columns_arr, axis=1)  # feature dateset\n  target_app = df[target_col]                  # target datasets\n  \n  # KFold\n  folds = KFold(n_splits = nfolds, shuffle=True, random_state = random_state)\n\n  clf = LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n                           intercept_scaling=1, max_iter=5000, multi_class='ovr', n_jobs=1,\n                           penalty='l1', random_state=None, solver='saga', tol=0.0001,\n                           verbose=0, warm_start=False)\n  \n  oof_preds_proba = np.zeros(ftr_app.shape[0])\n  auc_scores = []\n    \n  # ROS\n  ros = RandomOverSampler()\n\n  for fold_idx, (train_idx , valid_idx) in enumerate(folds.split(ftr_app)):\n        print(\"# iteration\", fold_idx, 'starts')\n        train_x = ftr_app.iloc[train_idx, :]\n        train_y = target_app.iloc[train_idx]\n        valid_x = ftr_app.iloc[valid_idx, :]\n        valid_y = target_app.iloc[valid_idx]\n\n        train_x_resampled, train_y_resampled = ros.fit_resample(train_x, train_y)\n        \n        # Fit ROS\n        clf.fit(train_x_resampled, train_y_resampled)\n\n        # Save predicted proba labels for validation set\n        oof_preds_proba[valid_idx] = clf.predict_proba(valid_x)[:, 1]\n\n        # compute AUC on validation set\n        auc_score = roc_auc_score(valid_y, oof_preds_proba[valid_idx])\n        auc_scores.append(auc_score)\n        print(f\"AUC: {auc_score}\")\n\n  print(f\"Mean AUC: {np.mean(auc_scores):.5f}\")  \n\n  df_off_preds['TARGET'] = oof_preds_proba\n\n  # SUMMARY\n  # calculate p-values\n  X2 = sm.add_constant(ftr_app)\n  target_app_arr = np.array(target_app)\n  est = sm.Logit(target_app_arr, X2)\n  est2 = est.fit()\n  print(est2.summary())\n\n  # app test \n  res = pd.DataFrame()\n  res[\"SK_ID_CURR\"] = apps_all_test[\"SK_ID_CURR\"]\n    \n  # apps_all_test \n  df_test = apps_all_test.copy()\n  X_apps_test = df_test.drop(\"SK_ID_CURR\", axis=1)\n\n  y_pred_test = clf.predict_proba(X_apps_test)[:, 1]\n  res[\"TARGET\"] = y_pred_test\n  \n  return df_off_preds, clf, res","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_off_preds, clf, test_res = KFold_ROS_Stacking_LogisticReg_model(df=merged_df_train, nfolds=5, random_state=10, drop_columns_arr=['TARGET', 'SK_ID_CURR'], target_col='TARGET', apps_all_test=merged_df_test)\ndf_off_preds.to_csv(\"/kaggle/working/KFold_ROS_Stacking_LogisticReg_train.csv\", index = False)\ntest_res.to_csv(\"/kaggle/working/KFold_ROS_Stacking_LogisticReg_test.csv\", index = False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Random Under Sampling\ndef KFold_RUS_Stacking_LogisticReg_model(df, nfolds, random_state, drop_columns_arr, target_col, apps_all_test):\n  # Data Frame\n  df_off_preds = pd.DataFrame()\n  df_off_preds['SK_ID_CURR'] = df['SK_ID_CURR']\n\n  ftr_app = df.drop(drop_columns_arr, axis=1)  # feature dateset\n  target_app = df[target_col]                  # target datasets\n  \n  # KFold\n  folds = KFold(n_splits = nfolds, shuffle=True, random_state = random_state)\n\n  clf = LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n                           intercept_scaling=1, max_iter=5000, multi_class='ovr', n_jobs=1,\n                           penalty='l1', random_state=None, solver='saga', tol=0.0001,\n                           verbose=0, warm_start=False)\n  \n  oof_preds_proba = np.zeros(ftr_app.shape[0])\n  auc_scores = []\n  \n  # RUS\n  rus = RandomUnderSampler()\n\n  for fold_idx, (train_idx , valid_idx) in enumerate(folds.split(ftr_app)):\n        print(\"# iteration\", fold_idx, 'starts')\n        train_x = ftr_app.iloc[train_idx, :]\n        train_y = target_app.iloc[train_idx]\n        valid_x = ftr_app.iloc[valid_idx, :]\n        valid_y = target_app.iloc[valid_idx]\n\n        train_x_resampled, train_y_resampled = rus.fit_resample(train_x, train_y)\n        \n        # Fit ROS\n        clf.fit(train_x_resampled, train_y_resampled)\n\n        # Save predicted proba labels for validation set\n        oof_preds_proba[valid_idx] = clf.predict_proba(valid_x)[:, 1]\n\n        # compute AUC on validation set\n        auc_score = roc_auc_score(valid_y, oof_preds_proba[valid_idx])\n        auc_scores.append(auc_score)\n        print(f\"AUC: {auc_score}\")\n\n  print(f\"Mean AUC: {np.mean(auc_scores):.5f}\")  \n\n  df_off_preds['TARGET'] = oof_preds_proba\n\n  # SUMMARY\n  # calculate p-values\n  X2 = sm.add_constant(ftr_app)\n  target_app_arr = np.array(target_app)\n  est = sm.Logit(target_app_arr, X2)\n  est2 = est.fit()\n  print(est2.summary())\n\n  # app test \n  res = pd.DataFrame()\n  res[\"SK_ID_CURR\"] = apps_all_test[\"SK_ID_CURR\"]\n    \n  # apps_all_test \n  df_test = apps_all_test.copy()\n  X_apps_test = df_test.drop(\"SK_ID_CURR\", axis=1)\n\n  y_pred_test = clf.predict_proba(X_apps_test)[:, 1]\n  res[\"TARGET\"] = y_pred_test\n  \n  return df_off_preds, clf, res","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_off_preds, clf, test_res = KFold_RUS_Stacking_LogisticReg_model(df=merged_df_train, nfolds=5, random_state=10, drop_columns_arr=['TARGET', 'SK_ID_CURR'], target_col='TARGET', apps_all_test=merged_df_test)\ndf_off_preds.to_csv(\"/kaggle/working/KFold_RUS_Stacking_LogisticReg_train.csv\", index = False)\ntest_res.to_csv(\"/kaggle/working/KFold_RUS_Stacking_LogisticReg_test.csv\", index = False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# SMOTE\ndef KFold_SMOTE_Stacking_LogisticReg_model(df, nfolds, random_state, drop_columns_arr, target_col, apps_all_test):\n  # Data Frame\n  df_off_preds = pd.DataFrame()\n  df_off_preds['SK_ID_CURR'] = df['SK_ID_CURR']\n\n  ftr_app = df.drop(drop_columns_arr, axis=1)  # feature dateset\n  target_app = df[target_col]                  # target datasets\n  \n  # KFold\n  folds = KFold(n_splits = nfolds, shuffle=True, random_state = random_state)\n\n  clf = LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n                           intercept_scaling=1, max_iter=5000, multi_class='ovr', n_jobs=1,\n                           penalty='l1', random_state=None, solver='saga', tol=0.0001,\n                           verbose=0, warm_start=False)\n  \n  oof_preds_proba = np.zeros(ftr_app.shape[0])\n  auc_scores = []\n    \n  # SMOTE\n  smote = SMOTE()\n\n  for fold_idx, (train_idx , valid_idx) in enumerate(folds.split(ftr_app)):\n        print(\"# iteration\", fold_idx, 'starts')\n        train_x = ftr_app.iloc[train_idx, :]\n        train_y = target_app.iloc[train_idx]\n        valid_x = ftr_app.iloc[valid_idx, :]\n        valid_y = target_app.iloc[valid_idx]\n\n        train_x_resampled, train_y_resampled = smote.fit_resample(train_x, train_y)\n        \n        # Fit ROS\n        clf.fit(train_x_resampled, train_y_resampled)\n\n        # Save predicted proba labels for validation set\n        oof_preds_proba[valid_idx] = clf.predict_proba(valid_x)[:, 1]\n\n        # compute AUC on validation set\n        auc_score = roc_auc_score(valid_y, oof_preds_proba[valid_idx])\n        auc_scores.append(auc_score)\n        print(f\"AUC: {auc_score}\")\n\n  print(f\"Mean AUC: {np.mean(auc_scores):.5f}\")  \n\n  df_off_preds['TARGET'] = oof_preds_proba\n\n  # SUMMARY\n  # calculate p-values\n  X2 = sm.add_constant(ftr_app)\n  target_app_arr = np.array(target_app)\n  est = sm.Logit(target_app_arr, X2)\n  est2 = est.fit()\n  print(est2.summary())\n\n  # app test \n  res = pd.DataFrame()\n  res[\"SK_ID_CURR\"] = apps_all_test[\"SK_ID_CURR\"]\n    \n  # apps_all_test \n  df_test = apps_all_test.copy()\n  X_apps_test = df_test.drop(\"SK_ID_CURR\", axis=1)\n\n  y_pred_test = clf.predict_proba(X_apps_test)[:, 1]\n  res[\"TARGET\"] = y_pred_test\n  \n  return df_off_preds, clf, res","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_off_preds, clf, test_res = KFold_SMOTE_Stacking_LogisticReg_model(df=merged_df_train, nfolds=5, random_state=10, drop_columns_arr=['TARGET', 'SK_ID_CURR'], target_col='TARGET', apps_all_test=merged_df_test)\ndf_off_preds.to_csv(\"/kaggle/working/KFold_SMOTE_Stacking_LogisticReg_train.csv\", index = False)\ntest_res.to_csv(\"/kaggle/working/KFold_SMOTE_Stacking_LogisticReg_test.csv\", index = False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Stratified K-Fold Cross-Validation","metadata":{}},{"cell_type":"code","source":"# No resampling method\ndef StratifiedKFold_Stacking_LogisticReg_model(df, nfolds, random_state, drop_columns_arr, target_col, apps_all_test):\n  # Data Frame\n  df_off_preds = pd.DataFrame()\n  df_off_preds['SK_ID_CURR'] = df['SK_ID_CURR']\n\n  ftr_app = df.drop(drop_columns_arr, axis=1)  # feature dateset\n  target_app = df[target_col]                  # target datasets\n  \n  folds = StratifiedKFold(n_splits = nfolds, shuffle=True, random_state = random_state)\n\n  clf = LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n                           intercept_scaling=1, max_iter=5000, multi_class='ovr', n_jobs=1,\n                           penalty='l1', random_state=None, solver='saga', tol=0.0001,\n                           verbose=0, warm_start=False)\n  \n  oof_preds_proba = np.zeros(ftr_app.shape[0])\n  auc_scores = []\n\n  for fold_idx, (train_idx , valid_idx) in enumerate(folds.split(ftr_app, target_app)):\n        print(\"# iteration\", fold_idx, 'starts')\n        train_x = ftr_app.iloc[train_idx, :]\n        train_y = target_app.iloc[train_idx]\n        valid_x = ftr_app.iloc[valid_idx, :]\n        valid_y = target_app.iloc[valid_idx]\n        \n        clf.fit(train_x, train_y)\n\n        # Save predicted proba labels for validation set\n        oof_preds_proba[valid_idx] = clf.predict_proba(valid_x)[:, 1]\n\n        # compute AUC on validation set\n        auc_score = roc_auc_score(valid_y, oof_preds_proba[valid_idx])\n        auc_scores.append(auc_score)\n        print(f\"AUC: {auc_score}\")\n\n  print(f\"Mean AUC: {np.mean(auc_scores):.5f}\")  \n\n  df_off_preds['TARGET'] = oof_preds_proba\n\n  # SUMMARY\n  # calculate p-values\n  X2 = sm.add_constant(ftr_app)\n  target_app_arr = np.array(target_app)\n  est = sm.Logit(target_app_arr, X2)\n  est2 = est.fit()\n  print(est2.summary())\n\n  # app test \n  res = pd.DataFrame()\n  res[\"SK_ID_CURR\"] = apps_all_test[\"SK_ID_CURR\"]\n    \n  # apps_all_test \n  df_test = apps_all_test.copy()\n  X_apps_test = df_test.drop(\"SK_ID_CURR\", axis=1)\n\n  y_pred_test = clf.predict_proba(X_apps_test)[:, 1]\n  res[\"TARGET\"] = y_pred_test\n  \n  return df_off_preds, clf, res","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_off_preds, clf, test_res = StratifiedKFold_Stacking_LogisticReg_model(df=merged_df_train, nfolds=5, random_state=10, drop_columns_arr=['TARGET', 'SK_ID_CURR'], target_col='TARGET', apps_all_test=merged_df_test)\ndf_off_preds.to_csv(\"/kaggle/working/StratifiedKFold_Stacking_LogisticReg_train.csv\", index = False)\ntest_res.to_csv(\"/kaggle/working/StratifiedKFold_Stacking_LogisticReg_test.csv\", index = False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Random Over Sampling\ndef StratifiedKFold_ROS_Stacking_LogisticReg_model(df, nfolds, random_state, drop_columns_arr, target_col, apps_all_test):\n  # Data Frame\n  df_off_preds = pd.DataFrame()\n  df_off_preds['SK_ID_CURR'] = df['SK_ID_CURR']\n\n  ftr_app = df.drop(drop_columns_arr, axis=1)  # feature dateset\n  target_app = df[target_col]                  # target datasets\n  \n  # Stratified KFold\n  folds = StratifiedKFold(n_splits = nfolds, shuffle=True, random_state = random_state)\n\n  clf = LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n                           intercept_scaling=1, max_iter=5000, multi_class='ovr', n_jobs=1,\n                           penalty='l1', random_state=None, solver='saga', tol=0.0001,\n                           verbose=0, warm_start=False)\n  \n  oof_preds_proba = np.zeros(ftr_app.shape[0])\n  auc_scores = []\n    \n  # ROS\n  ros = RandomOverSampler()\n\n  for fold_idx, (train_idx , valid_idx) in enumerate(folds.split(ftr_app, target_app)):\n        print(\"# iteration\", fold_idx, 'starts')\n        train_x = ftr_app.iloc[train_idx, :]\n        train_y = target_app.iloc[train_idx]\n        valid_x = ftr_app.iloc[valid_idx, :]\n        valid_y = target_app.iloc[valid_idx]\n\n        train_x_resampled, train_y_resampled = ros.fit_resample(train_x, train_y)\n        \n        # Fit ROS\n        clf.fit(train_x_resampled, train_y_resampled)\n\n        # Save predicted proba labels for validation set\n        oof_preds_proba[valid_idx] = clf.predict_proba(valid_x)[:, 1]\n\n        # compute AUC on validation set\n        auc_score = roc_auc_score(valid_y, oof_preds_proba[valid_idx])\n        auc_scores.append(auc_score)\n        print(f\"AUC: {auc_score}\")\n\n  print(f\"Mean AUC: {np.mean(auc_scores):.5f}\")  \n\n  df_off_preds['TARGET'] = oof_preds_proba\n\n  # SUMMARY\n  # calculate p-values\n  X2 = sm.add_constant(ftr_app)\n  target_app_arr = np.array(target_app)\n  est = sm.Logit(target_app_arr, X2)\n  est2 = est.fit()\n  print(est2.summary())\n\n  # app test \n  res = pd.DataFrame()\n  res[\"SK_ID_CURR\"] = apps_all_test[\"SK_ID_CURR\"]\n    \n  # apps_all_test \n  df_test = apps_all_test.copy()\n  X_apps_test = df_test.drop(\"SK_ID_CURR\", axis=1)\n\n  y_pred_test = clf.predict_proba(X_apps_test)[:, 1]\n  res[\"TARGET\"] = y_pred_test\n  \n  return df_off_preds, clf, res","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_off_preds, clf, test_res = StratifiedKFold_ROS_Stacking_LogisticReg_model(df=merged_df_train, nfolds=5, random_state=10, drop_columns_arr=['TARGET', 'SK_ID_CURR'], target_col='TARGET', apps_all_test=merged_df_test)\ndf_off_preds.to_csv(\"/kaggle/working/StratifiedKFold_ROS_Stacking_LogisticReg_train.csv\", index = False)\ntest_res.to_csv(\"/kaggle/working/StratifiedKFold_ROS_Stacking_LogisticReg_test.csv\", index = False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Random Under Sampling\ndef StratifiedKFold_RUS_Stacking_LogisticReg_model(df, nfolds, random_state, drop_columns_arr, target_col, apps_all_test):\n  # Data Frame\n  df_off_preds = pd.DataFrame()\n  df_off_preds['SK_ID_CURR'] = df['SK_ID_CURR']\n\n  ftr_app = df.drop(drop_columns_arr, axis=1)  # feature dateset\n  target_app = df[target_col]                  # target datasets\n  \n  # StratifiedKFold\n  folds = StratifiedKFold(n_splits = nfolds, shuffle=True, random_state = random_state)\n\n  clf = LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n                           intercept_scaling=1, max_iter=5000, multi_class='ovr', n_jobs=1,\n                           penalty='l1', random_state=None, solver='saga', tol=0.0001,\n                           verbose=0, warm_start=False)\n  \n  oof_preds_proba = np.zeros(ftr_app.shape[0])\n  auc_scores = []\n  \n  # RUS\n  rus = RandomUnderSampler()\n\n  for fold_idx, (train_idx , valid_idx) in enumerate(folds.split(ftr_app, target_app)):\n        print(\"# iteration\", fold_idx, 'starts')\n        train_x = ftr_app.iloc[train_idx, :]\n        train_y = target_app.iloc[train_idx]\n        valid_x = ftr_app.iloc[valid_idx, :]\n        valid_y = target_app.iloc[valid_idx]\n\n        train_x_resampled, train_y_resampled = rus.fit_resample(train_x, train_y)\n        \n        # Fit ROS\n        clf.fit(train_x_resampled, train_y_resampled)\n\n        # Save predicted proba labels for validation set\n        oof_preds_proba[valid_idx] = clf.predict_proba(valid_x)[:, 1]\n\n        # compute AUC on validation set\n        auc_score = roc_auc_score(valid_y, oof_preds_proba[valid_idx])\n        auc_scores.append(auc_score)\n        print(f\"AUC: {auc_score}\")\n\n  print(f\"Mean AUC: {np.mean(auc_scores):.5f}\")  \n\n  df_off_preds['TARGET'] = oof_preds_proba\n\n  # SUMMARY\n  # calculate p-values\n  X2 = sm.add_constant(ftr_app)\n  target_app_arr = np.array(target_app)\n  est = sm.Logit(target_app_arr, X2)\n  est2 = est.fit()\n  print(est2.summary())\n\n  # app test \n  res = pd.DataFrame()\n  res[\"SK_ID_CURR\"] = apps_all_test[\"SK_ID_CURR\"]\n    \n  # apps_all_test \n  df_test = apps_all_test.copy()\n  X_apps_test = df_test.drop(\"SK_ID_CURR\", axis=1)\n\n  y_pred_test = clf.predict_proba(X_apps_test)[:, 1]\n  res[\"TARGET\"] = y_pred_test\n  \n  return df_off_preds, clf, res","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_off_preds, clf, test_res = StratifiedKFold_RUS_Stacking_LogisticReg_model(df=merged_df_train, nfolds=5, random_state=10, drop_columns_arr=['TARGET', 'SK_ID_CURR'], target_col='TARGET', apps_all_test=merged_df_test)\ndf_off_preds.to_csv(\"/kaggle/working/StratifiedKFold_RUS_Stacking_LogisticReg_train.csv\", index = False)\ntest_res.to_csv(\"/kaggle/working/StratifiedKFold_RUS_Stacking_LogisticReg_test.csv\", index = False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# SMOTE\ndef StratifiedKFold_SMOTE_Stacking_LogisticReg_model(df, nfolds, random_state, drop_columns_arr, target_col, apps_all_test):\n  # Data Frame\n  df_off_preds = pd.DataFrame()\n  df_off_preds['SK_ID_CURR'] = df['SK_ID_CURR']\n\n  ftr_app = df.drop(drop_columns_arr, axis=1)  # feature dateset\n  target_app = df[target_col]                  # target datasets\n  \n  # KFold\n  folds = StratifiedKFold(n_splits = nfolds, shuffle=True, random_state = random_state)\n\n  clf = LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n                           intercept_scaling=1, max_iter=5000, multi_class='ovr', n_jobs=1,\n                           penalty='l1', random_state=None, solver='saga', tol=0.0001,\n                           verbose=0, warm_start=False)\n  \n  oof_preds_proba = np.zeros(ftr_app.shape[0])\n  auc_scores = []\n    \n  # SMOTE\n  smote = SMOTE()\n\n  for fold_idx, (train_idx , valid_idx) in enumerate(folds.split(ftr_app, target_app)):\n        print(\"# iteration\", fold_idx, 'starts')\n        train_x = ftr_app.iloc[train_idx, :]\n        train_y = target_app.iloc[train_idx]\n        valid_x = ftr_app.iloc[valid_idx, :]\n        valid_y = target_app.iloc[valid_idx]\n\n        train_x_resampled, train_y_resampled = smote.fit_resample(train_x, train_y)\n        \n        # Fit ROS\n        clf.fit(train_x_resampled, train_y_resampled)\n\n        # Save predicted proba labels for validation set\n        oof_preds_proba[valid_idx] = clf.predict_proba(valid_x)[:, 1]\n\n        # compute AUC on validation set\n        auc_score = roc_auc_score(valid_y, oof_preds_proba[valid_idx])\n        auc_scores.append(auc_score)\n        print(f\"AUC: {auc_score}\")\n\n  print(f\"Mean AUC: {np.mean(auc_scores):.5f}\")  \n\n  df_off_preds['TARGET'] = oof_preds_proba\n\n  # SUMMARY\n  # calculate p-values\n  X2 = sm.add_constant(ftr_app)\n  target_app_arr = np.array(target_app)\n  est = sm.Logit(target_app_arr, X2)\n  est2 = est.fit()\n  print(est2.summary())\n\n  # app test \n  res = pd.DataFrame()\n  res[\"SK_ID_CURR\"] = apps_all_test[\"SK_ID_CURR\"]\n    \n  # apps_all_test \n  df_test = apps_all_test.copy()\n  X_apps_test = df_test.drop(\"SK_ID_CURR\", axis=1)\n\n  y_pred_test = clf.predict_proba(X_apps_test)[:, 1]\n  res[\"TARGET\"] = y_pred_test\n  \n  return df_off_preds, clf, res","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_off_preds, clf, test_res = StratifiedKFold_SMOTE_Stacking_LogisticReg_model(df=merged_df_train, nfolds=5, random_state=10, drop_columns_arr=['TARGET', 'SK_ID_CURR'], target_col='TARGET', apps_all_test=merged_df_test)\ndf_off_preds.to_csv(\"/kaggle/working/StratifiedKFold_SMOTE_Stacking_LogisticReg_train.csv\", index = False)\ntest_res.to_csv(\"/kaggle/working/StratifiedKFold_SMOTE_Stacking_LogisticReg_test.csv\", index = False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Random Forest","metadata":{}},{"cell_type":"markdown","source":"### K-Fold Cross-Validation","metadata":{}},{"cell_type":"code","source":"# No resampling method\ndef KFold_Stacking_RandomForest_model(df, nfolds, random_state, drop_columns_arr, target_col, apps_all_test):\n    df_off_preds = pd.DataFrame()\n    df_off_preds['SK_ID_CURR'] = df['SK_ID_CURR']\n\n    ftr_app = df.drop(drop_columns_arr, axis=1)  # feature dateset\n    target_app = df[target_col]                  # target datasets\n    # apply KFolds\n    folds = KFold(n_splits = nfolds, shuffle=True, random_state = random_state)\n    \n    oof_preds_proba = np.zeros(ftr_app.shape[0])\n    auc_scores = []\n\n    clf = RandomForestClassifier(n_estimators=1000\n           , criterion='gini'\n           , max_depth=10\n           , min_samples_split=10\n           , min_samples_leaf=30\n           )\n    \n    for fold_idx, (train_idx , valid_idx) in enumerate(folds.split(ftr_app, target_app)):\n        print(\"# iteration\", fold_idx, 'starts')\n        train_x = ftr_app.iloc[train_idx, :]\n        train_y = target_app.iloc[train_idx]\n        valid_x = ftr_app.iloc[valid_idx, :]\n        valid_y = target_app.iloc[valid_idx]\n        \n        clf.fit(train_x, train_y)\n        # Save predicted proba labels for validation set\n        oof_preds_proba[valid_idx] = clf.predict_proba(valid_x)[:, 1]\n\n        # compute AUC on validation set\n        auc_score = roc_auc_score(valid_y, oof_preds_proba[valid_idx])\n        auc_scores.append(auc_score)\n        print(f\"AUC: {auc_score}\")\n\n    print(f\"Mean AUC: {np.mean(auc_scores):.5f}\")\n\n    df_off_preds['KFold_RF_AUC_PROBA'] = oof_preds_proba\n\n    # apps_all_test \n    df_test = apps_all_test.copy()\n    test_res = pd.DataFrame()\n    # save SK_ID_CURR\n    test_res[\"SK_ID_CURR\"]=df_test[\"SK_ID_CURR\"]\n    # deal with missing value\n    df_test = df_test.replace([np.inf, -np.inf], np.nan)\n    # fill NaN with median value\n    df_test = df_test.fillna(-999)\n  \n    X_apps_test = df_test.drop(\"SK_ID_CURR\", axis=1)\n\n    y_apps_test = clf.predict_proba(X_apps_test)\n    test_res[f\"TARGET\"] = y_apps_test[:, 1]\n\n    return df_off_preds, clf, test_res","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_off_preds, clf, test_res = KFold_Stacking_RandomForest_model(df=merged_df_train, nfolds=5, random_state=10, drop_columns_arr=['TARGET', 'SK_ID_CURR'], target_col='TARGET', apps_all_test=merged_df_test)\ndf_off_preds.to_csv(\"/kaggle/working/KFold_Stacking_RandomForest_train.csv\", index = False)\ntest_res.to_csv(\"/kaggle/working/KFold_Stacking_RandomForest_test.csv\", index = False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Random Over Sampling\ndef KFold_ROS_Stacking_RandomForest_model(df, nfolds, random_state, drop_columns_arr, target_col, apps_all_test):\n    df_off_preds = pd.DataFrame()\n    df_off_preds['SK_ID_CURR'] = df['SK_ID_CURR']\n\n    ftr_app = df.drop(drop_columns_arr, axis=1)  # feature dateset\n    target_app = df[target_col]                  # target datasets\n    # apply KFolds\n    folds = KFold(n_splits = nfolds, shuffle=True, random_state = random_state)\n    \n    oof_preds_proba = np.zeros(ftr_app.shape[0])\n    auc_scores = []\n\n    clf = RandomForestClassifier(n_estimators=1000\n           , criterion='gini'\n           , max_depth=10\n           , min_samples_split=10\n           , min_samples_leaf=30\n           )\n    \n    ros = RandomOverSampler()\n    \n    for fold_idx, (train_idx , valid_idx) in enumerate(folds.split(ftr_app, target_app)):\n        print(\"# iteration\", fold_idx, 'starts')\n        train_x = ftr_app.iloc[train_idx, :]\n        train_y = target_app.iloc[train_idx]\n        valid_x = ftr_app.iloc[valid_idx, :]\n        valid_y = target_app.iloc[valid_idx]\n        \n        train_x_resampled, train_y_resampled = ros.fit_resample(train_x, train_y)\n\n        clf.fit(train_x_resampled, train_y_resampled)\n        # Save predicted proba labels for validation set\n        oof_preds_proba[valid_idx] = clf.predict_proba(valid_x)[:, 1]\n\n        # compute AUC on validation set\n        auc_score = roc_auc_score(valid_y, oof_preds_proba[valid_idx])\n        auc_scores.append(auc_score)\n        print(f\"AUC: {auc_score}\")\n\n    print(f\"Mean AUC: {np.mean(auc_scores):.5f}\")\n\n    df_off_preds['KFold_RF_AUC_PROBA'] = oof_preds_proba\n\n    # apps_all_test \n    df_test = apps_all_test.copy()\n    test_res = pd.DataFrame()\n    # save SK_ID_CURR\n    test_res[\"SK_ID_CURR\"]=df_test[\"SK_ID_CURR\"]\n    # deal with missing value\n    df_test = df_test.replace([np.inf, -np.inf], np.nan)\n    # fill NaN with median value\n    df_test = df_test.fillna(-999)\n  \n    X_apps_test = df_test.drop(\"SK_ID_CURR\", axis=1)\n\n    y_apps_test = clf.predict_proba(X_apps_test)\n    test_res[f\"TARGET\"] = y_apps_test[:, 1]\n\n    return df_off_preds, clf, test_res","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_off_preds, clf, test_res = KFold_ROS_Stacking_RandomForest_model(df=merged_df_train, nfolds=5, random_state=10, drop_columns_arr=['TARGET', 'SK_ID_CURR'], target_col='TARGET', apps_all_test=merged_df_test)\ndf_off_preds.to_csv(\"/kaggle/working/KFold_ROS_Stacking_RandomForest_train.csv\", index = False)\ntest_res.to_csv(\"/kaggle/working/KFold_ROS_Stacking_RandomForest_test.csv\", index = False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Random Under Sampling\ndef KFold_RUS_Stacking_RandomForest_model(df, nfolds, random_state, drop_columns_arr, target_col, apps_all_test):\n    df_off_preds = pd.DataFrame()\n    df_off_preds['SK_ID_CURR'] = df['SK_ID_CURR']\n\n    # deal with missing data\n    df = df.replace([np.inf, -np.inf], np.nan)\n    # Fill NaN with median value\n    df = df.fillna(-999)\n\n    ftr_app = df.drop(drop_columns_arr, axis=1)  # feature dateset\n    target_app = df[target_col]                  # target datasets\n    # apply KFolds\n    folds = KFold(n_splits = nfolds, shuffle=True, random_state = random_state)\n    \n    oof_preds_proba = np.zeros(ftr_app.shape[0])\n    auc_scores = []\n\n    clf = RandomForestClassifier(n_estimators=1000\n           , criterion='gini'\n           , max_depth=10\n           , min_samples_split=10\n           , min_samples_leaf=30\n           )\n    \n    rus = RandomUnderSampler()\n    \n    for fold_idx, (train_idx , valid_idx) in enumerate(folds.split(ftr_app, target_app)):\n        print(\"# iteration\", fold_idx, 'starts')\n        train_x = ftr_app.iloc[train_idx, :]\n        train_y = target_app.iloc[train_idx]\n        valid_x = ftr_app.iloc[valid_idx, :]\n        valid_y = target_app.iloc[valid_idx]\n        \n        train_x_resampled, train_y_resampled = rus.fit_resample(train_x, train_y)\n\n        clf.fit(train_x_resampled, train_y_resampled)\n        # Save predicted proba labels for validation set\n        oof_preds_proba[valid_idx] = clf.predict_proba(valid_x)[:, 1]\n\n        # compute AUC on validation set\n        auc_score = roc_auc_score(valid_y, oof_preds_proba[valid_idx])\n        auc_scores.append(auc_score)\n        print(f\"AUC: {auc_score}\")\n\n    print(f\"Mean AUC: {np.mean(auc_scores):.5f}\")\n\n    df_off_preds['KFold_RF_AUC_PROBA'] = oof_preds_proba\n\n    # apps_all_test \n    df_test = apps_all_test.copy()\n    test_res = pd.DataFrame()\n    # save SK_ID_CURR\n    test_res[\"SK_ID_CURR\"]=df_test[\"SK_ID_CURR\"]\n    # deal with missing value\n    df_test = df_test.replace([np.inf, -np.inf], np.nan)\n    # fill NaN with median value\n    df_test = df_test.fillna(-999)\n  \n    X_apps_test = df_test.drop(\"SK_ID_CURR\", axis=1)\n\n    y_apps_test = clf.predict_proba(X_apps_test)\n    test_res[f\"TARGET\"] = y_apps_test[:, 1]\n\n    return df_off_preds, clf, test_res","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_off_preds, clf, test_res = KFold_RUS_Stacking_RandomForest_model(df=merged_df_train, nfolds=5, random_state=10, drop_columns_arr=['TARGET', 'SK_ID_CURR'], target_col='TARGET', apps_all_test=merged_df_test)\ndf_off_preds.to_csv(\"/kaggle/working/KFold_RUS_Stacking_RandomForest_train.csv\", index = False)\ntest_res.to_csv(\"/kaggle/working/KFold_RUS_Stacking_RandomForest_test.csv\", index = False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# SMOTE\ndef KFold_SMOTE_Stacking_RandomForest_model(df, nfolds, random_state, drop_columns_arr, target_col, apps_all_test):\n    df_off_preds = pd.DataFrame()\n    df_off_preds['SK_ID_CURR'] = df['SK_ID_CURR']\n\n    # deal with missing data\n    df = df.replace([np.inf, -np.inf], np.nan)\n    # Fill NaN with median value\n    df = df.fillna(-999)\n\n    ftr_app = df.drop(drop_columns_arr, axis=1)  # feature dateset\n    target_app = df[target_col]                  # target datasets\n    # apply KFolds\n    folds = KFold(n_splits = nfolds, shuffle=True, random_state = random_state)\n    \n    oof_preds_proba = np.zeros(ftr_app.shape[0])\n    auc_scores = []\n\n    clf = RandomForestClassifier(n_estimators=1000\n           , criterion='gini'\n           , max_depth=10\n           , min_samples_split=10\n           , min_samples_leaf=30\n           )\n    \n    smote = SMOTE()\n    \n    for fold_idx, (train_idx , valid_idx) in enumerate(folds.split(ftr_app, target_app)):\n        print(\"# iteration\", fold_idx, 'starts')\n        train_x = ftr_app.iloc[train_idx, :]\n        train_y = target_app.iloc[train_idx]\n        valid_x = ftr_app.iloc[valid_idx, :]\n        valid_y = target_app.iloc[valid_idx]\n        \n        train_x_resampled, train_y_resampled = smote.fit_resample(train_x, train_y)\n\n        clf.fit(train_x_resampled, train_y_resampled)\n        # Save predicted proba labels for validation set\n        oof_preds_proba[valid_idx] = clf.predict_proba(valid_x)[:, 1]\n\n        # compute AUC on validation set\n        auc_score = roc_auc_score(valid_y, oof_preds_proba[valid_idx])\n        auc_scores.append(auc_score)\n        print(f\"AUC: {auc_score}\")\n\n    print(f\"Mean AUC: {np.mean(auc_scores):.5f}\")\n\n    df_off_preds['KFold_RF_AUC_PROBA'] = oof_preds_proba\n\n    # apps_all_test \n    df_test = apps_all_test.copy()\n    test_res = pd.DataFrame()\n    # save SK_ID_CURR\n    test_res[\"SK_ID_CURR\"]=df_test[\"SK_ID_CURR\"]\n    # deal with missing value\n    df_test = df_test.replace([np.inf, -np.inf], np.nan)\n    # fill NaN with median value\n    df_test = df_test.fillna(-999)\n  \n    X_apps_test = df_test.drop(\"SK_ID_CURR\", axis=1)\n\n    y_apps_test = clf.predict_proba(X_apps_test)\n    test_res[f\"TARGET\"] = y_apps_test[:, 1]\n\n    return df_off_preds, clf, test_res","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_off_preds, clf, test_res = KFold_SMOTE_Stacking_RandomForest_model(df=merged_df_train, nfolds=5, random_state=10, drop_columns_arr=['TARGET', 'SK_ID_CURR'], target_col='TARGET', apps_all_test=merged_df_test)\ndf_off_preds.to_csv(\"/kaggle/working/KFold_SMOTE_Stacking_RandomForest_train.csv\", index = False)\ntest_res.to_csv(\"/kaggle/working/KFold_SMOTE_Stacking_RandomForest_test.csv\", index = False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Stratified K-Fold Cross-Validation","metadata":{}},{"cell_type":"code","source":"# No resampling method\ndef StratifiedKFold_Stacking_RandomForest_model(df, nfolds, random_state, drop_columns_arr, target_col, apps_all_test):\n    df_off_preds = pd.DataFrame()\n    df_off_preds['SK_ID_CURR'] = df['SK_ID_CURR']\n\n    ftr_app = df.drop(drop_columns_arr, axis=1)  # feature dateset\n    target_app = df[target_col]                  # target datasets\n\n    folds = StratifiedKFold(n_splits = nfolds, shuffle=True, random_state = random_state)\n    \n    oof_preds_proba = np.zeros(ftr_app.shape[0])\n    auc_scores = []\n\n    clf = RandomForestClassifier(n_estimators=1000\n           , criterion='gini'\n           , max_depth=10\n           , min_samples_split=10\n           , min_samples_leaf=30\n           )\n    \n    for fold_idx, (train_idx , valid_idx) in enumerate(folds.split(ftr_app, target_app)):\n        print(\"# iteration\", fold_idx, 'starts')\n        train_x = ftr_app.iloc[train_idx, :]\n        train_y = target_app.iloc[train_idx]\n        valid_x = ftr_app.iloc[valid_idx, :]\n        valid_y = target_app.iloc[valid_idx]\n        \n        clf.fit(train_x, train_y)\n        # Save predicted proba labels for validation set\n        oof_preds_proba[valid_idx] = clf.predict_proba(valid_x)[:, 1]\n\n        # compute AUC on validation set\n        auc_score = roc_auc_score(valid_y, oof_preds_proba[valid_idx])\n        auc_scores.append(auc_score)\n        print(f\"AUC: {auc_score}\")\n\n    print(f\"Mean AUC: {np.mean(auc_scores):.5f}\")\n\n    df_off_preds['KFold_RF_AUC_PROBA'] = oof_preds_proba\n\n    # apps_all_test \n    df_test = apps_all_test.copy()\n    test_res = pd.DataFrame()\n    # save SK_ID_CURR\n    test_res[\"SK_ID_CURR\"]=df_test[\"SK_ID_CURR\"]\n    # deal with missing value\n    df_test = df_test.replace([np.inf, -np.inf], np.nan)\n    # fill NaN with median value\n    df_test = df_test.fillna(-999)\n  \n    X_apps_test = df_test.drop(\"SK_ID_CURR\", axis=1)\n\n    y_apps_test = clf.predict_proba(X_apps_test)\n    test_res[f\"TARGET\"] = y_apps_test[:, 1]\n\n    return df_off_preds, clf, test_res","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_off_preds, clf, test_res = StratifiedKFold_Stacking_RandomForest_model(df=merged_df_train, nfolds=5, random_state=10, drop_columns_arr=['TARGET', 'SK_ID_CURR'], target_col='TARGET', apps_all_test=merged_df_test)\ndf_off_preds.to_csv(\"/kaggle/working/StratifiedKFold_Stacking_RandomForest_train.csv\", index = False)\ntest_res.to_csv(\"/kaggle/working/StratifiedKFold_Stacking_RandomForest_test.csv\", index = False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Random Over Sampling\ndef StratifiedKFold_ROS_Stacking_RandomForest_model(df, nfolds, random_state, drop_columns_arr, target_col, apps_all_test):\n    df_off_preds = pd.DataFrame()\n    df_off_preds['SK_ID_CURR'] = df['SK_ID_CURR']\n\n    # deal with missing data\n    df = df.replace([np.inf, -np.inf], np.nan)\n    # Fill NaN with median value\n    df = df.fillna(-999)\n\n    ftr_app = df.drop(drop_columns_arr, axis=1)  # feature dateset\n    target_app = df[target_col]                  # target datasets\n\n    folds = StratifiedKFold(n_splits = nfolds, shuffle=True, random_state = random_state)\n    \n    oof_preds_proba = np.zeros(ftr_app.shape[0])\n    auc_scores = []\n\n    clf = RandomForestClassifier(n_estimators=1000\n           , criterion='gini'\n           , max_depth=10\n           , min_samples_split=10\n           , min_samples_leaf=30\n           )\n    \n    ros = RandomOverSampler()\n    \n    for fold_idx, (train_idx , valid_idx) in enumerate(folds.split(ftr_app, target_app)):\n        print(\"# iteration\", fold_idx, 'starts')\n        train_x = ftr_app.iloc[train_idx, :]\n        train_y = target_app.iloc[train_idx]\n        valid_x = ftr_app.iloc[valid_idx, :]\n        valid_y = target_app.iloc[valid_idx]\n        \n        train_x_resampled, train_y_resampled = ros.fit_resample(train_x, train_y)\n\n        clf.fit(train_x_resampled, train_y_resampled)\n        # Save predicted proba labels for validation set\n        oof_preds_proba[valid_idx] = clf.predict_proba(valid_x)[:, 1]\n\n        # compute AUC on validation set\n        auc_score = roc_auc_score(valid_y, oof_preds_proba[valid_idx])\n        auc_scores.append(auc_score)\n        print(f\"AUC: {auc_score}\")\n\n    print(f\"Mean AUC: {np.mean(auc_scores):.5f}\")\n\n    df_off_preds['KFold_RF_AUC_PROBA'] = oof_preds_proba\n\n    # apps_all_test \n    df_test = apps_all_test.copy()\n    test_res = pd.DataFrame()\n    # save SK_ID_CURR\n    test_res[\"SK_ID_CURR\"]=df_test[\"SK_ID_CURR\"]\n    # deal with missing value\n    df_test = df_test.replace([np.inf, -np.inf], np.nan)\n    # fill NaN with median value\n    df_test = df_test.fillna(-999)\n  \n    X_apps_test = df_test.drop(\"SK_ID_CURR\", axis=1)\n\n    y_apps_test = clf.predict_proba(X_apps_test)\n    test_res[f\"TARGET\"] = y_apps_test[:, 1]\n\n    return df_off_preds, clf, test_res","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_off_preds, clf, test_res = StratifiedKFold_ROS_Stacking_RandomForest_model(df=merged_df_train, nfolds=5, random_state=10, drop_columns_arr=['TARGET', 'SK_ID_CURR'], target_col='TARGET', apps_all_test=merged_df_test)\ndf_off_preds.to_csv(\"/kaggle/working/StratifiedKFold_ROS_Stacking_RandomForest_train.csv\", index = False)\ntest_res.to_csv(\"/kaggle/working/StratifiedKFold_ROS_Stacking_RandomForest_test.csv\", index = False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Random Under Sampling\ndef StratifiedKFold_RUS_Stacking_RandomForest_model(df, nfolds, random_state, drop_columns_arr, target_col, apps_all_test):\n    df_off_preds = pd.DataFrame()\n    df_off_preds['SK_ID_CURR'] = df['SK_ID_CURR']\n\n    # deal with missing data\n    df = df.replace([np.inf, -np.inf], np.nan)\n    # Fill NaN with median value\n    df = df.fillna(-999)\n\n    ftr_app = df.drop(drop_columns_arr, axis=1)  # feature dateset\n    target_app = df[target_col]                  # target datasets\n    \n    folds = StratifiedKFold(n_splits = nfolds, shuffle=True, random_state = random_state)\n    \n    oof_preds_proba = np.zeros(ftr_app.shape[0])\n    auc_scores = []\n\n    clf = RandomForestClassifier(n_estimators=1000\n           , criterion='gini'\n           , max_depth=10\n           , min_samples_split=10\n           , min_samples_leaf=30\n           )\n    \n    rus = RandomUnderSampler()\n    \n    for fold_idx, (train_idx , valid_idx) in enumerate(folds.split(ftr_app, target_app)):\n        print(\"# iteration\", fold_idx, 'starts')\n        train_x = ftr_app.iloc[train_idx, :]\n        train_y = target_app.iloc[train_idx]\n        valid_x = ftr_app.iloc[valid_idx, :]\n        valid_y = target_app.iloc[valid_idx]\n        \n        train_x_resampled, train_y_resampled = rus.fit_resample(train_x, train_y)\n\n        clf.fit(train_x_resampled, train_y_resampled)\n        # Save predicted proba labels for validation set\n        oof_preds_proba[valid_idx] = clf.predict_proba(valid_x)[:, 1]\n\n        # compute AUC on validation set\n        auc_score = roc_auc_score(valid_y, oof_preds_proba[valid_idx])\n        auc_scores.append(auc_score)\n        print(f\"AUC: {auc_score}\")\n\n    print(f\"Mean AUC: {np.mean(auc_scores):.5f}\")\n\n    df_off_preds['KFold_RF_AUC_PROBA'] = oof_preds_proba\n\n    # apps_all_test \n    df_test = apps_all_test.copy()\n    test_res = pd.DataFrame()\n    # save SK_ID_CURR\n    test_res[\"SK_ID_CURR\"]=df_test[\"SK_ID_CURR\"]\n    # deal with missing value\n    df_test = df_test.replace([np.inf, -np.inf], np.nan)\n    # fill NaN with median value\n    df_test = df_test.fillna(-999)\n  \n    X_apps_test = df_test.drop(\"SK_ID_CURR\", axis=1)\n\n    y_apps_test = clf.predict_proba(X_apps_test)\n    test_res[f\"TARGET\"] = y_apps_test[:, 1]\n\n    return df_off_preds, clf, test_res","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_off_preds, clf, test_res = StratifiedKFold_RUS_Stacking_RandomForest_model(df=merged_df_train, nfolds=5, random_state=10, drop_columns_arr=['TARGET', 'SK_ID_CURR'], target_col='TARGET', apps_all_test=merged_df_test)\ndf_off_preds.to_csv(\"/kaggle/working/StratifiedKFold_RUS_Stacking_RandomForest_train.csv\", index = False)\ntest_res.to_csv(\"/kaggle/working/StratifiedKFold_RUS_Stacking_RandomForest_test.csv\", index = False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# SMOTE\ndef StratifiedKFold_SMOTE_Stacking_RandomForest_model(df, nfolds, random_state, drop_columns_arr, target_col, apps_all_test):\n    df_off_preds = pd.DataFrame()\n    df_off_preds['SK_ID_CURR'] = df['SK_ID_CURR']\n\n    # deal with missing data\n    df = df.replace([np.inf, -np.inf], np.nan)\n    # Fill NaN with median value\n    df = df.fillna(-999)\n\n    ftr_app = df.drop(drop_columns_arr, axis=1)  # feature dateset\n    target_app = df[target_col]                  # target datasets\n    \n    folds = StratifiedKFold(n_splits = nfolds, shuffle=True, random_state = random_state)\n    \n    oof_preds_proba = np.zeros(ftr_app.shape[0])\n    auc_scores = []\n\n    clf = RandomForestClassifier(n_estimators=1000\n           , criterion='gini'\n           , max_depth=10\n           , min_samples_split=10\n           , min_samples_leaf=30\n           )\n    \n    smote = SMOTE()\n    \n    for fold_idx, (train_idx , valid_idx) in enumerate(folds.split(ftr_app, target_app)):\n        print(\"# iteration\", fold_idx, 'starts')\n        train_x = ftr_app.iloc[train_idx, :]\n        train_y = target_app.iloc[train_idx]\n        valid_x = ftr_app.iloc[valid_idx, :]\n        valid_y = target_app.iloc[valid_idx]\n        \n        train_x_resampled, train_y_resampled = smote.fit_resample(train_x, train_y)\n\n        clf.fit(train_x_resampled, train_y_resampled)\n        # Save predicted proba labels for validation set\n        oof_preds_proba[valid_idx] = clf.predict_proba(valid_x)[:, 1]\n\n        # compute AUC on validation set\n        auc_score = roc_auc_score(valid_y, oof_preds_proba[valid_idx])\n        auc_scores.append(auc_score)\n        print(f\"AUC: {auc_score}\")\n\n    print(f\"Mean AUC: {np.mean(auc_scores):.5f}\")\n\n    df_off_preds['KFold_RF_AUC_PROBA'] = oof_preds_proba\n\n    # apps_all_test \n    df_test = apps_all_test.copy()\n    test_res = pd.DataFrame()\n    # save SK_ID_CURR\n    test_res[\"SK_ID_CURR\"]=df_test[\"SK_ID_CURR\"]\n    # deal with missing value\n    df_test = df_test.replace([np.inf, -np.inf], np.nan)\n    # fill NaN with median value\n    df_test = df_test.fillna(-999)\n  \n    X_apps_test = df_test.drop(\"SK_ID_CURR\", axis=1)\n\n    y_apps_test = clf.predict_proba(X_apps_test)\n    test_res[f\"TARGET\"] = y_apps_test[:, 1]\n\n    return df_off_preds, clf, test_res","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_off_preds, clf, test_res = StratifiedKFold_SMOTE_Stacking_RandomForest_model(df=merged_df_train, nfolds=5, random_state=10, drop_columns_arr=['TARGET', 'SK_ID_CURR'], target_col='TARGET', apps_all_test=merged_df_test)\ndf_off_preds.to_csv(\"/kaggle/working/StratifiedKFold_SMOTE_Stacking_RandomForest_train.csv\", index = False)\ntest_res.to_csv(\"/kaggle/working/StratifiedKFold_SMOTE_Stacking_RandomForest_test.csv\", index = False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Gradient Boosting","metadata":{}},{"cell_type":"markdown","source":"### K-Fold Cross-Validation","metadata":{}},{"cell_type":"code","source":"# No resampling method\ndef KFold_Stacking_GBoosting_model(df, nfolds, random_state, drop_columns_arr, target_col, apps_all_test):    \n    df_off_preds = pd.DataFrame()\n    df_off_preds['SK_ID_CURR'] = df['SK_ID_CURR']\n\n    ftr_app = df.drop(drop_columns_arr, axis=1)  # feature dateset\n    target_app = df[target_col]                  # target datasets\n    \n    folds = KFold(n_splits = nfolds, shuffle=True, random_state = random_state)\n    \n    clf = GradientBoostingClassifier(n_estimators=200, learning_rate=0.008, max_depth=5, random_state=0, loss='deviance')\n    \n    print(\"AUC:\")\n    oof_preds_proba = np.zeros(ftr_app.shape[0])\n    auc_scores = []\n\n    for fold_idx, (train_idx , valid_idx) in enumerate(folds.split(ftr_app, target_app)):\n        print(\"#iteration \", fold_idx, 'starts')\n        train_x = ftr_app.iloc[train_idx, :]\n        train_y = target_app.iloc[train_idx]\n        valid_x = ftr_app.iloc[valid_idx, :]\n        valid_y = target_app.iloc[valid_idx]\n        \n        clf.fit(train_x, train_y)\n        # Save predicted proba labels for validation set\n        oof_preds_proba[valid_idx] = clf.predict_proba(valid_x)[:, 1]\n        \n        # compute AUC on validation set\n        auc_score = roc_auc_score(valid_y, oof_preds_proba[valid_idx])\n        auc_scores.append(auc_score)\n        print(f\"AUC: {auc_score}\")\n\n    print(f\"Mean AUC: {np.mean(auc_scores):.5f}\")\n        \n    # return Target of train set\n    df_off_preds['TARGET'] = oof_preds_proba\n\n    # apps_all_test \n    df_test = apps_all_test.copy()\n    test_res = pd.DataFrame()\n    # save SK_ID_CURR\n    test_res[\"SK_ID_CURR\"]=df_test[\"SK_ID_CURR\"]\n  \n    X_apps_test = df_test.drop(\"SK_ID_CURR\", axis=1)\n\n    y_apps_test = clf.predict_proba(X_apps_test)\n    test_res[\"TARGET\"] = y_apps_test[:, 1]\n\n    return df_off_preds, clf, test_res","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_off_preds, clf, test_res = KFold_Stacking_GBoosting_model(df=merged_df_train, nfolds=5, random_state=10, drop_columns_arr=['TARGET', 'SK_ID_CURR'], target_col='TARGET', apps_all_test=merged_df_test)\ndf_off_preds.to_csv(\"/kaggle/working/KFold_Stacking_GBoosting_train.csv\", index = False)\ntest_res.to_csv(\"/kaggle/working/KFold_Stacking_GBoosting_test.csv\", index = False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Random Over Sampling\ndef KFold_ROS_Stacking_GBoosting_model(df, nfolds, random_state, drop_columns_arr, target_col, apps_all_test):    \n    df_off_preds = pd.DataFrame()\n    df_off_preds['SK_ID_CURR'] = df['SK_ID_CURR']\n\n    ftr_app = df.drop(drop_columns_arr, axis=1)  # feature dateset\n    target_app = df[target_col]                  # target datasets\n    \n    folds = KFold(n_splits = nfolds, shuffle=True, random_state = random_state)\n    \n    ros = RandomOverSampler()\n    \n    clf = GradientBoostingClassifier(n_estimators=200, learning_rate=0.008, max_depth=5, random_state=0, loss='deviance')\n    \n    print(\"AUC:\")\n    oof_preds_proba = np.zeros(ftr_app.shape[0])\n    auc_scores = []\n\n    for fold_idx, (train_idx , valid_idx) in enumerate(folds.split(ftr_app, target_app)):\n        print(\"#iteration \", fold_idx, 'starts')\n        train_x = ftr_app.iloc[train_idx, :]\n        train_y = target_app.iloc[train_idx]\n        valid_x = ftr_app.iloc[valid_idx, :]\n        valid_y = target_app.iloc[valid_idx]\n        \n        train_x_resampled, train_y_resampled = ros.fit_resample(train_x, train_y)\n\n        clf.fit(train_x_resampled, train_y_resampled)\n        # Save predicted proba labels for validation set\n        oof_preds_proba[valid_idx] = clf.predict_proba(valid_x)[:, 1]\n        \n        # compute AUC on validation set\n        auc_score = roc_auc_score(valid_y, oof_preds_proba[valid_idx])\n        auc_scores.append(auc_score)\n        print(f\"AUC: {auc_score}\")\n\n    print(f\"Mean AUC: {np.mean(auc_scores):.5f}\")\n        \n    # return Target of train set\n    df_off_preds['TARGET'] = oof_preds_proba\n\n    # apps_all_test \n    df_test = apps_all_test.copy()\n    test_res = pd.DataFrame()\n    # save SK_ID_CURR\n    test_res[\"SK_ID_CURR\"]=df_test[\"SK_ID_CURR\"]\n  \n    X_apps_test = df_test.drop(\"SK_ID_CURR\", axis=1)\n\n    y_apps_test = clf.predict_proba(X_apps_test)\n    test_res[\"TARGET\"] = y_apps_test[:, 1]\n\n    return df_off_preds, clf, test_res","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_off_preds, clf, test_res = KFold_ROS_Stacking_GBoosting_model(df=merged_df_train, nfolds=5, random_state=10, drop_columns_arr=['TARGET', 'SK_ID_CURR'], target_col='TARGET', apps_all_test=merged_df_test)\ndf_off_preds.to_csv(\"/kaggle/working/KFold_ROS_Stacking_GBoosting_train.csv\", index = False)\ntest_res.to_csv(\"/kaggle/working/KFold_ROS_Stacking_GBoosting_test.csv\", index = False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Random Under Sampling\ndef KFold_RUS_Stacking_GBoosting_model(df, nfolds, random_state, drop_columns_arr, target_col, apps_all_test):    \n    df_off_preds = pd.DataFrame()\n    df_off_preds['SK_ID_CURR'] = df['SK_ID_CURR']\n\n    ftr_app = df.drop(drop_columns_arr, axis=1)  # feature dateset\n    target_app = df[target_col]                  # target datasets\n    \n    folds = KFold(n_splits = nfolds, shuffle=True, random_state = random_state)\n    \n    rus = RandomUnderSampler()\n    \n    clf = GradientBoostingClassifier(n_estimators=200, learning_rate=0.008, max_depth=5, random_state=0, loss='deviance')\n    \n    print(\"AUC:\")\n    oof_preds_proba = np.zeros(ftr_app.shape[0])\n    auc_scores = []\n\n    for fold_idx, (train_idx , valid_idx) in enumerate(folds.split(ftr_app, target_app)):\n        print(\"#iteration \", fold_idx, 'starts')\n        train_x = ftr_app.iloc[train_idx, :]\n        train_y = target_app.iloc[train_idx]\n        valid_x = ftr_app.iloc[valid_idx, :]\n        valid_y = target_app.iloc[valid_idx]\n        \n        train_x_resampled, train_y_resampled = rus.fit_resample(train_x, train_y)\n\n        clf.fit(train_x_resampled, train_y_resampled)\n        # Save predicted proba labels for validation set\n        oof_preds_proba[valid_idx] = clf.predict_proba(valid_x)[:, 1]\n        \n        # compute AUC on validation set\n        auc_score = roc_auc_score(valid_y, oof_preds_proba[valid_idx])\n        auc_scores.append(auc_score)\n        print(f\"AUC: {auc_score}\")\n\n    print(f\"Mean AUC: {np.mean(auc_scores):.5f}\")\n        \n    # return Target of train set\n    df_off_preds['TARGET'] = oof_preds_proba\n\n    # apps_all_test \n    df_test = apps_all_test.copy()\n    test_res = pd.DataFrame()\n    # save SK_ID_CURR\n    test_res[\"SK_ID_CURR\"]=df_test[\"SK_ID_CURR\"]\n  \n    X_apps_test = df_test.drop(\"SK_ID_CURR\", axis=1)\n\n    y_apps_test = clf.predict_proba(X_apps_test)\n    test_res[\"TARGET\"] = y_apps_test[:, 1]\n\n    return df_off_preds, clf, test_res","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_off_preds, clf, test_res = KFold_RUS_Stacking_GBoosting_model(df=merged_df_train, nfolds=5, random_state=10, drop_columns_arr=['TARGET', 'SK_ID_CURR'], target_col='TARGET', apps_all_test=merged_df_test)\ndf_off_preds.to_csv(\"/kaggle/working/KFold_RUS_Stacking_GBoosting_train.csv\", index = False)\ntest_res.to_csv(\"/kaggle/working/KFold_RUS_Stacking_GBoosting_test.csv\", index = False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# SMOTE\ndef KFold_SMOTE_Stacking_GBoosting_model(df, nfolds, random_state, drop_columns_arr, target_col, apps_all_test):    \n    df_off_preds = pd.DataFrame()\n    df_off_preds['SK_ID_CURR'] = df['SK_ID_CURR']\n\n    ftr_app = df.drop(drop_columns_arr, axis=1)  # feature dateset\n    target_app = df[target_col]                  # target datasets\n    \n    folds = KFold(n_splits = nfolds, shuffle=True, random_state = random_state)\n    \n    smote = SMOTE()\n    \n    clf = GradientBoostingClassifier(n_estimators=200, learning_rate=0.008, max_depth=5, random_state=0, loss='deviance')\n    \n    print(\"AUC:\")\n    oof_preds_proba = np.zeros(ftr_app.shape[0])\n    auc_scores = []\n\n    for fold_idx, (train_idx , valid_idx) in enumerate(folds.split(ftr_app, target_app)):\n        print(\"#iteration \", fold_idx, 'starts')\n        train_x = ftr_app.iloc[train_idx, :]\n        train_y = target_app.iloc[train_idx]\n        valid_x = ftr_app.iloc[valid_idx, :]\n        valid_y = target_app.iloc[valid_idx]\n        \n        train_x_resampled, train_y_resampled = smote.fit_resample(train_x, train_y)\n\n        clf.fit(train_x_resampled, train_y_resampled)\n        # Save predicted proba labels for validation set\n        oof_preds_proba[valid_idx] = clf.predict_proba(valid_x)[:, 1]\n        \n        # compute AUC on validation set\n        auc_score = roc_auc_score(valid_y, oof_preds_proba[valid_idx])\n        auc_scores.append(auc_score)\n        print(f\"AUC: {auc_score}\")\n\n    print(f\"Mean AUC: {np.mean(auc_scores):.5f}\")\n        \n    # return Target of train set\n    df_off_preds['TARGET'] = oof_preds_proba\n\n    # apps_all_test \n    df_test = apps_all_test.copy()\n    test_res = pd.DataFrame()\n    # save SK_ID_CURR\n    test_res[\"SK_ID_CURR\"]=df_test[\"SK_ID_CURR\"]\n  \n    X_apps_test = df_test.drop(\"SK_ID_CURR\", axis=1)\n\n    y_apps_test = clf.predict_proba(X_apps_test)\n    test_res[\"TARGET\"] = y_apps_test[:, 1]\n\n    return df_off_preds, clf, test_res","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_off_preds, clf, test_res = KFold_SMOTE_Stacking_GBoosting_model(df=merged_df_train, nfolds=5, random_state=10, drop_columns_arr=['TARGET', 'SK_ID_CURR'], target_col='TARGET', apps_all_test=merged_df_test)\ndf_off_preds.to_csv(\"/kaggle/working/KFold_SMOTE_Stacking_GBoosting_train.csv\", index = False)\ntest_res.to_csv(\"/kaggle/working/KFold_SMOTE_Stacking_GBoosting_test.csv\", index = False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Stratified K-Fold Cross-Validation","metadata":{}},{"cell_type":"code","source":"# No resampling method\ndef StratifiedKFold_Stacking_GBoosting_model(df, nfolds, random_state, drop_columns_arr, target_col, apps_all_test):    \n    df_off_preds = pd.DataFrame()\n    df_off_preds['SK_ID_CURR'] = df['SK_ID_CURR']\n\n    ftr_app = df.drop(drop_columns_arr, axis=1)  # feature dateset\n    target_app = df[target_col]                  # target datasets\n    \n    folds = StratifiedKFold(n_splits = nfolds, shuffle=True, random_state = random_state)\n    \n    clf = GradientBoostingClassifier(n_estimators=200, learning_rate=0.008, max_depth=5, random_state=0, loss='deviance')\n    \n    print(\"AUC:\")\n    oof_preds_proba = np.zeros(ftr_app.shape[0])\n    auc_scores = []\n\n    for fold_idx, (train_idx , valid_idx) in enumerate(folds.split(ftr_app, target_app)):\n        print(\"#iteration \", fold_idx, 'starts')\n        train_x = ftr_app.iloc[train_idx, :]\n        train_y = target_app.iloc[train_idx]\n        valid_x = ftr_app.iloc[valid_idx, :]\n        valid_y = target_app.iloc[valid_idx]\n        \n        clf.fit(train_x, train_y)\n        # Save predicted proba labels for validation set\n        oof_preds_proba[valid_idx] = clf.predict_proba(valid_x)[:, 1]\n        \n        # compute AUC on validation set\n        auc_score = roc_auc_score(valid_y, oof_preds_proba[valid_idx])\n        auc_scores.append(auc_score)\n        print(f\"AUC: {auc_score}\")\n\n    print(f\"Mean AUC: {np.mean(auc_scores):.5f}\")\n        \n    # return Target of train set\n    df_off_preds['TARGET'] = oof_preds_proba\n\n    # apps_all_test \n    df_test = apps_all_test.copy()\n    test_res = pd.DataFrame()\n    # save SK_ID_CURR\n    test_res[\"SK_ID_CURR\"]=df_test[\"SK_ID_CURR\"]\n  \n    X_apps_test = df_test.drop(\"SK_ID_CURR\", axis=1)\n\n    y_apps_test = clf.predict_proba(X_apps_test)\n    test_res[\"TARGET\"] = y_apps_test[:, 1]\n\n    return df_off_preds, clf, test_res","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_off_preds, clf, test_res = StratifiedKFold_Stacking_GBoosting_model(df=merged_df_train, nfolds=5, random_state=10, drop_columns_arr=['TARGET', 'SK_ID_CURR'], target_col='TARGET', apps_all_test=merged_df_test)\ndf_off_preds.to_csv(\"/kaggle/working/StratifiedKFold_Stacking_GBoosting_train.csv\", index = False)\ntest_res.to_csv(\"/kaggle/working/StratifiedKFold_Stacking_GBoosting_test.csv\", index = False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Random Over Sampling\ndef StratifiedKFold_ROS_Stacking_GBoosting_model(df, nfolds, random_state, drop_columns_arr, target_col, apps_all_test):    \n    df_off_preds = pd.DataFrame()\n    df_off_preds['SK_ID_CURR'] = df['SK_ID_CURR']\n\n    ftr_app = df.drop(drop_columns_arr, axis=1)  # feature dateset\n    target_app = df[target_col]                  # target datasets\n    \n    folds = StratifiedKFold(n_splits = nfolds, shuffle=True, random_state = random_state)\n    \n    ros = RandomOverSampler()\n    \n    clf = GradientBoostingClassifier(n_estimators=200, learning_rate=0.008, max_depth=5, random_state=0, loss='deviance')\n    \n    print(\"AUC:\")\n    oof_preds_proba = np.zeros(ftr_app.shape[0])\n    auc_scores = []\n\n    for fold_idx, (train_idx , valid_idx) in enumerate(folds.split(ftr_app, target_app)):\n        print(\"#iteration \", fold_idx, 'starts')\n        train_x = ftr_app.iloc[train_idx, :]\n        train_y = target_app.iloc[train_idx]\n        valid_x = ftr_app.iloc[valid_idx, :]\n        valid_y = target_app.iloc[valid_idx]\n        \n        train_x_resampled, train_y_resampled = ros.fit_resample(train_x, train_y)\n\n        clf.fit(train_x_resampled, train_y_resampled)\n        # Save predicted proba labels for validation set\n        oof_preds_proba[valid_idx] = clf.predict_proba(valid_x)[:, 1]\n        \n        # compute AUC on validation set\n        auc_score = roc_auc_score(valid_y, oof_preds_proba[valid_idx])\n        auc_scores.append(auc_score)\n        print(f\"AUC: {auc_score}\")\n\n    print(f\"Mean AUC: {np.mean(auc_scores):.5f}\")\n        \n    # return Target of train set\n    df_off_preds['TARGET'] = oof_preds_proba\n\n    # apps_all_test \n    df_test = apps_all_test.copy()\n    test_res = pd.DataFrame()\n    # save SK_ID_CURR\n    test_res[\"SK_ID_CURR\"]=df_test[\"SK_ID_CURR\"]\n  \n    X_apps_test = df_test.drop(\"SK_ID_CURR\", axis=1)\n\n    y_apps_test = clf.predict_proba(X_apps_test)\n    test_res[\"TARGET\"] = y_apps_test[:, 1]\n\n    return df_off_preds, clf, test_res","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_off_preds, clf, test_res = StratifiedKFold_ROS_Stacking_GBoosting_model(df=merged_df_train, nfolds=5, random_state=10, drop_columns_arr=['TARGET', 'SK_ID_CURR'], target_col='TARGET', apps_all_test=merged_df_test)\ndf_off_preds.to_csv(\"/kaggle/working/StratifiedKFold_ROS_Stacking_GBoosting_train.csv\", index = False)\ntest_res.to_csv(\"/kaggle/working/StratifiedKFold_ROS_Stacking_GBoosting_test.csv\", index = False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Random Under Sampling\ndef StratifiedKFold_RUS_Stacking_GBoosting_model(df, nfolds, random_state, drop_columns_arr, target_col, apps_all_test):    \n    df_off_preds = pd.DataFrame()\n    df_off_preds['SK_ID_CURR'] = df['SK_ID_CURR']\n\n    ftr_app = df.drop(drop_columns_arr, axis=1)  # feature dateset\n    target_app = df[target_col]                  # target datasets\n    \n    folds = StratifiedKFold(n_splits = nfolds, shuffle=True, random_state = random_state)\n    \n    rus = RandomUnderSampler()\n    \n    clf = GradientBoostingClassifier(n_estimators=200, learning_rate=0.008, max_depth=5, random_state=0, loss='deviance')\n    \n    print(\"AUC:\")\n    oof_preds_proba = np.zeros(ftr_app.shape[0])\n    auc_scores = []\n\n    for fold_idx, (train_idx , valid_idx) in enumerate(folds.split(ftr_app, target_app)):\n        print(\"#iteration \", fold_idx, 'starts')\n        train_x = ftr_app.iloc[train_idx, :]\n        train_y = target_app.iloc[train_idx]\n        valid_x = ftr_app.iloc[valid_idx, :]\n        valid_y = target_app.iloc[valid_idx]\n        \n        train_x_resampled, train_y_resampled = rus.fit_resample(train_x, train_y)\n\n        clf.fit(train_x_resampled, train_y_resampled)\n        # Save predicted proba labels for validation set\n        oof_preds_proba[valid_idx] = clf.predict_proba(valid_x)[:, 1]\n        \n        # compute AUC on validation set\n        auc_score = roc_auc_score(valid_y, oof_preds_proba[valid_idx])\n        auc_scores.append(auc_score)\n        print(f\"AUC: {auc_score}\")\n\n    print(f\"Mean AUC: {np.mean(auc_scores):.5f}\")\n        \n    # return Target of train set\n    df_off_preds['TARGET'] = oof_preds_proba\n\n    # apps_all_test \n    df_test = apps_all_test.copy()\n    test_res = pd.DataFrame()\n    # save SK_ID_CURR\n    test_res[\"SK_ID_CURR\"]=df_test[\"SK_ID_CURR\"]\n  \n    X_apps_test = df_test.drop(\"SK_ID_CURR\", axis=1)\n\n    y_apps_test = clf.predict_proba(X_apps_test)\n    test_res[\"TARGET\"] = y_apps_test[:, 1]\n\n    return df_off_preds, clf, test_res","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_off_preds, clf, test_res = StratifiedKFold_RUS_Stacking_GBoosting_model(df=merged_df_train, nfolds=5, random_state=10, drop_columns_arr=['TARGET', 'SK_ID_CURR'], target_col='TARGET', apps_all_test=merged_df_test)\ndf_off_preds.to_csv(\"/kaggle/working/StratifiedKFold_RUS_Stacking_GBoosting_train.csv\", index = False)\ntest_res.to_csv(\"/kaggle/working/StratifiedKFold_RUS_Stacking_GBoosting_test.csv\", index = False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# SMOTE\ndef StratifiedKFold_SMOTE_Stacking_GBoosting_model(df, nfolds, random_state, drop_columns_arr, target_col, apps_all_test):    \n    df_off_preds = pd.DataFrame()\n    df_off_preds['SK_ID_CURR'] = df['SK_ID_CURR']\n\n    ftr_app = df.drop(drop_columns_arr, axis=1)  # feature dateset\n    target_app = df[target_col]                  # target datasets\n    \n    folds = StratifiedKFold(n_splits = nfolds, shuffle=True, random_state = random_state)\n    \n    smote = SMOTE()\n    \n    clf = GradientBoostingClassifier(n_estimators=200, learning_rate=0.008, max_depth=5, random_state=0, loss='deviance')\n    \n    print(\"AUC:\")\n    oof_preds_proba = np.zeros(ftr_app.shape[0])\n    auc_scores = []\n\n    for fold_idx, (train_idx , valid_idx) in enumerate(folds.split(ftr_app, target_app)):\n        print(\"#iteration \", fold_idx, 'starts')\n        train_x = ftr_app.iloc[train_idx, :]\n        train_y = target_app.iloc[train_idx]\n        valid_x = ftr_app.iloc[valid_idx, :]\n        valid_y = target_app.iloc[valid_idx]\n        \n        train_x_resampled, train_y_resampled = smote.fit_resample(train_x, train_y)\n\n        clf.fit(train_x_resampled, train_y_resampled)\n        # Save predicted proba labels for validation set\n        oof_preds_proba[valid_idx] = clf.predict_proba(valid_x)[:, 1]\n        \n        # compute AUC on validation set\n        auc_score = roc_auc_score(valid_y, oof_preds_proba[valid_idx])\n        auc_scores.append(auc_score)\n        print(f\"AUC: {auc_score}\")\n\n    print(f\"Mean AUC: {np.mean(auc_scores):.5f}\")\n        \n    # return Target of train set\n    df_off_preds['TARGET'] = oof_preds_proba\n\n    # apps_all_test \n    df_test = apps_all_test.copy()\n    test_res = pd.DataFrame()\n    # save SK_ID_CURR\n    test_res[\"SK_ID_CURR\"]=df_test[\"SK_ID_CURR\"]\n  \n    X_apps_test = df_test.drop(\"SK_ID_CURR\", axis=1)\n\n    y_apps_test = clf.predict_proba(X_apps_test)\n    test_res[\"TARGET\"] = y_apps_test[:, 1]\n\n    return df_off_preds, clf, test_res","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_off_preds, clf, test_res = StratifiedKFold_SMOTE_Stacking_GBoosting_model(df=merged_df_train, nfolds=5, random_state=10, drop_columns_arr=['TARGET', 'SK_ID_CURR'], target_col='TARGET', apps_all_test=merged_df_test)\ndf_off_preds.to_csv(\"/kaggle/working/StratifiedKFold_SMOTE_Stacking_GBoosting_train.csv\", index = False)\ntest_res.to_csv(\"/kaggle/working/StratifiedKFold_SMOTE_Stacking_GBoosting_test.csv\", index = False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## XGBoost","metadata":{}},{"cell_type":"markdown","source":"### K-Fold Cross-Validation","metadata":{}},{"cell_type":"code","source":"# No resampling method\ndef KFold_Stacking_XGBoosting_model(df, nfolds, random_state, drop_columns_arr, target_col, apps_all_test):    \n    df_off_preds = pd.DataFrame()\n    df_off_preds['SK_ID_CURR'] = df['SK_ID_CURR']\n\n    ftr_app = df.drop(drop_columns_arr, axis=1)  # feature dateset\n    target_app = df[target_col]                  # target datasets\n    \n    folds = KFold(n_splits = nfolds, shuffle=True, random_state = random_state)\n    \n    clf = XGBClassifier(\n                nthread=5,\n                n_estimators=50000,\n                learning_rate=0.008,\n                max_depth = 15,\n                num_leaves=100,\n                colsample_bytree=0.5,\n                subsample=0.5,\n                max_bin=407,\n                reg_alpha=4,\n                reg_lambda=5,\n                min_child_weight= 6,\n                min_child_samples=165,\n                silent=-1,\n                verbose=-1\n                )\n    \n    print(\"AUC:\")\n    oof_preds_proba = np.zeros(ftr_app.shape[0])\n    \n    for fold_idx, (train_idx , valid_idx) in enumerate(folds.split(ftr_app, target_app)):\n        print(\"#iteration \", fold_idx, 'starts')\n        train_x = ftr_app.iloc[train_idx, :]\n        train_y = target_app.iloc[train_idx]\n        valid_x = ftr_app.iloc[valid_idx, :]\n        valid_y = target_app.iloc[valid_idx]\n        \n        clf.fit(train_x, train_y, eval_set=[(train_x, train_y), (valid_x, valid_y)], eval_metric= 'auc', verbose= 200, early_stopping_rounds= 200)\n        # Save predicted proba labels for validation set\n        oof_preds_proba[valid_idx] = clf.predict_proba(valid_x)[:, 1]\n        \n    # return Target of train set\n    df_off_preds['TARGET'] = oof_preds_proba\n\n    # apps_all_test \n    df_test = apps_all_test.copy()\n    test_res = pd.DataFrame()\n    # save SK_ID_CURR\n    test_res[\"SK_ID_CURR\"]=df_test[\"SK_ID_CURR\"]\n  \n    X_apps_test = df_test.drop(\"SK_ID_CURR\", axis=1)\n\n    y_apps_test = clf.predict_proba(X_apps_test)\n    test_res[\"TARGET\"] = y_apps_test[:, 1]\n\n    return df_off_preds, clf, test_res","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_off_preds, clf, test_res = KFold_Stacking_XGBoosting_model(df=merged_df_train, nfolds=5, random_state=10, drop_columns_arr=['TARGET', 'SK_ID_CURR'], target_col='TARGET', apps_all_test=merged_df_test)\ndf_off_preds.to_csv(\"/kaggle/working/KFold_Stacking_XGBoosting_train.csv\", index = False)\ntest_res.to_csv(\"/kaggle/working/KFold_Stacking_XGBoosting_test.csv\", index = False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Random Over Sampling\ndef KFold_ROS_Stacking_XGBoosting_model(df, nfolds, random_state, drop_columns_arr, target_col, apps_all_test):    \n    df_off_preds = pd.DataFrame()\n    df_off_preds['SK_ID_CURR'] = df['SK_ID_CURR']\n\n    ftr_app = df.drop(drop_columns_arr, axis=1)  # feature dateset\n    target_app = df[target_col]                  # target datasets\n    \n    folds = KFold(n_splits = nfolds, shuffle=True, random_state = random_state)\n    \n    ros = RandomOverSampler()\n    \n    clf = XGBClassifier(\n                nthread=5,\n                n_estimators=50000,\n                learning_rate=0.008,\n                max_depth = 15,\n                num_leaves=100,\n                colsample_bytree=0.5,\n                subsample=0.5,\n                max_bin=407,\n                reg_alpha=4,\n                reg_lambda=5,\n                min_child_weight= 6,\n                min_child_samples=165,\n                silent=-1,\n                verbose=-1\n                )\n    \n    print(\"AUC:\")\n    oof_preds_proba = np.zeros(ftr_app.shape[0])\n    \n    for fold_idx, (train_idx , valid_idx) in enumerate(folds.split(ftr_app, target_app)):\n        print(\"#iteration \", fold_idx, 'starts')\n        train_x = ftr_app.iloc[train_idx, :]\n        train_y = target_app.iloc[train_idx]\n        valid_x = ftr_app.iloc[valid_idx, :]\n        valid_y = target_app.iloc[valid_idx]\n        \n        train_x_resampled, train_y_resampled = ros.fit_resample(train_x, train_y)\n\n        clf.fit(train_x_resampled, train_y_resampled, eval_set=[(train_x_resampled, train_y_resampled), (valid_x, valid_y)], eval_metric= 'auc', verbose= 200, early_stopping_rounds= 200)\n        # Save predicted proba labels for validation set\n        oof_preds_proba[valid_idx] = clf.predict_proba(valid_x)[:, 1]\n        \n    # return Target of train set\n    df_off_preds['TARGET'] = oof_preds_proba\n\n    # apps_all_test \n    df_test = apps_all_test.copy()\n    test_res = pd.DataFrame()\n    # save SK_ID_CURR\n    test_res[\"SK_ID_CURR\"]=df_test[\"SK_ID_CURR\"]\n  \n    X_apps_test = df_test.drop(\"SK_ID_CURR\", axis=1)\n\n    y_apps_test = clf.predict_proba(X_apps_test)\n    test_res[\"TARGET\"] = y_apps_test[:, 1]\n\n    return df_off_preds, clf, test_res","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_off_preds, clf, test_res = KFold_ROS_Stacking_XGBoosting_model(df=merged_df_train, nfolds=5, random_state=10, drop_columns_arr=['TARGET', 'SK_ID_CURR'], target_col='TARGET', apps_all_test=merged_df_test)\ndf_off_preds.to_csv(\"/kaggle/working/KFold_ROS_Stacking_XGBoosting_train.csv\", index = False)\ntest_res.to_csv(\"/kaggle/working/KFold_ROS_Stacking_XGBoosting_test.csv\", index = False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Random Under Sampling\ndef KFold_RUS_Stacking_XGBoosting_model(df, nfolds, random_state, drop_columns_arr, target_col, apps_all_test):    \n    df_off_preds = pd.DataFrame()\n    df_off_preds['SK_ID_CURR'] = df['SK_ID_CURR']\n\n    ftr_app = df.drop(drop_columns_arr, axis=1)  # feature dateset\n    target_app = df[target_col]                  # target datasets\n    \n    folds = KFold(n_splits = nfolds, shuffle=True, random_state = random_state)\n    \n    rus = RandomUnderSampler()\n    \n    clf = XGBClassifier(\n                nthread=5,\n                n_estimators=50000,\n                learning_rate=0.008,\n                max_depth = 15,\n                num_leaves=100,\n                colsample_bytree=0.5,\n                subsample=0.5,\n                max_bin=407,\n                reg_alpha=4,\n                reg_lambda=5,\n                min_child_weight= 6,\n                min_child_samples=165,\n                silent=-1,\n                verbose=-1\n                )\n    \n    print(\"AUC:\")\n    oof_preds_proba = np.zeros(ftr_app.shape[0])\n    \n    for fold_idx, (train_idx , valid_idx) in enumerate(folds.split(ftr_app, target_app)):\n        print(\"#iteration \", fold_idx, 'starts')\n        train_x = ftr_app.iloc[train_idx, :]\n        train_y = target_app.iloc[train_idx]\n        valid_x = ftr_app.iloc[valid_idx, :]\n        valid_y = target_app.iloc[valid_idx]\n        \n        train_x_resampled, train_y_resampled = rus.fit_resample(train_x, train_y)\n\n        clf.fit(train_x_resampled, train_y_resampled, eval_set=[(train_x_resampled, train_y_resampled), (valid_x, valid_y)], eval_metric= 'auc', verbose= 200, early_stopping_rounds= 200)\n        # Save predicted proba labels for validation set\n        oof_preds_proba[valid_idx] = clf.predict_proba(valid_x)[:, 1]\n        \n    # return Target of train set\n    df_off_preds['TARGET'] = oof_preds_proba\n\n    # apps_all_test \n    df_test = apps_all_test.copy()\n    test_res = pd.DataFrame()\n    # save SK_ID_CURR\n    test_res[\"SK_ID_CURR\"]=df_test[\"SK_ID_CURR\"]\n  \n    X_apps_test = df_test.drop(\"SK_ID_CURR\", axis=1)\n\n    y_apps_test = clf.predict_proba(X_apps_test)\n    test_res[\"TARGET\"] = y_apps_test[:, 1]\n\n    return df_off_preds, clf, test_res","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_off_preds, clf, test_res = KFold_RUS_Stacking_XGBoosting_model(df=merged_df_train, nfolds=5, random_state=10, drop_columns_arr=['TARGET', 'SK_ID_CURR'], target_col='TARGET', apps_all_test=merged_df_test)\ndf_off_preds.to_csv(\"/kaggle/working/KFold_RUS_Stacking_XGBoosting_train.csv\", index = False)\ntest_res.to_csv(\"/kaggle/working/KFold_RUS_Stacking_XGBoosting_test.csv\", index = False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# SMOTE\ndef KFold_SMOTE_Stacking_XGBoosting_model(df, nfolds, random_state, drop_columns_arr, target_col, apps_all_test):    \n    df_off_preds = pd.DataFrame()\n    df_off_preds['SK_ID_CURR'] = df['SK_ID_CURR']\n\n    ftr_app = df.drop(drop_columns_arr, axis=1)  # feature dateset\n    target_app = df[target_col]                  # target datasets\n    \n    folds = KFold(n_splits = nfolds, shuffle=True, random_state = random_state)\n    \n    smote = SMOTE()\n    \n    clf = XGBClassifier(\n                nthread=5,\n                n_estimators=50000,\n                learning_rate=0.008,\n                max_depth = 15,\n                num_leaves=100,\n                colsample_bytree=0.5,\n                subsample=0.5,\n                max_bin=407,\n                reg_alpha=4,\n                reg_lambda=5,\n                min_child_weight= 6,\n                min_child_samples=165,\n                silent=-1,\n                verbose=-1\n                )\n    \n    print(\"AUC:\")\n    oof_preds_proba = np.zeros(ftr_app.shape[0])\n    \n    for fold_idx, (train_idx , valid_idx) in enumerate(folds.split(ftr_app, target_app)):\n        print(\"#iteration \", fold_idx, 'starts')\n        train_x = ftr_app.iloc[train_idx, :]\n        train_y = target_app.iloc[train_idx]\n        valid_x = ftr_app.iloc[valid_idx, :]\n        valid_y = target_app.iloc[valid_idx]\n        \n        train_x_resampled, train_y_resampled = smote.fit_resample(train_x, train_y)\n\n        clf.fit(train_x_resampled, train_y_resampled, eval_set=[(train_x_resampled, train_y_resampled), (valid_x, valid_y)], eval_metric= 'auc', verbose= 200, early_stopping_rounds= 200)\n        # Save predicted proba labels for validation set\n        oof_preds_proba[valid_idx] = clf.predict_proba(valid_x)[:, 1]\n        \n    # return Target of train set\n    df_off_preds['TARGET'] = oof_preds_proba\n\n    # apps_all_test \n    df_test = apps_all_test.copy()\n    test_res = pd.DataFrame()\n    # save SK_ID_CURR\n    test_res[\"SK_ID_CURR\"]=df_test[\"SK_ID_CURR\"]\n  \n    X_apps_test = df_test.drop(\"SK_ID_CURR\", axis=1)\n\n    y_apps_test = clf.predict_proba(X_apps_test)\n    test_res[\"TARGET\"] = y_apps_test[:, 1]\n\n    return df_off_preds, clf, test_res","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_off_preds, clf, test_res = KFold_SMOTE_Stacking_XGBoosting_model(df=merged_df_train, nfolds=5, random_state=10, drop_columns_arr=['TARGET', 'SK_ID_CURR'], target_col='TARGET', apps_all_test=merged_df_test)\ndf_off_preds.to_csv(\"/kaggle/working/KFold_SMOTE_Stacking_XGBoosting_train.csv\", index = False)\ntest_res.to_csv(\"/kaggle/working/KFold_SMOTE_Stacking_XGBoosting_test.csv\", index = False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Stratified K-Fold Cross-Validation","metadata":{}},{"cell_type":"code","source":"# No resampling method\ndef StratifiedKFold_Stacking_XGBoosting_model(df, nfolds, random_state, drop_columns_arr, target_col, apps_all_test):    \n    df_off_preds = pd.DataFrame()\n    df_off_preds['SK_ID_CURR'] = df['SK_ID_CURR']\n\n    ftr_app = df.drop(drop_columns_arr, axis=1)  # feature dateset\n    target_app = df[target_col]                  # target datasets\n    \n    folds = StratifiedKFold(n_splits = nfolds, shuffle=True, random_state = random_state)\n    \n    clf = XGBClassifier(\n                nthread=5,\n                n_estimators=50000,\n                learning_rate=0.008,\n                max_depth = 15,\n                num_leaves=100,\n                colsample_bytree=0.5,\n                subsample=0.5,\n                max_bin=407,\n                reg_alpha=4,\n                reg_lambda=5,\n                min_child_weight= 6,\n                min_child_samples=165,\n                silent=-1,\n                verbose=-1\n                )\n    \n    print(\"AUC:\")\n    oof_preds_proba = np.zeros(ftr_app.shape[0])\n    \n    for fold_idx, (train_idx , valid_idx) in enumerate(folds.split(ftr_app, target_app)):\n        print(\"#iteration \", fold_idx, 'starts')\n        train_x = ftr_app.iloc[train_idx, :]\n        train_y = target_app.iloc[train_idx]\n        valid_x = ftr_app.iloc[valid_idx, :]\n        valid_y = target_app.iloc[valid_idx]\n        \n        clf.fit(train_x, train_y, eval_set=[(train_x, train_y), (valid_x, valid_y)], eval_metric= 'auc', verbose= 200, early_stopping_rounds= 200)\n        # Save predicted proba labels for validation set\n        oof_preds_proba[valid_idx] = clf.predict_proba(valid_x)[:, 1]\n        \n    # return Target of train set\n    df_off_preds['TARGET'] = oof_preds_proba\n\n    # apps_all_test \n    df_test = apps_all_test.copy()\n    test_res = pd.DataFrame()\n    # save SK_ID_CURR\n    test_res[\"SK_ID_CURR\"]=df_test[\"SK_ID_CURR\"]\n  \n    X_apps_test = df_test.drop(\"SK_ID_CURR\", axis=1)\n\n    y_apps_test = clf.predict_proba(X_apps_test)\n    test_res[\"TARGET\"] = y_apps_test[:, 1]\n\n    return df_off_preds, clf, test_res","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_off_preds, clf, test_res = StratifiedKFold_Stacking_XGBoosting_model(df=merged_df_train, nfolds=5, random_state=10, drop_columns_arr=['TARGET', 'SK_ID_CURR'], target_col='TARGET', apps_all_test=merged_df_test)\ndf_off_preds.to_csv(\"/kaggle/working/StratifiedKFold_Stacking_XGBoosting_train.csv\", index = False)\ntest_res.to_csv(\"/kaggle/working/StratifiedKFold_Stacking_XGBoosting_test.csv\", index = False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Random Over Sampling\ndef StratifiedKFold_ROS_Stacking_XGBoosting_model(df, nfolds, random_state, drop_columns_arr, target_col, apps_all_test):    \n    df_off_preds = pd.DataFrame()\n    df_off_preds['SK_ID_CURR'] = df['SK_ID_CURR']\n\n    ftr_app = df.drop(drop_columns_arr, axis=1)  # feature dateset\n    target_app = df[target_col]                  # target datasets\n    \n    folds = StratifiedKFold(n_splits = nfolds, shuffle=True, random_state = random_state)\n    \n    ros = RandomOverSampler()\n    \n    clf = XGBClassifier(\n                nthread=5,\n                n_estimators=50000,\n                learning_rate=0.008,\n                max_depth = 15,\n                num_leaves=100,\n                colsample_bytree=0.5,\n                subsample=0.5,\n                max_bin=407,\n                reg_alpha=4,\n                reg_lambda=5,\n                min_child_weight= 6,\n                min_child_samples=165,\n                silent=-1,\n                verbose=-1\n                )\n    \n    print(\"AUC:\")\n    oof_preds_proba = np.zeros(ftr_app.shape[0])\n    \n    for fold_idx, (train_idx , valid_idx) in enumerate(folds.split(ftr_app, target_app)):\n        print(\"#iteration \", fold_idx, 'starts')\n        train_x = ftr_app.iloc[train_idx, :]\n        train_y = target_app.iloc[train_idx]\n        valid_x = ftr_app.iloc[valid_idx, :]\n        valid_y = target_app.iloc[valid_idx]\n        \n        train_x_resampled, train_y_resampled = ros.fit_resample(train_x, train_y)\n\n        clf.fit(train_x_resampled, train_y_resampled, eval_set=[(train_x_resampled, train_y_resampled), (valid_x, valid_y)], eval_metric= 'auc', verbose= 200, early_stopping_rounds= 200)\n        # Save predicted proba labels for validation set\n        oof_preds_proba[valid_idx] = clf.predict_proba(valid_x)[:, 1]\n        \n    # return Target of train set\n    df_off_preds['TARGET'] = oof_preds_proba\n\n    # apps_all_test \n    df_test = apps_all_test.copy()\n    test_res = pd.DataFrame()\n    # save SK_ID_CURR\n    test_res[\"SK_ID_CURR\"]=df_test[\"SK_ID_CURR\"]\n  \n    X_apps_test = df_test.drop(\"SK_ID_CURR\", axis=1)\n\n    y_apps_test = clf.predict_proba(X_apps_test)\n    test_res[\"TARGET\"] = y_apps_test[:, 1]\n\n    return df_off_preds, clf, test_res","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_off_preds, clf, test_res = StratifiedKFold_ROS_Stacking_XGBoosting_model(df=merged_df_train, nfolds=5, random_state=10, drop_columns_arr=['TARGET', 'SK_ID_CURR'], target_col='TARGET', apps_all_test=merged_df_test)\ndf_off_preds.to_csv(\"/kaggle/working/StratifiedKFold_ROS_Stacking_XGBoosting_train.csv\", index = False)\ntest_res.to_csv(\"/kaggle/working/StratifiedKFold_ROS_Stacking_XGBoosting_test.csv\", index = False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Random Under Sampling\ndef StratifiedKFold_RUS_Stacking_XGBoosting_model(df, nfolds, random_state, drop_columns_arr, target_col, apps_all_test):    \n    df_off_preds = pd.DataFrame()\n    df_off_preds['SK_ID_CURR'] = df['SK_ID_CURR']\n\n    ftr_app = df.drop(drop_columns_arr, axis=1)  # feature dateset\n    target_app = df[target_col]                  # target datasets\n    \n    folds = StratifiedKFold(n_splits = nfolds, shuffle=True, random_state = random_state)\n    \n    rus = RandomUnderSampler()\n    \n    clf = XGBClassifier(\n                nthread=5,\n                n_estimators=50000,\n                learning_rate=0.008,\n                max_depth = 15,\n                num_leaves=100,\n                colsample_bytree=0.5,\n                subsample=0.5,\n                max_bin=407,\n                reg_alpha=4,\n                reg_lambda=5,\n                min_child_weight= 6,\n                min_child_samples=165,\n                silent=-1,\n                verbose=-1\n                )\n    \n    print(\"AUC:\")\n    oof_preds_proba = np.zeros(ftr_app.shape[0])\n    \n    for fold_idx, (train_idx , valid_idx) in enumerate(folds.split(ftr_app, target_app)):\n        print(\"#iteration \", fold_idx, 'starts')\n        train_x = ftr_app.iloc[train_idx, :]\n        train_y = target_app.iloc[train_idx]\n        valid_x = ftr_app.iloc[valid_idx, :]\n        valid_y = target_app.iloc[valid_idx]\n        \n        train_x_resampled, train_y_resampled = rus.fit_resample(train_x, train_y)\n\n        clf.fit(train_x_resampled, train_y_resampled, eval_set=[(train_x_resampled, train_y_resampled), (valid_x, valid_y)], eval_metric= 'auc', verbose= 200, early_stopping_rounds= 200)\n        # Save predicted proba labels for validation set\n        oof_preds_proba[valid_idx] = clf.predict_proba(valid_x)[:, 1]\n        \n    # return Target of train set\n    df_off_preds['TARGET'] = oof_preds_proba\n\n    # apps_all_test \n    df_test = apps_all_test.copy()\n    test_res = pd.DataFrame()\n    # save SK_ID_CURR\n    test_res[\"SK_ID_CURR\"]=df_test[\"SK_ID_CURR\"]\n  \n    X_apps_test = df_test.drop(\"SK_ID_CURR\", axis=1)\n\n    y_apps_test = clf.predict_proba(X_apps_test)\n    test_res[\"TARGET\"] = y_apps_test[:, 1]\n\n    return df_off_preds, clf, test_res","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_off_preds, clf, test_res = StratifiedKFold_RUS_Stacking_XGBoosting_model(df=merged_df_train, nfolds=5, random_state=10, drop_columns_arr=['TARGET', 'SK_ID_CURR'], target_col='TARGET', apps_all_test=merged_df_test)\ndf_off_preds.to_csv(\"/kaggle/working/StratifiedKFold_RUS_Stacking_XGBoosting_train.csv\", index = False)\ntest_res.to_csv(\"/kaggle/working/StratifiedKFold_RUS_Stacking_XGBoosting_test.csv\", index = False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# SMOTE\ndef StratifiedKFold_SMOTE_Stacking_XGBoosting_model(df, nfolds, random_state, drop_columns_arr, target_col, apps_all_test):    \n    df_off_preds = pd.DataFrame()\n    df_off_preds['SK_ID_CURR'] = df['SK_ID_CURR']\n\n    ftr_app = df.drop(drop_columns_arr, axis=1)  # feature dateset\n    target_app = df[target_col]                  # target datasets\n    \n    folds = StratifiedKFold(n_splits = nfolds, shuffle=True, random_state = random_state)\n    \n    smote = SMOTE()\n    \n    clf = XGBClassifier(\n                nthread=5,\n                n_estimators=50000,\n                learning_rate=0.008,\n                max_depth = 15,\n                num_leaves=100,\n                colsample_bytree=0.5,\n                subsample=0.5,\n                max_bin=407,\n                reg_alpha=4,\n                reg_lambda=5,\n                min_child_weight= 6,\n                min_child_samples=165,\n                silent=-1,\n                verbose=-1\n                )\n    \n    print(\"AUC:\")\n    oof_preds_proba = np.zeros(ftr_app.shape[0])\n    \n    for fold_idx, (train_idx , valid_idx) in enumerate(folds.split(ftr_app, target_app)):\n        print(\"#iteration \", fold_idx, 'starts')\n        train_x = ftr_app.iloc[train_idx, :]\n        train_y = target_app.iloc[train_idx]\n        valid_x = ftr_app.iloc[valid_idx, :]\n        valid_y = target_app.iloc[valid_idx]\n        \n        train_x_resampled, train_y_resampled = smote.fit_resample(train_x, train_y)\n\n        clf.fit(train_x_resampled, train_y_resampled, eval_set=[(train_x_resampled, train_y_resampled), (valid_x, valid_y)], eval_metric= 'auc', verbose= 200, early_stopping_rounds= 200)\n        # Save predicted proba labels for validation set\n        oof_preds_proba[valid_idx] = clf.predict_proba(valid_x)[:, 1]\n        \n    # return Target of train set\n    df_off_preds['TARGET'] = oof_preds_proba\n\n    # apps_all_test \n    df_test = apps_all_test.copy()\n    test_res = pd.DataFrame()\n    # save SK_ID_CURR\n    test_res[\"SK_ID_CURR\"]=df_test[\"SK_ID_CURR\"]\n  \n    X_apps_test = df_test.drop(\"SK_ID_CURR\", axis=1)\n\n    y_apps_test = clf.predict_proba(X_apps_test)\n    test_res[\"TARGET\"] = y_apps_test[:, 1]\n\n    return df_off_preds, clf, test_res","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_off_preds, clf, test_res = StratifiedKFold_SMOTE_Stacking_XGBoosting_model(df=merged_df_train, nfolds=5, random_state=10, drop_columns_arr=['TARGET', 'SK_ID_CURR'], target_col='TARGET', apps_all_test=merged_df_test)\ndf_off_preds.to_csv(\"/kaggle/working/StratifiedKFold_SMOTE_Stacking_XGBoosting_train.csv\", index = False)\ntest_res.to_csv(\"/kaggle/working/StratifiedKFold_SMOTE_Stacking_XGBoosting_test.csv\", index = False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Light GBM","metadata":{}},{"cell_type":"markdown","source":"### K-Fold Cross-Validation","metadata":{}},{"cell_type":"code","source":"# No resampling method\ndef KFold_Stacking_LightGBMC_model(df, nfolds, random_state, drop_columns_arr, target_col, apps_all_test):\n    df_off_preds = pd.DataFrame()\n    df_off_preds['SK_ID_CURR'] = df['SK_ID_CURR']\n\n    ftr_app = df.drop(drop_columns_arr, axis=1)  # feature dateset\n    target_app = df[target_col]                  # target datasets\n    \n    folds = KFold(n_splits = nfolds, shuffle=True, random_state = random_state)\n    \n    oof_preds = np.zeros(ftr_app.shape[0])\n    \n    clf = LGBMClassifier(\n                nthread=5,\n                n_estimators=50000,\n                learning_rate=0.008,\n                max_depth=12,\n                num_leaves=58,\n                colsample_bytree=0.613,\n                subsample=0.8,\n                max_bin=410,\n                reg_alpha=3.564,\n                reg_lambda=4.930,\n                min_child_weight= 6,\n                min_child_samples=165,\n                silent=-1,\n                verbose=-1,\n                )\n    \n    for fold_idx, (train_idx , valid_idx) in enumerate(folds.split(ftr_app, target_app)):\n        print(\"# iteration\", fold_idx, 'starts')\n        train_x = ftr_app.iloc[train_idx, :]\n        train_y = target_app.iloc[train_idx]\n        valid_x = ftr_app.iloc[valid_idx, :]\n        valid_y = target_app.iloc[valid_idx]\n\n        clf.fit(train_x, train_y, eval_set=[(train_x, train_y), (valid_x, valid_y)], eval_metric= 'auc', verbose= 200, early_stopping_rounds= 200)\n        \n        oof_preds[valid_idx] = clf.predict_proba(valid_x, num_iteration = clf.best_iteration_)[:, 1]\n\n    df_off_preds['TARGET'] = oof_preds\n\n    # test set\n    df_test = apps_all_test.copy() \n    test_res = pd.DataFrame()\n    # save SK_ID_CURR\n    test_res[\"SK_ID_CURR\"]=df_test[\"SK_ID_CURR\"]\n    X_apps_test = df_test.drop(\"SK_ID_CURR\", axis=1)\n\n    y_apps_test = clf.predict_proba(X_apps_test)\n    test_res[f\"TARGET\"] = y_apps_test[:, 1]\n    return df_off_preds, clf, test_res","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_off_preds, clf, test_res = KFold_Stacking_LightGBMC_model(df=merged_df_train, nfolds=5, random_state=10, drop_columns_arr=['TARGET', 'SK_ID_CURR'], target_col='TARGET', apps_all_test=merged_df_test)\ndf_off_preds.to_csv(\"/kaggle/working/KFold_Stacking_LightGBMC_train.csv\", index = False)\ntest_res.to_csv(\"/kaggle/working/KFold_Stacking_LightGBMC_test.csv\", index = False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Random Over Sampling\ndef KFold_ROS_Stacking_LightGBMC_model(df, nfolds, random_state, drop_columns_arr, target_col, apps_all_test):\n    df_off_preds = pd.DataFrame()\n    df_off_preds['SK_ID_CURR'] = df['SK_ID_CURR']\n\n    ftr_app = df.drop(drop_columns_arr, axis=1)  # feature dateset\n    target_app = df[target_col]                  # target datasets\n    \n    folds = KFold(n_splits = nfolds, shuffle=True, random_state = random_state)\n    \n    oof_preds = np.zeros(ftr_app.shape[0])\n    \n    clf = LGBMClassifier(\n                nthread=5,\n                n_estimators=50000,\n                learning_rate=0.008,\n                max_depth=12,\n                num_leaves=58,\n                colsample_bytree=0.613,\n                subsample=0.8,\n                max_bin=410,\n                reg_alpha=3.564,\n                reg_lambda=4.930,\n                min_child_weight= 6,\n                min_child_samples=165,\n                silent=-1,\n                verbose=-1,\n                )\n    \n    # Apply ROS to the training set\n    ros = RandomOverSampler(random_state=42)\n    \n    for fold_idx, (train_idx , valid_idx) in enumerate(folds.split(ftr_app, target_app)):\n        print(\"# iteration\", fold_idx, 'starts')\n        train_x = ftr_app.iloc[train_idx, :]\n        train_y = target_app.iloc[train_idx]\n        valid_x = ftr_app.iloc[valid_idx, :]\n        valid_y = target_app.iloc[valid_idx]\n\n        train_x_resampled, train_y_resampled = ros.fit_resample(train_x, train_y)\n\n        clf.fit(train_x_resampled, train_y_resampled, eval_set=[(train_x_resampled, train_y_resampled), (valid_x, valid_y)], eval_metric= 'auc', verbose= 200, early_stopping_rounds= 200)\n        \n        oof_preds[valid_idx] = clf.predict_proba(valid_x, num_iteration = clf.best_iteration_)[:, 1]\n\n    df_off_preds['TARGET'] = oof_preds\n\n    # test set\n    df_test = apps_all_test.copy() \n    test_res = pd.DataFrame()\n    # save SK_ID_CURR\n    test_res[\"SK_ID_CURR\"]=df_test[\"SK_ID_CURR\"]\n    X_apps_test = df_test.drop(\"SK_ID_CURR\", axis=1)\n\n    y_apps_test = clf.predict_proba(X_apps_test)\n    test_res[f\"TARGET\"] = y_apps_test[:, 1]\n    return df_off_preds, clf, test_res","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_off_preds, clf, test_res = KFold_ROS_Stacking_LightGBMC_model(df=merged_df_train, nfolds=5, random_state=10, drop_columns_arr=['TARGET', 'SK_ID_CURR'], target_col='TARGET', apps_all_test=merged_df_test)\ndf_off_preds.to_csv(\"/kaggle/working/KFold_ROS_Stacking_LightGBMC_train.csv\", index = False)\ntest_res.to_csv(\"/kaggle/working/KFold_ROS_Stacking_LightGBMC_test.csv\", index = False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Random Under Sampling\ndef KFold_RUS_Stacking_LightGBMC_model(df, nfolds, random_state, drop_columns_arr, target_col, apps_all_test):\n    df_off_preds = pd.DataFrame()\n    df_off_preds['SK_ID_CURR'] = df['SK_ID_CURR']\n\n    ftr_app = df.drop(drop_columns_arr, axis=1)  # feature dateset\n    target_app = df[target_col]                  # target datasets\n    \n    folds = KFold(n_splits = nfolds, shuffle=True, random_state = random_state)\n    \n    oof_preds = np.zeros(ftr_app.shape[0])\n    \n    clf = LGBMClassifier(\n                nthread=5,\n                n_estimators=50000,\n                learning_rate=0.008,\n                max_depth=12,\n                num_leaves=58,\n                colsample_bytree=0.613,\n                subsample=0.8,\n                max_bin=410,\n                reg_alpha=3.564,\n                reg_lambda=4.930,\n                min_child_weight= 6,\n                min_child_samples=165,\n                silent=-1,\n                verbose=-1,\n                )\n    \n    # Apply RUS to the training set\n    rus = RandomUnderSampler(random_state=42)\n    \n    for fold_idx, (train_idx , valid_idx) in enumerate(folds.split(ftr_app, target_app)):\n        print(\"# iteration\", fold_idx, 'starts')\n        train_x = ftr_app.iloc[train_idx, :]\n        train_y = target_app.iloc[train_idx]\n        valid_x = ftr_app.iloc[valid_idx, :]\n        valid_y = target_app.iloc[valid_idx]\n\n        train_x_resampled, train_y_resampled = rus.fit_resample(train_x, train_y)\n\n        clf.fit(train_x_resampled, train_y_resampled, eval_set=[(train_x_resampled, train_y_resampled), (valid_x, valid_y)], eval_metric= 'auc', verbose= 200, early_stopping_rounds= 200)\n        \n        oof_preds[valid_idx] = clf.predict_proba(valid_x, num_iteration = clf.best_iteration_)[:, 1]\n\n    df_off_preds['TARGET'] = oof_preds\n\n    # test set\n    df_test = apps_all_test.copy() \n    test_res = pd.DataFrame()\n    # save SK_ID_CURR\n    test_res[\"SK_ID_CURR\"]=df_test[\"SK_ID_CURR\"]\n    X_apps_test = df_test.drop(\"SK_ID_CURR\", axis=1)\n\n    y_apps_test = clf.predict_proba(X_apps_test)\n    test_res[f\"TARGET\"] = y_apps_test[:, 1]\n    return df_off_preds, clf, test_res","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_off_preds, clf, test_res = KFold_RUS_Stacking_LightGBMC_model(df=merged_df_train, nfolds=5, random_state=10, drop_columns_arr=['TARGET', 'SK_ID_CURR'], target_col='TARGET', apps_all_test=merged_df_test)\ndf_off_preds.to_csv(\"/kaggle/working/KFold_RUS_Stacking_LightGBMC_train.csv\", index = False)\ntest_res.to_csv(\"/kaggle/working/KFold_RUS_Stacking_LightGBMC_test.csv\", index = False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# SMOTE\ndef KFold_SMOTE_Stacking_LightGBMC_model(df, nfolds, random_state, drop_columns_arr, target_col, apps_all_test):\n    df_off_preds = pd.DataFrame()\n    df_off_preds['SK_ID_CURR'] = df['SK_ID_CURR']\n\n    ftr_app = df.drop(drop_columns_arr, axis=1)  # feature dateset\n    target_app = df[target_col]                  # target datasets\n    \n    folds = KFold(n_splits = nfolds, shuffle=True, random_state = random_state)\n    \n    oof_preds = np.zeros(ftr_app.shape[0])\n    \n    clf = LGBMClassifier(\n                nthread=5,\n                n_estimators=50000,\n                learning_rate=0.008,\n                max_depth=12,\n                num_leaves=58,\n                colsample_bytree=0.613,\n                subsample=0.8,\n                max_bin=410,\n                reg_alpha=3.564,\n                reg_lambda=4.930,\n                min_child_weight= 6,\n                min_child_samples=165,\n                silent=-1,\n                verbose=-1,\n                )\n    \n    # Apply SMOTE to the training set\n    smote = SMOTE()\n    \n    for fold_idx, (train_idx , valid_idx) in enumerate(folds.split(ftr_app, target_app)):\n        print(\"# iteration\", fold_idx, 'starts')\n        train_x = ftr_app.iloc[train_idx, :]\n        train_y = target_app.iloc[train_idx]\n        valid_x = ftr_app.iloc[valid_idx, :]\n        valid_y = target_app.iloc[valid_idx]\n\n        train_x_resampled, train_y_resampled = smote.fit_resample(train_x, train_y)\n\n        clf.fit(train_x_resampled, train_y_resampled, eval_set=[(train_x_resampled, train_y_resampled), (valid_x, valid_y)], eval_metric= 'auc', verbose= 200, early_stopping_rounds= 200)\n        \n        oof_preds[valid_idx] = clf.predict_proba(valid_x, num_iteration = clf.best_iteration_)[:, 1]\n\n    df_off_preds['TARGET'] = oof_preds\n\n    # test set\n    df_test = apps_all_test.copy() \n    test_res = pd.DataFrame()\n    # save SK_ID_CURR\n    test_res[\"SK_ID_CURR\"]=df_test[\"SK_ID_CURR\"]\n    X_apps_test = df_test.drop(\"SK_ID_CURR\", axis=1)\n\n    y_apps_test = clf.predict_proba(X_apps_test)\n    test_res[f\"TARGET\"] = y_apps_test[:, 1]\n    return df_off_preds, clf, test_res","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_off_preds, clf, test_res = KFold_SMOTE_Stacking_LightGBMC_model(df=merged_df_train, nfolds=5, random_state=10, drop_columns_arr=['TARGET', 'SK_ID_CURR'], target_col='TARGET', apps_all_test=merged_df_test)\ndf_off_preds.to_csv(\"/kaggle/working/KFold_SMOTE_Stacking_LightGBMC_train.csv\", index = False)\ntest_res.to_csv(\"/kaggle/working/KFold_SMOTE_Stacking_LightGBMC_test.csv\", index = False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Stratified K-Fold Cross-Validation","metadata":{}},{"cell_type":"code","source":"# No resampling method\ndef StratifiedKFold_Stacking_LightGBMC_model(df, nfolds, random_state, drop_columns_arr, target_col, apps_all_test):\n    df_off_preds = pd.DataFrame()\n    df_off_preds['SK_ID_CURR'] = df['SK_ID_CURR']\n\n    ftr_app = df.drop(drop_columns_arr, axis=1)  # feature dateset\n    target_app = df[target_col]                  # target datasets\n    \n    folds = StratifiedKFold(n_splits = nfolds, shuffle=True, random_state = random_state)\n    \n    oof_preds = np.zeros(ftr_app.shape[0])\n    \n    clf = LGBMClassifier(\n                nthread=5,\n                n_estimators=50000,\n                learning_rate=0.008,\n                max_depth=12,\n                num_leaves=58,\n                colsample_bytree=0.613,\n                subsample=0.8,\n                max_bin=410,\n                reg_alpha=3.564,\n                reg_lambda=4.930,\n                min_child_weight= 6,\n                min_child_samples=165,\n                silent=-1,\n                verbose=-1,\n                )\n    \n    for fold_idx, (train_idx , valid_idx) in enumerate(folds.split(ftr_app, target_app)):\n        print(\"# iteration\", fold_idx, 'starts')\n        train_x = ftr_app.iloc[train_idx, :]\n        train_y = target_app.iloc[train_idx]\n        valid_x = ftr_app.iloc[valid_idx, :]\n        valid_y = target_app.iloc[valid_idx]\n\n        clf.fit(train_x, train_y, eval_set=[(train_x, train_y), (valid_x, valid_y)], eval_metric= 'auc', verbose= 200, early_stopping_rounds= 200)\n        \n        oof_preds[valid_idx] = clf.predict_proba(valid_x, num_iteration = clf.best_iteration_)[:, 1]\n\n    df_off_preds['TARGET'] = oof_preds\n\n    # test set\n    df_test = apps_all_test.copy() \n    test_res = pd.DataFrame()\n    # save SK_ID_CURR\n    test_res[\"SK_ID_CURR\"]=df_test[\"SK_ID_CURR\"]\n    X_apps_test = df_test.drop(\"SK_ID_CURR\", axis=1)\n\n    y_apps_test = clf.predict_proba(X_apps_test)\n    test_res[f\"TARGET\"] = y_apps_test[:, 1]\n    return df_off_preds, clf, test_res","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_off_preds, clf, test_res = StratifiedKFold_Stacking_LightGBMC_model(df=merged_df_train, nfolds=5, random_state=10, drop_columns_arr=['TARGET', 'SK_ID_CURR'], target_col='TARGET', apps_all_test=merged_df_test)\ndf_off_preds.to_csv(\"/kaggle/working/StratifiedKFold_Stacking_LightGBMC_train.csv\", index = False)\ntest_res.to_csv(\"/kaggle/working/StratifiedKFold_Stacking_LightGBMC_test.csv\", index = False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Random Over Sampling\ndef StratifiedKFold_ROS_Stacking_LightGBMC_model(df, nfolds, random_state, drop_columns_arr, target_col, apps_all_test):\n    df_off_preds = pd.DataFrame()\n    df_off_preds['SK_ID_CURR'] = df['SK_ID_CURR']\n\n    ftr_app = df.drop(drop_columns_arr, axis=1)  # feature dateset\n    target_app = df[target_col]                  # target datasets\n    \n    folds = StratifiedKFold(n_splits = nfolds, shuffle=True, random_state = random_state)\n    \n    oof_preds = np.zeros(ftr_app.shape[0])\n    \n    clf = LGBMClassifier(\n                nthread=5,\n                n_estimators=50000,\n                learning_rate=0.008,\n                max_depth=12,\n                num_leaves=58,\n                colsample_bytree=0.613,\n                subsample=0.8,\n                max_bin=410,\n                reg_alpha=3.564,\n                reg_lambda=4.930,\n                min_child_weight= 6,\n                min_child_samples=165,\n                silent=-1,\n                verbose=-1,\n                )\n    \n    # Apply ROS to the training set\n    ros = RandomOverSampler(random_state=42)\n    \n    for fold_idx, (train_idx , valid_idx) in enumerate(folds.split(ftr_app, target_app)):\n        print(\"# iteration\", fold_idx, 'starts')\n        train_x = ftr_app.iloc[train_idx, :]\n        train_y = target_app.iloc[train_idx]\n        valid_x = ftr_app.iloc[valid_idx, :]\n        valid_y = target_app.iloc[valid_idx]\n\n        train_x_resampled, train_y_resampled = ros.fit_resample(train_x, train_y)\n\n        clf.fit(train_x_resampled, train_y_resampled, eval_set=[(train_x_resampled, train_y_resampled), (valid_x, valid_y)], eval_metric= 'auc', verbose= 200, early_stopping_rounds= 200)\n        \n        oof_preds[valid_idx] = clf.predict_proba(valid_x, num_iteration = clf.best_iteration_)[:, 1]\n\n    df_off_preds['TARGET'] = oof_preds\n\n    # test set\n    df_test = apps_all_test.copy() \n    test_res = pd.DataFrame()\n    # save SK_ID_CURR\n    test_res[\"SK_ID_CURR\"]=df_test[\"SK_ID_CURR\"]\n    X_apps_test = df_test.drop(\"SK_ID_CURR\", axis=1)\n\n    y_apps_test = clf.predict_proba(X_apps_test)\n    test_res[f\"TARGET\"] = y_apps_test[:, 1]\n    return df_off_preds, clf, test_res","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_off_preds, clf, test_res = StratifiedKFold_ROS_Stacking_LightGBMC_model(df=merged_df_train, nfolds=5, random_state=10, drop_columns_arr=['TARGET', 'SK_ID_CURR'], target_col='TARGET', apps_all_test=merged_df_test)\ndf_off_preds.to_csv(\"/kaggle/working/StratifiedKFold_ROS_Stacking_LightGBMC_train.csv\", index = False)\ntest_res.to_csv(\"/kaggle/working/StratifiedKFold_ROS_Stacking_LightGBMC_test.csv\", index = False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Random Under Sampling\ndef StratifiedKFold_RUS_Stacking_LightGBMC_model(df, nfolds, random_state, drop_columns_arr, target_col, apps_all_test):\n    df_off_preds = pd.DataFrame()\n    df_off_preds['SK_ID_CURR'] = df['SK_ID_CURR']\n\n    ftr_app = df.drop(drop_columns_arr, axis=1)  # feature dateset\n    target_app = df[target_col]                  # target datasets\n    \n    folds = StratifiedKFold(n_splits = nfolds, shuffle=True, random_state = random_state)\n    \n    oof_preds = np.zeros(ftr_app.shape[0])\n    \n    clf = LGBMClassifier(\n                nthread=5,\n                n_estimators=50000,\n                learning_rate=0.008,\n                max_depth=12,\n                num_leaves=58,\n                colsample_bytree=0.613,\n                subsample=0.8,\n                max_bin=410,\n                reg_alpha=3.564,\n                reg_lambda=4.930,\n                min_child_weight= 6,\n                min_child_samples=165,\n                silent=-1,\n                verbose=-1,\n                )\n    \n    # Apply RUS to the training set\n    rus = RandomUnderSampler(random_state=42)\n    \n    for fold_idx, (train_idx , valid_idx) in enumerate(folds.split(ftr_app, target_app)):\n        print(\"# iteration\", fold_idx, 'starts')\n        train_x = ftr_app.iloc[train_idx, :]\n        train_y = target_app.iloc[train_idx]\n        valid_x = ftr_app.iloc[valid_idx, :]\n        valid_y = target_app.iloc[valid_idx]\n\n        train_x_resampled, train_y_resampled = rus.fit_resample(train_x, train_y)\n\n        clf.fit(train_x_resampled, train_y_resampled, eval_set=[(train_x_resampled, train_y_resampled), (valid_x, valid_y)], eval_metric= 'auc', verbose= 200, early_stopping_rounds= 200)\n        \n        oof_preds[valid_idx] = clf.predict_proba(valid_x, num_iteration = clf.best_iteration_)[:, 1]\n\n    df_off_preds['TARGET'] = oof_preds\n\n    # test set\n    df_test = apps_all_test.copy() \n    test_res = pd.DataFrame()\n    # save SK_ID_CURR\n    test_res[\"SK_ID_CURR\"]=df_test[\"SK_ID_CURR\"]\n    X_apps_test = df_test.drop(\"SK_ID_CURR\", axis=1)\n\n    y_apps_test = clf.predict_proba(X_apps_test)\n    test_res[f\"TARGET\"] = y_apps_test[:, 1]\n    return df_off_preds, clf, test_res","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_off_preds, clf, test_res = StratifiedKFold_RUS_Stacking_LightGBMC_model(df=merged_df_train, nfolds=5, random_state=10, drop_columns_arr=['TARGET', 'SK_ID_CURR'], target_col='TARGET', apps_all_test=merged_df_test)\ndf_off_preds.to_csv(\"/kaggle/working/StratifiedKFold_RUS_Stacking_LightGBMC_train.csv\", index = False)\ntest_res.to_csv(\"/kaggle/working/StratifiedKFold_RUS_Stacking_LightGBMC_test.csv\", index = False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# SMOTE\ndef StratifiedKFold_SMOTE_Stacking_LightGBMC_model(df, nfolds, random_state, drop_columns_arr, target_col, apps_all_test):\n    df_off_preds = pd.DataFrame()\n    df_off_preds['SK_ID_CURR'] = df['SK_ID_CURR']\n\n    ftr_app = df.drop(drop_columns_arr, axis=1)  # feature dateset\n    target_app = df[target_col]                  # target datasets\n    \n    folds = StratifiedKFold(n_splits = nfolds, shuffle=True, random_state = random_state)\n    \n    oof_preds = np.zeros(ftr_app.shape[0])\n    \n    clf = LGBMClassifier(\n                nthread=5,\n                n_estimators=50000,\n                learning_rate=0.008,\n                max_depth=12,\n                num_leaves=58,\n                colsample_bytree=0.613,\n                subsample=0.8,\n                max_bin=410,\n                reg_alpha=3.564,\n                reg_lambda=4.930,\n                min_child_weight= 6,\n                min_child_samples=165,\n                silent=-1,\n                verbose=-1,\n                )\n    \n    # Apply SMOTE to the training set\n    smote = SMOTE()\n    \n    for fold_idx, (train_idx , valid_idx) in enumerate(folds.split(ftr_app, target_app)):\n        print(\"# iteration\", fold_idx, 'starts')\n        train_x = ftr_app.iloc[train_idx, :]\n        train_y = target_app.iloc[train_idx]\n        valid_x = ftr_app.iloc[valid_idx, :]\n        valid_y = target_app.iloc[valid_idx]\n\n        train_x_resampled, train_y_resampled = smote.fit_resample(train_x, train_y)\n\n        clf.fit(train_x_resampled, train_y_resampled, eval_set=[(train_x_resampled, train_y_resampled), (valid_x, valid_y)], eval_metric= 'auc', verbose= 200, early_stopping_rounds= 200)\n        \n        oof_preds[valid_idx] = clf.predict_proba(valid_x, num_iteration = clf.best_iteration_)[:, 1]\n\n    df_off_preds['TARGET'] = oof_preds\n\n    # test set\n    df_test = apps_all_test.copy() \n    test_res = pd.DataFrame()\n    # save SK_ID_CURR\n    test_res[\"SK_ID_CURR\"]=df_test[\"SK_ID_CURR\"]\n    X_apps_test = df_test.drop(\"SK_ID_CURR\", axis=1)\n\n    y_apps_test = clf.predict_proba(X_apps_test)\n    test_res[f\"TARGET\"] = y_apps_test[:, 1]\n    return df_off_preds, clf, test_res","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_off_preds, clf, test_res = StratifiedKFold_SMOTE_Stacking_LightGBMC_model(df=merged_df_train, nfolds=5, random_state=10, drop_columns_arr=['TARGET', 'SK_ID_CURR'], target_col='TARGET', apps_all_test=merged_df_test)\ndf_off_preds.to_csv(\"/kaggle/working/StratifiedKFold_SMOTE_Stacking_LightGBMC_train.csv\", index = False)\ntest_res.to_csv(\"/kaggle/working/StratifiedKFold_SMOTE_Stacking_LightGBMC_test.csv\", index = False)","metadata":{},"execution_count":null,"outputs":[]}]}